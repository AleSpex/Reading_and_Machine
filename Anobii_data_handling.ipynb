{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f02404-48ff-4666-8146-d07206d5f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA AND FUNCTIONS\n",
    "\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.types import IntegerType, StringType, MapType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import row_number, lit, dense_rank, concat_ws\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "import liwc\n",
    "\n",
    "#300 RATES PER BOOK\n",
    "#80 WORDS IN CONSIDERED COMMENTS\n",
    "\n",
    "#############################################\n",
    "#            read data                      # \n",
    "#############################################\n",
    "print(\"Read Anobii data\")\n",
    "\n",
    "# Read table which contains for each item_id (id of each book), the id of the author (author_id) who wrote that book\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/author_item.csv\"\n",
    "DFauthorbooks = spark.read.csv(file,header=True) #MOSTRA I LIBRI RELATIVI AGLI AUTORI\n",
    "\n",
    "# Read table which contains for each author_id (id of each auhtor), the info of that author\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/author_display.csv\"\n",
    "DFdisplay = spark.read.csv(file,header=True) #MOSTRA GLI AUTORI DEL DATABASE\n",
    "\n",
    "# Read table which contains the mapping of the language (language=11 means italian)\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/language_mapping.csv\"\n",
    "DFlanguages = spark.read.csv(file,header=True)\n",
    "\n",
    "# Read table which contains the info about items, i.e. books\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/item.csv\"\n",
    "DFitems_anobii = spark.read.csv(file,header=True) \n",
    "# DFitems_anobii.show(1, False)\n",
    "\n",
    "# Read table which contains the rate given by a person to a book\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/link_person_item.csv\" #item_review ha il voto dato dall'utente a quel libro\n",
    "DFinfo = spark.read.csv(file,header=True)\n",
    "# DFinfo.show(1, False)\n",
    "\n",
    "# Read table which contains the genre of each book\n",
    "file = \"anobii_genres/new_genres5.csv\"\n",
    "DFgenres = spark.read.csv(file, header=True)\n",
    "\n",
    "#Comments of the users related to books\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item_comment.csv\"\n",
    "DFreviews = spark.read.csv(file, header=True)\n",
    "\n",
    "#Remove noise data\n",
    "DFinfo = DFinfo.filter((DFinfo.item_review == '0') | (DFinfo.item_review == '1') | (DFinfo.item_review == '2') | (DFinfo.item_review == '3') | (DFinfo.item_review == '4') | (DFinfo.item_review == '5'))\n",
    "\n",
    "#FUNCTIONS\n",
    "def title_and_subtitle(line): #To split title and subtitle\n",
    "    if len(line.title.split(\" : \")) > 1: #Book possesses a subtitle\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, title, sub_title, line.author, 4, \"None\", 4, \"None\", line.ISBNISSN_new, \"bct\") #NE APPROFITTO ANCHE PER INSERIRE VOTO E CAMPI PER IL MERGE (PER ORA NULL)\n",
    "    else: #Il libro non possiede un sottotitolo\n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, line.title, \"None\", line.author, 4, \"None\", 4, \"None\", line.ISBNISSN_new, \"bct\")\n",
    "\n",
    "def create_user_dictionary(rdd): #Used to assign an integer id to each user of the rdd (to get the rows of the CSR)\n",
    "    rdd = rdd.map(lambda x: (str(x.person_id), list(x))).sortByKey()\n",
    "    user_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in user_dictionary.keys():\n",
    "        user_dictionary[key] = i\n",
    "        i += 1\n",
    "    return user_dictionary\n",
    "\n",
    "def create_book_dictionary(rdd): #Used to assign an integer id to each book of the rdd (to get the column of the CSR)\n",
    "    rdd = rdd.map(lambda x: (x.book_id, list(x))).sortByKey()\n",
    "    book_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in book_dictionary.keys():\n",
    "        book_dictionary[key] = i\n",
    "        i += 1\n",
    "    return book_dictionary\n",
    "\n",
    "def addDataType1(line):\n",
    "    return Row(line.item_id, line.person_id, line.title, str(line.sub_title), line.item_review, line.total_review, line.average_rating, str(line.total_votes), line.isbn, \"anobii\")\n",
    "\n",
    "\n",
    "def addRowColumnId(line): #Used to add index to books and users (not used anymore)\n",
    "    book_number = book_dictionary[line.book_id] \n",
    "    user_number = user_dictionary[line.person_id]\n",
    "    return Row(line.book_id,\n",
    "               line.title,\n",
    "               line.sub_title,\n",
    "               line.total_wishlist,\n",
    "               line.no_of_page,\n",
    "               line.publication_date,\n",
    "               line.publisher,\n",
    "               line.binding,\n",
    "               line.edition,\n",
    "               line.product_type,\n",
    "               line.total_votes,\n",
    "               line.data_type,\n",
    "               line.person_id,\n",
    "               line.item_review,\n",
    "               line.author,\n",
    "               line.genre,\n",
    "               line.encrypt_item_id,\n",
    "               line.isbn,\n",
    "               line.total_count,\n",
    "               line.average_rating,\n",
    "               line.total_review,\n",
    "               str(user_number), \n",
    "               str(book_number))\n",
    "    return Row(line.person_id, line.title, str(line.sub_title), line.item_review, line.data_type, line.book_id, line.author, line.genre, line.encrypt_item_id, line.total_votes_or_loans, line.average_rating, line.total_review, line.isbn, str(user_number), str(book_number))\n",
    "\n",
    "def title_and_subtitle_books(line): #FUNZIONE USATA PER DIVIDERE TITOLO E SOTTOTITOLO NEL DATASET DEI LIBRI DELLE BIBLIOTECHE E PER ELIMINARE EDITION_DATE ED EDITION_LANGUAGE\n",
    "    if len(line.title.split(\" : \")) > 1:\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "    else:\n",
    "        title = line.title\n",
    "        sub_title = \"None\"\n",
    "    #\"title\", \"sub_title\", \"author\", \"publisher\", \"book_id\"\n",
    "    return Row(title, sub_title, line.author, line.publisher, line.manifestation_id_new, line.ISBNISSN_new)\n",
    "\n",
    "def concatenateContentsDescriptions(line1, line2):\n",
    "    #More than one description in the same book\n",
    "    return Row(book_id=line1.book_id, title=line1.title, sub_title=line1.sub_title, \n",
    "               total_wishlist=line1.total_wishlist, no_of_page=line1.no_of_page, publication_date=line1.publication_date, \n",
    "               publisher=line1.publisher, binding=line1.binding, edition=line1.edition, product_type=line1.product_type, \n",
    "               total_votes=line1.total_votes, data_type=line1.data_type, author=line1.author, genre=line1.genre, \n",
    "               encrypt_item_id=line1.encrypt_item_id, isbn=line1.isbn, total_count=line1.total_count, average_rating=line1.average_rating, \n",
    "               total_review=line1.total_review, content=line1.content + \" \" + line2.content, content2=line1.content2) #book_index=line1.book_index,\n",
    "\n",
    "def toSingleDescriptions(line1):\n",
    "    return Row(book_id=line1[1].book_id, title=line1[1].title, sub_title=line1[1].sub_title, \n",
    "               total_wishlist=line1[1].total_wishlist, no_of_page=line1[1].no_of_page, publication_date=line1[1].publication_date, \n",
    "               publisher=line1[1].publisher, binding=line1[1].binding, edition=line1[1].edition, product_type=line1[1].product_type, \n",
    "               total_votes=line1[1].total_votes, data_type=line1[1].data_type, author=line1[1].author, genre=line1[1].genre, \n",
    "               encrypt_item_id=line1[1].encrypt_item_id, isbn=line1[1].isbn, total_count=line1[1].total_count, average_rating=line1[1].average_rating, \n",
    "               total_review=line1[1].total_review,  content=line1[1].content, content2=line1[1].content2)#book_index=line1[1].book_index,\n",
    "\n",
    "def concatenateContentsComments(line1, line2):\n",
    "    #Comments concatenation to description\n",
    "    return Row(book_id=line1.book_id, title=line1.title, sub_title=line1.sub_title, \n",
    "               total_wishlist=line1.total_wishlist, no_of_page=line1.no_of_page, publication_date=line1.publication_date, \n",
    "               publisher=line1.publisher, binding=line1.binding, edition=line1.edition, product_type=line1.product_type, \n",
    "               total_votes=line1.total_votes, data_type=line1.data_type, author=line1.author, genre=line1.genre, \n",
    "               encrypt_item_id=line1.encrypt_item_id, isbn=line1.isbn, total_count=line1.total_count, average_rating=line1.average_rating, \n",
    "               total_review=line1.total_review,  content=line1.content, content2=line1.content2, comment_content = str(line1.comment_content) + \" \" + str(line2.comment_content))#book_index=line1.book_index,\n",
    "\n",
    "def mergeDescriptionComments(line1):\n",
    "    return Row(book_id=line1.book_id, title=line1.title, sub_title=line1.sub_title, \n",
    "               total_wishlist=line1.total_wishlist, no_of_page=line1.no_of_page, publication_date=line1.publication_date, \n",
    "               publisher=line1.publisher, binding=line1.binding, edition=line1.edition, product_type=line1.product_type, \n",
    "               total_votes=line1.total_votes, data_type=line1.data_type, author=line1.author, genre=line1.genre, \n",
    "               encrypt_item_id=line1.encrypt_item_id, isbn=line1.isbn, total_count=line1.total_count, average_rating=line1.average_rating, \n",
    "               total_review=line1.total_review,  content2=line1.content2, content=str(line1.content) + \" \" + str(line1.comment_content))#book_index=line1.book_index,\n",
    "\n",
    "def toSingleComments(line1):\n",
    "    #print(line1)\n",
    "    return Row(book_id=line1[1].book_id, title=line1[1].title, sub_title=line1[1].sub_title, \n",
    "               total_wishlist=line1[1].total_wishlist, no_of_page=line1[1].no_of_page, publication_date=line1[1].publication_date, \n",
    "               publisher=line1[1].publisher, binding=line1[1].binding, edition=line1[1].edition, product_type=line1[1].product_type, \n",
    "               total_votes=line1[1].total_votes, data_type=line1[1].data_type, author=line1[1].author, genre=line1[1].genre, \n",
    "               encrypt_item_id=line1[1].encrypt_item_id, isbn=line1[1].isbn, total_count=line1[1].total_count, average_rating=line1[1].average_rating, \n",
    "               total_review=line1[1].total_review, content2=line1[1].content2, content=line1[1].content, comment_content = line1[1].comment_content)# book_index=line1[1].book_index,\n",
    "print(\"Raws data have been read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19befe-aa78-4f38-9837-1d3d69856940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERING START CELL\n",
    "\n",
    "#these are the columns which are needed for our work, for the item table. The others can be dropped\n",
    "DFitems_anobii_cols_to_keep = [\n",
    "                        \"item_id\",\\\n",
    "                        \"isbn\",\\\n",
    "#                         \"family_id\",\\\n",
    "                        \"title\",\\\n",
    "                        \"sub_title\",\\\n",
    "                        # \"barcode\",\\\n",
    "                        # \"image_source\",\\\n",
    "                        # \"image_width\",\\\n",
    "                        # \"image_height\",\\\n",
    "                        \"no_of_page\",\\\n",
    "                        \"publication_date\",\\\n",
    "                        \"publisher\",\\\n",
    "                        \"binding\",\\\n",
    "                        \"edition\",\\\n",
    "                        # \"reading_level\",\\\n",
    "                        # \"height\",\\\n",
    "                        # \"height_unit\",\\\n",
    "                        # \"length\",\\\n",
    "                        # \"length_unit\",\\\n",
    "                        # \"width\",\\\n",
    "                        # \"width_unit\",\\\n",
    "                        # \"weight\",\\\n",
    "                        # \"weight_unit\",\\\n",
    "                        # \"salesrank\",\\\n",
    "                        # \"item_popularity\",\\\n",
    "                        # \"check_same_family\",\\\n",
    "                        # \"check_internal_family\",\\\n",
    "                        # \"last_update\",\\\n",
    "                        \"average_rating\",\\\n",
    "                        \"total_review\",\\\n",
    "                        \"product_type\",\\\n",
    "                        # \"title_foreign\",\\\n",
    "                        # \"image_process\",\\\n",
    "                        # \"amazon\",\\\n",
    "                        # \"google\",\\\n",
    "                        \"encrypt_item_id\",\\\n",
    "                        # \"pid\",\\\n",
    "                        # \"binding_id\",\\\n",
    "                        # \"problem\",\\\n",
    "                        \"language\",\\\n",
    "                        # \"language_correct\",\\\n",
    "                        # \"ean\",\\\n",
    "                        # \"family_head\",\\\n",
    "                        # \"google_time\",\\\n",
    "                        # \"total_world\",\\\n",
    "                        # \"lock\",\\\n",
    "                        # \"volumes\",\\\n",
    "                        # \"publication_country_id\",\\\n",
    "                        # \"added_date\",\\\n",
    "                        # \"publishing_status\",\\\n",
    "                        # \"total_libraries\",\\\n",
    "                        # \"unavailable_date\",\\\n",
    "                        # \"table_of_contents_html\",\\\n",
    "                        # \"product_form_detail\",\\\n",
    "                        # \"total_edition_ratings\",\\\n",
    "                        # \"epub_url\",\\\n",
    "                        # \"imprint_name\",\\\n",
    "                        # \"is_sellable\",\\\n",
    "                        # \"total_topics\",\\\n",
    "                        # \"publisher_id\",\\\n",
    "                        \"total_wishlist\",\\\n",
    "                        # \"embargo_date\",\\\n",
    "                        # \"data_source\",\\\n",
    "                        # \"ebook_type\",\\\n",
    "                        # \"has_ebook\",\\\n",
    "                        # \"fulfillment_book_id\",\\\n",
    "                        # \"ebook_filesize\",\\\n",
    "                        # \"sample_status\",\\\n",
    "                        # \"sample_url\",\\\n",
    "                        # \"sample_filesize\",\\\n",
    "                      ]\n",
    "DFitems_anobii = DFitems_anobii.select(DFitems_anobii_cols_to_keep)\n",
    "print(\"Filter Anobii data (select books in italian, drop comics and books with a low number of ratings)\")\n",
    "#FILTERING 1: italian language\n",
    "#Filtering tuples with language != '11'\n",
    "\n",
    "DFfilteredlanguageitems = DFitems_anobii.filter(DFitems_anobii.language == \"11\")\n",
    "DFitems_anobii = DFitems_anobii.select(DFitems_anobii_cols_to_keep)\n",
    "print(DFfilteredlanguageitems.count())\n",
    "\n",
    "#FILTERING 2: only \"hardcover\" and \"paperback\" (filtering on binding attribute)\n",
    "\n",
    "DFfilteredbindingitems = DFfilteredlanguageitems.filter((DFfilteredlanguageitems.binding == \"Paperback\") | (DFfilteredlanguageitems.binding == \"Hardcover\"))\n",
    "print(DFfilteredbindingitems.count())\n",
    "\n",
    "#FILTERING 3: delete periodical books (as possible)\n",
    "#Keywords:Paperino, Topolino, Bonelli comics\n",
    "DFfilteredmagazineitems = DFfilteredbindingitems.filter(~(DFfilteredbindingitems.title.contains(\"Topolino\")) | (DFfilteredbindingitems.title.contains(\"Paperino\"))|(DFfilteredbindingitems.title.contains(\"Tex\"))|(DFfilteredbindingitems.title.contains(\"Dylan Dog\"))|(DFfilteredbindingitems.title.contains(\"Nathan Never\"))|(DFfilteredbindingitems.title.contains(\"Zagor\")))\n",
    "print(DFfilteredmagazineitems.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d931d62-e9e3-4f72-a659-57fa6d32677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL PLOT\n",
    "\n",
    "if False:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    size = 30\n",
    "    f = 1\n",
    "    rcParams['figure.figsize'] = 12.6*f, 7*f\n",
    "    rcParams['xtick.labelsize'] = size\n",
    "    rcParams['ytick.labelsize'] = size\n",
    "    rcParams['font.size'] = size\n",
    "    rcParams[\"font.sans-serif\"] = [\"Liberation Sans\"]\n",
    "    rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    rcParams.update({'figure.autolayout': False})\n",
    "    rcParams['pdf.fonttype'] = 42\n",
    "    rcParams['ps.fonttype'] = 42\n",
    "\n",
    "    import numpy as np\n",
    "    from itertools import accumulate\n",
    "\n",
    "    if False:\n",
    "        #PLOT CDF\n",
    "        file = \"/data/SMARTDATA/books/anobii_2021/sql/link_person_item.csv\"\n",
    "        DF = spark.read.csv(file,header=True)\n",
    "        #print(\"There are \"+str(DF.count())+\" ratings\")\n",
    "        prova = DF.groupby(DF.person_id).count().toPandas()\n",
    "        #print(\"the mean is \"+str(prova['count'].mean()))\n",
    "        #print(\"the median is \"+str(prova['count'].median()))\n",
    "        # fig,ax = plt.subplots()\n",
    "        # USE numpy's HISTOGRAM FUNCTION TO COMPUTE BINS\n",
    "        xh, xb = np.histogram(prova['count'], bins=6000, normed=True)\n",
    "        # COMPUTE THE CUMULATIVE SUM WITH accumulate\n",
    "        xh = list(accumulate(xh))\n",
    "\n",
    "        # NORMALIZE THE RESULT\n",
    "        xh = np.array(xh) / max(xh)\n",
    "        fig,ax = plt.subplots()\n",
    "        # PLOT WITH LABEL\n",
    "        ax.plot(xb[1:], xh, label=\"Anobii\")\n",
    "        #ax.plot(xbBCT[1:], xhBCT, label=\"BCT\")\n",
    "        #ax.grid()\n",
    "        #ax.legend()\n",
    "        ax.set_xlim(-20, 3000)#10000)\n",
    "        ax.set_ylim(0.0, 1.1)\n",
    "        #ax.set_title(\"CDF of Loans per User\")\n",
    "        ax.set_xlabel(\"Ratings per User\")\n",
    "        ax.set_ylabel(\"CDF\")\n",
    "        #ax.legend(frameon=False)\n",
    "        plt.savefig(\"006_cdfLoansPerUserAnobii.pdf\",\\\n",
    "                            # bbox_extra_artists=(first_legend,second_legend), \\\n",
    "                            bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #Number of users in top 10 countries\n",
    "        file = \"/data/SMARTDATA/books/anobii_2021/sql/person.csv\" #item_review ha il voto dato dall'utente a quel libro\n",
    "        DFusers = spark.read.csv(file,header=True)\n",
    "        DFusers_2 = DFusers.filter(DFusers.person_active == '1')\n",
    "\n",
    "        # Read table which contains the mapping of the language (language=11 means italian)\n",
    "        file = \"/data/SMARTDATA/books/anobii_2021/sql/language_mapping.csv\"\n",
    "        DFlanguages = spark.read.csv(file,header=True)\n",
    "\n",
    "        DFjoined = DFusers.join(DFlanguages, DFusers.language == DFlanguages.language_id)\n",
    "        DFjoined_2 = DFusers_2.join(DFlanguages, DFusers.language == DFlanguages.language_id)\n",
    "\n",
    "        DFcounting = DFjoined.select('language_name').groupBy('language_name').count().orderBy('count', ascending=False)\n",
    "\n",
    "        language_name = ['English', 'Italiano', '繁體中文', 'Español', 'Deutsch', 'Nederlands', 'РУССКИЙ', 'Français', '한국어']\n",
    "        language_name_2 = ['English', 'Italian', 'Chinese', 'Spanish', 'German', 'Dutch', 'Russian', 'French', 'Korean']\n",
    "\n",
    "        genre_users_language = {}\n",
    "        genre_users_language_2 = {}\n",
    "\n",
    "        for language, language2 in zip(language_name, language_name_2):\n",
    "            count = DFjoined.filter(DFjoined.language_name.contains(language)).count()\n",
    "            count_2 = DFjoined_2.filter(DFjoined_2.language_name.contains(language)).count()\n",
    "            genre_users_language[language2] = count\n",
    "            genre_users_language_2[language2] = count_2\n",
    "\n",
    "        names = list(genre_users_language.keys())\n",
    "        values = list(genre_users_language.values())\n",
    "\n",
    "        names_2 = list(genre_users_language_2.keys())\n",
    "        values_2 = list(genre_users_language_2.values())\n",
    "\n",
    "        X_axis = np.arange(len(language_name))\n",
    "        plt.figure()\n",
    "        plotting = plt.bar(X_axis - 0.2, values, 0.4)\n",
    "        plotting_2 = plt.bar(X_axis + 0.2, values_2, 0.4)\n",
    "        plt.legend(['all users', 'active users'])\n",
    "        plt.xticks(X_axis, language_name_2, rotation='vertical')\n",
    "        plt.ylabel('Number of users')\n",
    "        plt.savefig('007_number_anobii_users_countries.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if False:\n",
    "        #Number of books per top 10 language\n",
    "        file = \"/data/SMARTDATA/books/anobii_2021/sql/item.csv\" #item_review ha il voto dato dall'utente a quel libro\n",
    "        DFbooks = spark.read.csv(file,header=True)\n",
    "\n",
    "        file = \"/data/SMARTDATA/books/anobii_2021/sql/language_mapping.csv\"\n",
    "        DFlanguages = spark.read.csv(file,header=True)\n",
    "        DFjoined = DFbooks.join(DFlanguages, DFbooks.language == DFlanguages.language_id)\n",
    "\n",
    "        DFcounting = DFjoined.select('language_name').groupBy('language_name').count().orderBy('count', ascending=False)\n",
    "\n",
    "        language_name = ['English', 'Italiano', '繁體中文', 'Español', 'Deutsch', 'Nederlands', 'РУССКИЙ', 'Français', '日本語']\n",
    "        language_name_2 = ['English', 'Italian', 'Chinese', 'Spanish', 'German', 'Dutch', 'Russian', 'French', 'Japanese']\n",
    "\n",
    "        genre_users_language = {}\n",
    "\n",
    "        for language, language2 in zip(language_name, language_name_2):\n",
    "            count = DFjoined.filter(DFjoined.language_name.contains(language)).count()\n",
    "            genre_users_language[language2] = count\n",
    "\n",
    "        names = list(genre_users_language.keys())[0:5]\n",
    "        values = list(genre_users_language.values())[0:5]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(names, values)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('008_number_anobii_books_countries.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if False:\n",
    "        #Occurrences of ratings in Anobii dataset\n",
    "        DFinfo_grouped = DFinfo.groupBy('item_review').count()\n",
    "        DFinfo_grouped_pandas = DFinfo_grouped.toPandas()\n",
    "        list_ratings = DFinfo_grouped_pandas['item_review'].to_list()\n",
    "        list_votes = DFinfo_grouped_pandas['count'].to_list()\n",
    "\n",
    "        list_ratings_votes = list(zip(list_ratings, list_votes))\n",
    "        list_ratings_votes.sort()\n",
    "\n",
    "        list_ratings = [item[0] for item in list_ratings_votes]\n",
    "        list_votes = [item[1] for item in list_ratings_votes]\n",
    "\n",
    "        plt.bar(list_ratings, list_votes)\n",
    "        plt.xlabel('Rate')\n",
    "        plt.ylabel('Number of rated books')\n",
    "        plt.savefig('009_rates_anobii_books.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if False:\n",
    "        #GENRES OCCURRENCE IN GENRE DATASET\n",
    "        DFgenres_grouped = DFgenres.groupBy('name').count()\n",
    "        DFgenres_grouped_pandas = DFgenres_grouped.toPandas()\n",
    "        list_genres = DFgenres_grouped_pandas['name']\n",
    "        list_counts = DFgenres_grouped_pandas['count']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_genres, list_counts)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.ylabel('Genre occurrence')\n",
    "        plt.savefig('010_genre_occurrences.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    if False:\n",
    "        #PLOT FOR MERGED DATASET (MOST FREQUENT KEYWORD in TOP 5)\n",
    "        import pandas as pd\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_top5keywords = DF_final['top_keywords_5_with_comment'].to_list()\n",
    "\n",
    "        list_keywords = [eval(item) for item in DF_final_top5keywords]\n",
    "        list_flat_keywords = [item for sublist in list_keywords for item in sublist]\n",
    "\n",
    "        keywords = {}\n",
    "\n",
    "        for keyword in list_flat_keywords: \n",
    "            if keyword not in keywords.keys():\n",
    "                keywords[keyword] = 1\n",
    "            else:\n",
    "                keywords[keyword] += 1\n",
    "\n",
    "        keywords = dict(sorted(keywords.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        names = list(keywords.keys())[0:20]\n",
    "        values = list(keywords.values())[0:20]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(names, values)\n",
    "        plt.ylabel('Number of occurrences')\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.savefig('016_keyword_occurrences_with_comm.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    if False:\n",
    "        #CALCULATE ENTROPY\n",
    "        #minus Sum for each keyword(Occurrence_keyword/Total_occurrences * logbasekeywordnumber(Occurrence_keyword/Total_occurrences))\n",
    "        #How many keywords?\n",
    "        import math\n",
    "        keyword_number = ['5', '10', '15', '20']\n",
    "        entropy_with_values = []\n",
    "        entropy_without_values = []\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        for number in keyword_number:\n",
    "            list_keywords = DF_final[f'top_keywords_{number}_with_comment'].to_list()\n",
    "            flat_list = [item for sublist in list_keywords for item in sublist]\n",
    "            flat_list_unique = list(set(flat_list))\n",
    "\n",
    "            entropy_array = []\n",
    "            #Calculate entropy as above\n",
    "            for keyword in flat_list_unique:\n",
    "\n",
    "                flat_list_keyword = [item for item in flat_list if item == keyword] #Occurrences\n",
    "                #if len(flat_list_keyword) > 150:\n",
    "                    #print(keyword)\n",
    "                #print(len(flat_list_keyword))\n",
    "                entropy_keyword = (len(flat_list_keyword) / len(flat_list)) * (math.log((len(flat_list_keyword) / len(flat_list)), len(flat_list_unique)))\n",
    "                entropy_array.append(entropy_keyword)\n",
    "\n",
    "            entropy_np = np.asarray(entropy_array)\n",
    "            entropy_with = -(np.sum(entropy_np))\n",
    "            entropy_with_values.append(entropy_with)\n",
    "            print(entropy_with_values)\n",
    "            list_keywords = DF_final[f'top_keywords_{number}_without_comm'].to_list()\n",
    "            flat_list = [item for sublist in list_keywords for item in sublist]\n",
    "            flat_list_unique = list(set(flat_list))\n",
    "\n",
    "            entropy_array = []\n",
    "            #Calculate entropy as above\n",
    "            for keyword in flat_list_unique:\n",
    "                flat_list_keyword = [item for item in flat_list if item == keyword] #Occurrences\n",
    "                #if len(flat_list_keyword) > 150:\n",
    "                    #print(keyword)\n",
    "                #print(len(flat_list_keyword))\n",
    "                entropy_keyword = (len(flat_list_keyword) / len(flat_list)) * (math.log((len(flat_list_keyword) / len(flat_list)), len(flat_list_unique)))\n",
    "                entropy_array.append(entropy_keyword)\n",
    "\n",
    "            entropy_np = np.asarray(entropy_array)\n",
    "            entropy_without = -(np.sum(entropy_np))\n",
    "            entropy_without_values.append(entropy_without)\n",
    "\n",
    "        #GRAPHS ENTROPY\n",
    "        plt.figure()\n",
    "        plt.plot(keyword_number, entropy_with_values)\n",
    "        plt.plot(keyword_number, entropy_without_values)\n",
    "        plt.ylabel('Entropy')\n",
    "        plt.xlabel('Number of keywords per book')\n",
    "        plt.legend(['With comments','No comments'])\n",
    "        plt.savefig('017_entropy_keywords.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #COVERAGE GENRE KEYWORDS (SAVED BEFOREHAND FOR COMFORT)\n",
    "        possible_keywords = [5, 10, 15, 20, 30, 50]\n",
    "        average_percentages = [49.086402663093516, 65.79894419074137, 75.69834836556531, 82.83928946909826, 91.31414622247611, 98.63530510583139]\n",
    "\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(possible_keywords, average_percentages)\n",
    "        plt.xlabel('Number of keywords per book')\n",
    "        plt.ylabel('Coverage percentage')\n",
    "        plt.savefig('018_coverage_keywords.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #feel-it mood plot\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_grouped = DF_final.groupby(['sentiment']).count()\n",
    "        list_mood = ['negative','positive']\n",
    "        list_values = [1878, 553]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_mood, list_values)\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('019_mood_feelit.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #feel-it emotion plot\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_grouped = DF_final.groupby(['emotion']).count()\n",
    "        #print(DF_final_grouped)\n",
    "        list_mood = ['anger','joy', 'sadness', 'fear']\n",
    "        list_values = [161, 733, 1179, 358]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_mood, list_values)\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('020_emotion_feelit.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #VADER mood labels plot\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_grouped = DF_final.groupby(['vader_score']).count()\n",
    "        print(DF_final_grouped)\n",
    "        list_mood = ['negative','positive']\n",
    "        list_values = [1076, 1355]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_mood, list_values)\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('021_mood_vader.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #TEXTBLOB mood plot\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_grouped = DF_final.groupby(['textblob_english_sentiment']).count()\n",
    "        print(DF_final_grouped)\n",
    "        list_mood = ['negative','positive']\n",
    "        list_values = [607, 1824]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_mood, list_values)\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('022_mood_textblob.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        #majority mood plot\n",
    "        DF_final = pd.read_csv('2_final_dataset.csv')\n",
    "        DF_final_grouped = DF_final.groupby(['majority']).count()\n",
    "        #print(DF_final_grouped)\n",
    "        list_mood = ['negative','positive']\n",
    "        list_values = [1129, 1302]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(list_mood, list_values)\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.savefig('023_mood_majority.pdf', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fffed-b361-46db-b285-d27a97f5de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESSING DATAFRAME GENRES#\n",
    "\n",
    "#Phase 1: delete tuple selfhelp, referece, textbook as genre\n",
    "DFgenres = DFgenres.filter((DFgenres.name != \"SelfHelp\") & (DFgenres.name != \"Reference\") & (DFgenres.name != \"Textbook\"))\n",
    "\n",
    "#Phase 1.2: delete tuples with votes == null (noise data)\n",
    "DFgenres = DFgenres.filter(~(DFgenres.votes.isNull()))\n",
    "\n",
    "#Phase 2: map genres by aggregating them as described in the thesis\n",
    "RDDgenres = DFgenres.rdd\n",
    "\n",
    "def mapGenres(line):\n",
    "    transformed_line = line.name\n",
    "    if transformed_line == \"Cooking-Food&Wine\" or transformed_line == \"Games\" or transformed_line == \"Crafts&Hobbies\" or transformed_line == \"Home&Gardening\" or transformed_line == \"Music\" or transformed_line == \"Art-Architecture&Photography\" or transformed_line == \"Sports-Outdoors&Adventure\" or transformed_line == \"Entertainment\":\n",
    "        transformed_line = \"FreeTime\"\n",
    "    elif transformed_line == \"Professional&Technical\" or transformed_line == \"Computer&Technology\" or transformed_line == \"Law\" or transformed_line == \"Medicine\" or transformed_line == \"Business&Economics\" or transformed_line == \"ForeignLanguageStudy\" or transformed_line == \"Education&Teaching\":\n",
    "        transformed_line = \"Professional&Technical\"\n",
    "    elif transformed_line == \"Health-Mind&Body\" or transformed_line == \"Religion&Spirituality\":\n",
    "        transformed_line = \"Health-Mind&Body\"\n",
    "    elif transformed_line == \"Family-Sex&Relationships\" or transformed_line == \"Gay&Lesbian\":\n",
    "        transformed_line = \"Family-Sex&Relationships\"\n",
    "    elif transformed_line == \"Science&Nature\" or transformed_line == \"Pets\":\n",
    "        transformed_line = \"Science&Nature\"\n",
    "    elif transformed_line == \"Children\" or transformed_line == \"Teens\":\n",
    "        transformed_line = \"Children&Teens\"\n",
    "    #elif transformed_line == \"Fiction&Literature\":\n",
    "    #    transformed_line = \"None\"\n",
    "    return Row(id=line.id, familyid=line.familyid, itemid=line.itemid, categoryid=line.categoryid, slug=line.slug, name=transformed_line, languageid=line.languageid, votes = line.votes)\n",
    "\n",
    "RDDgenres_mapped = RDDgenres.map(mapGenres)\n",
    "DFgenres = RDDgenres_mapped.toDF([])\n",
    "\n",
    "#delete fiction & literature\n",
    "print(DFgenres.count())\n",
    "DFgenres = DFgenres.filter(DFgenres.name != \"Fiction&Literature\")\n",
    "print(DFgenres.count())\n",
    "\n",
    "#Phase 2.2: Aggregation genres\n",
    "\n",
    "DFgenres = DFgenres.select(\"*\", F.sum(DFgenres.votes).over(Window.partitionBy(DFgenres.itemid, DFgenres.name)).alias(\"new_votes\")).drop(DFgenres.votes)\n",
    "DFgenres = DFgenres.withColumnRenamed(\"new_votes\", \"votes\").dropDuplicates([\"itemid\", \"name\"])\n",
    "\n",
    "#Phase 3: keeping only 4 genres max per book\n",
    "DFgenres = DFgenres.withColumn(\"rank\", row_number().over(Window.partitionBy(DFgenres.itemid).orderBy(col(\"votes\").desc()))).filter(col(\"rank\") <= 4)\n",
    "\n",
    "#Phase 4: aggregation of book in one tuple (genres are now a list) \n",
    "\n",
    "DFgenres = DFgenres.select(concat_ws(\"/\", DFgenres.name, DFgenres.votes).alias(\"genre_with_votes\"), \"id\", \"familyid\", \"itemid\", \"categoryid\", \"languageid\", \"slug\")\n",
    "\n",
    "RDDgenres = DFgenres.rdd\n",
    "RDDgenres_pair = RDDgenres.map(lambda x: (x.itemid, x))\n",
    "\n",
    "def aggregateGenres(line1, line2):\n",
    "    return Row(id=line1.id, familyid=line1.familyid, itemid=line1.itemid, categoryid=line1.categoryid, slug=line1.slug, languageid=line1.languageid, genre_with_votes = line1.genre_with_votes + \" \" + line2.genre_with_votes)\n",
    "\n",
    "RDDgenres_reduced = RDDgenres_pair.reduceByKey(aggregateGenres)\n",
    "\n",
    "def toSingleGenres(line1):\n",
    "    return Row(id=line1[1].id, familyid=line1[1].familyid, itemid=line1[1].itemid, categoryid=line1[1].categoryid, slug=line1[1].slug, languageid=line1[1].languageid, genre_with_votes = line1[1].genre_with_votes)\n",
    "\n",
    "RDDgenres_single = RDDgenres_reduced.map(toSingleGenres)\n",
    "\n",
    "def toDictGenre(line1):\n",
    "    dict_genres = {}\n",
    "    genre_vote_list = line1.genre_with_votes.split(\" \")\n",
    "    for genre_vote in genre_vote_list:\n",
    "        genre = genre_vote.split(\"/\")[0]\n",
    "        vote = genre_vote.split(\"/\")[1]\n",
    "        dict_genres[genre] = vote\n",
    "\n",
    "    return Row(id=line1.id, familyid=line1.familyid, itemid=line1.itemid, categoryid=line1.categoryid, slug=line1.slug, languageid=line1.languageid, genre_with_votes = dict_genres)\n",
    "\n",
    "RDDgenres_single = RDDgenres_single.map(toDictGenre)\n",
    "DFgenres = RDDgenres_single.toDF([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f516649-d9c1-47db-a69a-1ff88188e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENT HANDLING CELL\n",
    "from pyspark.sql import functions as F\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item_comment.csv\"\n",
    "DFreviews = spark.read.csv(file, header=True)\n",
    "\n",
    "#Comment length filtering (80 words per comment min)\n",
    "DFreviews = DFreviews.filter(F.size(F.split('comment_content', ' ')) >= 80)\n",
    "\n",
    "#PLOT COMMENTS LENGTH\n",
    "if False:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    file = \"/data/SMARTDATA/books/anobii/link_person_item_comment.csv\"\n",
    "    DFreviews = spark.read.csv(file, header=True)\n",
    "    DFreviews = DFreviews.withColumn(\"comment_length\", F.size(F.split('comment_content', ' ')))\n",
    "    DFreviews_count_words = DFreviews.groupBy('comment_length').count()\n",
    "    #DFreviews_count_words.show(1, False)\n",
    "    DFreviews_count_words_pandas = DFreviews_count_words.toPandas().sort_values(by=['comment_length'])\n",
    "    #print(DFreviews_count_words_pandas)\n",
    "    list_lengths = DFreviews_count_words_pandas['comment_length'].to_list()\n",
    "    list_counts = DFreviews_count_words_pandas['count'].to_list()\n",
    "    plt.figure()\n",
    "    plt.plot(list_lengths[1:201], list_counts[1:201])\n",
    "    plt.xlabel('Length of comment in words')\n",
    "    plt.ylabel('Number of comments')\n",
    "    plt.savefig('011_comment_length.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176d8ed-082e-4cf1-bcf5-9a3481d4cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERING CELL 2\n",
    "\n",
    "#FILTERING 4: books with more than X (selectable) votes.\n",
    "\n",
    "DFstarsfilteredno0 = DFinfo#.filter(DFinfo.item_review > 0) #KEEP THE 0 votes because they are still implicit interactions\n",
    "\n",
    "#Count books with most ratings and sort them in descending order\n",
    "DFgrouped = DFstarsfilteredno0.groupby(\"item_id\").count().withColumnRenamed(\"count\", \"total_votes\")\\\n",
    "                              .sort(\"total_votes\", ascending=False)\n",
    "\n",
    "\n",
    "#list_books = []\n",
    "#for i in [50, 100, 150, 200, 250, 300]: #FOR RATING BOOKS PLOT\n",
    "#29537 books with 50 threshold, 15273 books with 100 threshold\n",
    "DFgroupedfiltered = DFgrouped.filter(DFgrouped['total_votes'] >= 300) #300 = RATING THRESHOLD\n",
    "DFjoinbookstars = DFfilteredmagazineitems.join(DFgroupedfiltered, DFfilteredmagazineitems.item_id == DFgroupedfiltered.item_id).drop(DFgroupedfiltered.item_id)\n",
    "print(DFjoinbookstars.count())\n",
    "#list_books.append(DFjoinbookstars.count())\n",
    "\n",
    "# DFjoinbookstars:\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "# |item_id|isbn      |title            |sub_title|no_of_page|publication_date|publisher|binding  |edition|average_rating  |total_review|product_type|encrypt_item_id   |language|total_wishlist|total_votes|\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "# |1981748|8845260372|Giulietta squeenz|null     |209       |2008-05-01      |Bompiani |Paperback|null   |3.18773234200743|129         |1           |014f24ec9629744c88|11      |110           |543        |\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "\n",
    "#FILTERING 5: Various cleaning\n",
    "#Taking titles and trasforming them in lower case for merging \n",
    "DFmanifestations_definitive_anobii = DFjoinbookstars.select(\"item_id\", \\\n",
    "                                                            lower(DFjoinbookstars.title), \\\n",
    "                                                            lower(DFjoinbookstars.sub_title), \\\n",
    "                                                            \"isbn\",\\\n",
    "                                                            \"average_rating\", \\\n",
    "                                                            \"total_review\", \\\n",
    "                                                            \"total_wishlist\", \\\n",
    "                                                            \"no_of_page\",\n",
    "                                                            \"publication_date\",\n",
    "                                                            \"publisher\",\n",
    "                                                            \"binding\",\n",
    "                                                            \"edition\",\n",
    "                                                            \"product_type\",\n",
    "                                                            \"total_votes\",\n",
    "                                                            \"encrypt_item_id\",)\\\n",
    "                                                    .withColumnRenamed(\"lower(title)\", \"title\")\\\n",
    "                                                    .withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "# DFmanifestations_definitive_anobii.show(1, False)\n",
    "# DFmanifestations_definitive_anobii: (uguale a DFjoinbookstars ma senza language)\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "\n",
    "if False:\n",
    "    #PLOT RATING THRESHOLD\n",
    "    plt.figure()\n",
    "    plt.plot([50,100,150,200,250,300], list_books)\n",
    "    plt.xlabel('Rating threshold')\n",
    "    plt.ylabel('Number of books')\n",
    "    plt.savefig('012_rating_threshold.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a8096-be15-4c68-a7b7-d1d0f71ee379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENRES INTEGRATION CELL\n",
    "\n",
    "print(\"Anobii data have been filtered (select books in italian, drop comics and books with a low number of ratings)\")\n",
    "print(\"Integrate with genre and author attributes Anobii data\")\n",
    "#add genres to the item table: this is contained in DFgenres:\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# |id |familyid|itemid |categoryid|slug              |name              |languageid|votes|\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# |1  |32423317|2823074|3         |business-economics|Business&Economics|3         |2.0  |\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# Notice that if a book has more than 1 genre, DFgenres contained more than one row with that item_id, one for genre.\n",
    "# Aggregation of rows with same itemid is needed \n",
    "#DFgenres_aggregated = DFgenres.groupBy('itemid')\\\n",
    "#                              .agg(F.concat_ws(\" / \", F.collect_list('name'))\\\n",
    "#                                    .alias('genres'))\n",
    "# DFgenres_aggregated:\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "# |itemid |genres                                                                                        |\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "# |1981748|Humor / Fiction&Literature / Romance / Family-Sex&Relationships / Teens / Philosophy / History|\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "\n",
    "# join between items and DFgenres_aggregated to have, for each item, its genres\n",
    "DFmanifestations_definitive_anobii_genres = DFmanifestations_definitive_anobii.join(DFgenres,\\\n",
    "                                                                                    DFgenres.itemid == DFmanifestations_definitive_anobii.item_id)\\\n",
    "                                                                              .select(DFmanifestations_definitive_anobii[\"*\"],\\\n",
    "                                                                                      DFgenres.genre_with_votes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad08474-bbb4-4625-9d5b-8c6398c15925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENRE PLOTS CELL\n",
    "if False:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    size = 30\n",
    "    f = 1\n",
    "    rcParams['figure.figsize'] = 12.6*f, 7*f\n",
    "    rcParams['xtick.labelsize'] = size\n",
    "    rcParams['ytick.labelsize'] = size\n",
    "    rcParams['font.size'] = size\n",
    "    rcParams[\"font.sans-serif\"] = [\"Liberation Sans\"]\n",
    "    rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    rcParams.update({'figure.autolayout': False})\n",
    "    rcParams['pdf.fonttype'] = 42\n",
    "    rcParams['ps.fonttype'] = 42\n",
    "\n",
    "    if False:\n",
    "        #PLOT OCCURRENCE GENRES IN FILTERED DATASET\n",
    "        genre_counter = {}\n",
    "\n",
    "        list_genres = DFmanifestations_definitive_anobii_genres.toPandas()['genre_with_votes'].to_list()\n",
    "        #print(list_genres)\n",
    "\n",
    "        for genre_dict in list_genres:\n",
    "            #genre_dict = eval(genre_dict)\n",
    "            for genre in genre_dict.keys():\n",
    "                if genre in genre_counter.keys():\n",
    "                    genre_counter[genre] += 1\n",
    "                else:\n",
    "                    genre_counter[genre] = 1\n",
    "        genre_counter.pop('name', None)\n",
    "        print(genre_counter)\n",
    "\n",
    "        names = list(genre_counter.keys())\n",
    "        values = list(genre_counter.values())\n",
    "\n",
    "        histogram = plt.bar(names,values)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.ylabel('Genre occurrence')\n",
    "        plt.savefig('013_genres_occurrence_filtering.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if False:\n",
    "        #PLOT NUMBER OF BOOKS PER NUMBER OF GENRES\n",
    "\n",
    "        file = \"anobii_genres/new_genres5.csv\"\n",
    "        DFgenres = spark.read.csv(file, header=True)\n",
    "\n",
    "        from pyspark.sql import functions as F, Window\n",
    "        DFgenres_part = DFgenres.select(\"*\", F.row_number().over(Window.partitionBy(DFgenres.itemid).orderBy(DFgenres.votes.cast(\"int\").desc())).alias(\"id_inc\"))\n",
    "\n",
    "        _list_means = []\n",
    "        _list_counts = []\n",
    "        _list = [i+1 for i in range(21)]\n",
    "        import numpy as np\n",
    "        from pyspark.sql.functions import mean, sum, count\n",
    "        for i in _list:\n",
    "            DFfiltered = DFgenres_part.filter(DFgenres_part.id_inc == i)\n",
    "            _count = DFfiltered.select(count(DFfiltered.votes.cast('int'))).collect()\n",
    "            _mean = DFfiltered.select(mean(DFfiltered.votes.cast('int'))).collect()\n",
    "            _list_means.append(_mean[0][0])\n",
    "            _list_counts.append(_count[0][0])\n",
    "            print(_mean[0][0])\n",
    "            print(_count[0][0])\n",
    "\n",
    "        plt.figure()\n",
    "        plotting = plt.bar(_list, _list_counts)\n",
    "        #plt.xticks(rotation='vertical')\n",
    "        plt.ylabel('Number of books')\n",
    "        plt.xlabel('Number of genres')\n",
    "        plt.savefig('014_number_books_per_number_genres.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    if False:\n",
    "        #PLOT AVERAGE SCORE FOR NUMBER OF GENRES\n",
    "        plt.figure()\n",
    "        plotting = plt.plot(_list, _list_means)\n",
    "        plt.ylabel('Average total score')\n",
    "        plt.xlabel('Number of genres')\n",
    "        #plt.xticks(rotation='vertical')\n",
    "        #plt.xticks(range(len(_list))[1:], [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
    "        plt.savefig('015_average_score_for_genre_number.pdf', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cdde8b-fe29-478e-8f79-c1be6439b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTHOR AND GENRE INTEGRATION CELL\n",
    "\n",
    "# DFmanifestations_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |genres                                                                                        |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|History / Fiction&Literature / Family-Sex&Relationships / Teens / Humor / Romance / Philosophy|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# add a column which explain the origin of the data (anobii or BCT)\n",
    "DFmanifestations_definitive_anobii_genres = DFmanifestations_definitive_anobii_genres.withColumn('data_type', lit(\"anobii\"))\n",
    "# DFmanifestations_definitive_anobii_genres.show(1, False)\n",
    "# DFmanifestations_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |genres                                                                                        |data_type|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|Family-Sex&Relationships / Teens / Humor / Romance / Philosophy / History / Fiction&Literature|anobii   |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# add author in the DFmanifestations_definitive_anobii_genres table\n",
    "# find author_id for each book\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_definitive_anobii_genres.join(DFauthorbooks, \\\n",
    "                                                                                       DFauthorbooks.item_id == DFmanifestations_definitive_anobii_genres.item_id)\\\n",
    "                                                                                 .select(DFmanifestations_definitive_anobii_genres[\"*\"], \\\n",
    "                                                                                         DFauthorbooks[\"author_id\"])\n",
    "# DFmanifestations_anobii_genres_author.show(1, False)\n",
    "# DFmanifestations_anobii_genres_author:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|author_id|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Romance / Humor /...|   anobii|   354644|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# find author (name) for each book (and remove books which has same title but different auhtor?)\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_anobii_genres_author.join(DFdisplay,\\\n",
    "                                                                                   DFmanifestations_anobii_genres_author.author_id == DFdisplay.author_id)\\\n",
    "                                                                             .select(DFmanifestations_anobii_genres_author[\"*\"], \\\n",
    "                                                                                     DFdisplay[\"author_name\"])\\\n",
    "                                                                             .drop(\"author_id\")\n",
    "\n",
    "# remove books which has same title but different auhtor\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_anobii_genres_author.select(\"*\", F.min(DFmanifestations_anobii_genres_author.author_name)\\\n",
    "                                                                                           .over(Window.partitionBy(DFmanifestations_anobii_genres_author.item_id))\\\n",
    "                                                                                           .alias(\"author\"))\\\n",
    "                                                                             .drop(\"author_name\")\\\n",
    "                                                                             .dropDuplicates(['item_id', 'author'])\n",
    "# DFmanifestations_anobii_genres_author.show(1, False)\n",
    "# DFmanifestations_anobii_genres_author:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Philosophy / Hist...|   anobii|Pulsatilla|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "#join of item and rating tables to obtain person_id, item_id, rating and all attributes of the item in the same row\n",
    "#df1.join(df2, df1.id == df2.id).select(df1[\"*\"],df2[\"other\"])\n",
    "DFloans_definitive_anobii_genres = DFstarsfilteredno0.join(DFmanifestations_anobii_genres_author, \\\n",
    "                                                           DFmanifestations_anobii_genres_author.item_id == DFstarsfilteredno0.item_id)\\\n",
    "                                                     .select(DFmanifestations_anobii_genres_author[\"*\"], \\\n",
    "                                                             DFstarsfilteredno0[\"person_id\"], \\\n",
    "                                                             DFstarsfilteredno0[\"item_review\"])\n",
    "# DFloans_definitive_anobii_genres.show(1, False)\n",
    "# DFloans_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|person_id|item_review|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Philosophy / Fict...|   anobii|Pulsatilla|  1244593|          3|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "\n",
    "print(\"Anobii data have been integreted with genre and author attributes\")\n",
    "print(\"Read and filter BCT data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f784b0e-7e6e-46de-b2e4-90cd86342a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD BCT FILTERED DATA\n",
    "\n",
    "%run BCT_data_handling.ipynb #Così a quanto pare\n",
    "DFmanifestations_definitive_bct = DFmanifestations_definitive\n",
    "DFloans_definitive_bct = DFloans_definitive\n",
    "# DFmanifestations_definitive_bct.show(1, False)\n",
    "# DFmanifestations_definitive_bct:\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# |edition_language|edition_date|    title|       author|publisher|manifestation_id_new|ISBNISSN_new|\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# |             ita|        1996|Pinocchio|Carlo Collodi|   Nuages|              107930|  8807820714|\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# DFloans_definitive_bct:\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "# |manifestation_id_new|       patron_id_md5|    loan_date_begin|      loan_date_end|           due_date|from_library|to_library|end_library|\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "# |              220771|fa242f1458100dccc...|2012-09-05 11:27:25|2012-09-27 18:18:00|2012-10-05 11:27:21|          18|        18|         18|\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "print(\"BCT data have been read and filtered\")\n",
    "print(\"Prepare data for merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2dcb2f-ae51-45a5-8889-f2d8c29a5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCT data preparation: prepare the table of loans which contains also metadata of the book\n",
    "DFloans_with_titles = DFloans_definitive_bct.join(DFmanifestations_definitive_bct, \\\n",
    "                                                  DFloans_definitive_bct.manifestation_id_new == DFmanifestations_definitive_bct.manifestation_id_new)\\\n",
    "                                             .select(DFloans_definitive_bct.manifestation_id_new, \\\n",
    "                                                     \"patron_id_md5\", \\\n",
    "                                                     \"author\", \\\n",
    "                                                     \"ISBNISSN_new\", \\\n",
    "                                                     lower(DFmanifestations_definitive_bct.title))\\\n",
    "                                             .withColumnRenamed(\"lower(title)\", \"title\")\n",
    "# DFloans_with_titles:\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "# |manifestation_id_new|       patron_id_md5|       author|ISBNISSN_new|    title|\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "# |              107930|b5c0986c79b1afafd...|Carlo Collodi|  8807820714|pinocchio|\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "\n",
    "# BCT data preparation: split title and subtitle\n",
    "RDDloans_with_titles = DFloans_with_titles.rdd    \n",
    "RDDloans_for_merge = RDDloans_with_titles.map(title_and_subtitle)  \n",
    "# DFloans_with_titles.show(1, False)\n",
    "DFloans_to_merge = RDDloans_for_merge.toDF([\"item_id\", \\\n",
    "                                            \"person_id\", \\\n",
    "                                            \"title\", \\\n",
    "                                            \"author\", \\\n",
    "                                            \"sub_title\", \\\n",
    "                                            \"item_review\", \\\n",
    "                                            \"total_review\", \\\n",
    "                                            \"average_rating\", \\\n",
    "                                            \"total_votes\", \\\n",
    "                                            \"isbn\", \\\n",
    "                                            \"data_type\"])\n",
    "# BCT data preparation: add missing columns, which are present in DFloans_definitive_anobii_genres\n",
    "columns_to_add = ['total_wishlist',\n",
    "                  'no_of_page',\n",
    "                  'publication_date',\n",
    "                  'publisher',\n",
    "                  'binding',\n",
    "                  'edition',\n",
    "                  'product_type',\n",
    "                  'encrypt_item_id',\n",
    "                  'genre_with_votes',\n",
    "                 ]\n",
    "values_to_add = {'total_wishlist': None,\n",
    "                  'no_of_page': None,\n",
    "                  'publication_date': None, \n",
    "                  'publisher': None, \n",
    "                  'binding': \"Paperback\",\n",
    "                  'edition': None,\n",
    "                  'product_type': 1,\n",
    "                  'encrypt_item_id': None,\n",
    "                  'genre_with_votes': None,\n",
    "    \n",
    "}\n",
    "for c in columns_to_add:\n",
    "        DFloans_to_merge = DFloans_to_merge.withColumn(c, lit(values_to_add[c]))\n",
    "\n",
    "DFloans_to_merge = DFloans_to_merge.select(\"item_id\", \"title\", \"sub_title\", \"isbn\", \"average_rating\", \"total_review\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"encrypt_item_id\", \"genre_with_votes\", \"data_type\", \"author\", \"person_id\", \"item_review\")\n",
    "\n",
    "#DFloans_to_merge = DFloans_to_merge.withColumn(\"genre_with_votes\",DFloans_to_merge.genre_with_votes.cast(MapType(StringType(), StringType())))\n",
    "#DFloans_definitive_anobii_genres.printSchema()\n",
    "#DFloans_to_merge.printSchema()\n",
    "\n",
    "# DFloans_to_merge:\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "# |item_id|           person_id|    title|author_name|    sub_title|item_review|total_review|average_rating|total_votes|      isbn|  data_type|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|encrypt_item_id|genre|\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "# | 107930|fcc17388ef20567fe...|pinocchio|       None|Carlo Collodi|          4|        None|          None|       None|8807820714|biblioteche|          null|      null|            null|     null|Paperback|   null|           1|           null| null|\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "print(\"Data have been prepared for merge\")\n",
    "print(\"Merge data\")\n",
    "# union of the loans of bct data and anobii data\n",
    "DFloans_merged = DFloans_definitive_anobii_genres.union(DFloans_to_merge)\n",
    "# DFloans_merged.show(1)\n",
    "# DFloans_merged\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|person_id|item_review|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Family-Sex&Relati...|   anobii|Pulsatilla|   734393|          5|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# Remove books, whose title is one word only, i.e. keep books whose title contains at least a blank space\n",
    "# DFloans_merged.filter(DFloans_merged.title == \"pinocchio\").show()\n",
    "DFloans_merged_nosinglewordtitles = DFloans_merged.filter(DFloans_merged.title.contains(\" \")) \n",
    "# DFloans_merged_nosinglewordtitles.filter(DFloans_merged_nosinglewordtitles.title == \"pinocchio\").show()\n",
    "\n",
    "# Assign to books with the same title, the same book_id\n",
    "DFloans_merged_aggregated = DFloans_merged_nosinglewordtitles.select(\"*\", \\\n",
    "                                                                     F.first(DFloans_merged_nosinglewordtitles.item_id)\\\n",
    "                                                                      .over(Window.partitionBy(DFloans_merged_nosinglewordtitles.title).orderBy(DFloans_merged_nosinglewordtitles.data_type))\\\n",
    "                                                                      .alias(\"book_id\"))\\\n",
    "                                                              .drop(\"item_id\")\n",
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "# |               title|          sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|          publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|          author|person_id|item_review|book_id|\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "# |come mi batte for...|storia di mio padre|8806198882|4.14122681883024|         206|           270|       302|      2009-11-03|Einaudi (Frontiere)|Hardcover|      1|           1|        705|01500978c278d06718|Crime / Teens / N...|   anobii|Benedetta Tobagi|   767565|          3|2806310|\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "\n",
    "# Assign to books with the same title, the same new_author\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.author)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_author\"))\n",
    "\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "\n",
    "# Assign to books with the same title, the same new_genre\n",
    "#DFloans_merged_aggregated.show(1, False)\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.first(DFloans_merged_aggregated.genre_with_votes)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id).orderBy(DFloans_merged_aggregated.data_type))\\\n",
    "                                                              .alias(\"new_genre\"))\n",
    "\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "\n",
    "# Assign to books with the same title, the same new_encrypt\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.encrypt_item_id)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_encrypt_item_id\"))\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# Assign to books with the same title, the same new_isbn\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.isbn)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_isbn\"))\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# Update metrics of loans: new_total_count (to count the number of votes or loans) \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.count(\"*\")\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_total_count\"))\n",
    "\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# Update metrics of loans: new_average_rating \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.avg(DFloans_merged_aggregated.item_review)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_average_rating\"))\n",
    "\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# Update metrics of loans: new_total_review, to count the actual number of review for a book (only anobii provides real review!!) \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.max(DFloans_merged_aggregated.total_review)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_total_review\"))\n",
    "\n",
    "#DFinfo = DFloans_merged_aggregated\n",
    "#DFinfo.filter((DFinfo.item_review != 0) & (DFinfo.item_review != 1) & (DFinfo.item_review != 2) & (DFinfo.item_review != 3) & (DFinfo.item_review != 4) & (DFinfo.item_review != 5)).show(20, False)\n",
    "# Remove \"old\" attributes\n",
    "columnsToDrop = ['author',\n",
    "                 'genre_with_votes',\n",
    "                 'encrypt_item_id',\n",
    "                 'isbn',\n",
    "                 'total_count',\n",
    "                 'average_rating',\n",
    "                 'total_review',]\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.drop(*columnsToDrop)\n",
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "# |            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|person_id|item_review|book_id|new_author|           new_genre|new_encrypt_item_id|  new_isbn|new_total_count|new_average_rating|new_total_review|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "# |giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|   959028|          3|1981748|Pulsatilla|Philosophy / Hist...| 014f24ec9629744c88|8845260372|            543|3.1860036832412524|             129|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "\n",
    "# Rename \"new\" attributes\n",
    "columnsToRenames = ['new_author',\n",
    "                    'new_genre',\n",
    "                    'new_encrypt_item_id',\n",
    "                    'new_isbn',\n",
    "                    'new_total_count',\n",
    "                    'new_average_rating',\n",
    "                    'new_total_review',]\n",
    "for c in columnsToRenames:\n",
    "    DFloans_merged_aggregated = DFloans_merged_aggregated.withColumnRenamed(c, c.replace(\"new_\", \"\"))\n",
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "# |            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|person_id|item_review|book_id|    author|               genre|   encrypt_item_id|      isbn|total_count|    average_rating|total_review|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "# |giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|   273238|          4|1981748|Pulsatilla|Humor / Philosoph...|014f24ec9629744c88|8845260372|        543|3.1860036832412524|         129|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "\n",
    "# Remove ['book_id', 'person_id'] duplicates\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.dropDuplicates(['book_id', 'person_id'])\n",
    "print(\"Data has been merged\")\n",
    "# before write data on file, create index for both users and books of the sparce matrix\n",
    "#RDDmerged_almost_definitive = DFloans_merged_aggregated.rdd\n",
    "\n",
    "# functions which creates the dictionary where the key is the book_id/person_id and the value is the corresponding index\n",
    "#book_dictionary = create_book_dictionary(RDDmerged_almost_definitive)\n",
    "#user_dictionary = create_user_dictionary(RDDmerged_almost_definitive)\n",
    "\n",
    "# add the user_index and the book_index in the dataframe\n",
    "#RDDdefinitive = RDDmerged_almost_definitive.map(addRowColumnId)\n",
    "if False:\n",
    "    DFloans_merged_aggregated = RDDmerged_almost_definitive.toDF(['book_id',\n",
    "                                                    'title',\n",
    "                                                    'sub_title',\n",
    "                                                    'total_wishlist',\n",
    "                                                    'no_of_page',\n",
    "                                                    'publication_date',\n",
    "                                                    'publisher',\n",
    "                                                    'binding',\n",
    "                                                    'edition',\n",
    "                                                    'product_type',\n",
    "                                                    'total_votes',\n",
    "                                                    'data_type',\n",
    "                                                    'person_id',\n",
    "                                                    'item_review',\n",
    "                                                    'author',\n",
    "                                                    'genre',\n",
    "                                                    'encrypt_item_id',\n",
    "                                                    'isbn',\n",
    "                                                    'total_count',\n",
    "                                                    'average_rating',\n",
    "                                                    'total_review'] , sampleRatio=0.9)\n",
    "                                                    #'user_index', \n",
    "                                                    #'book_index'], sampleRatio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edece73-9973-4c9c-beed-ad7c41dbff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATION RATINGS CSV FILES CELL\n",
    "\n",
    "ratings = DFloans_merged_aggregated.filter(~(DFloans_merged_aggregated.genre.isNull()))\n",
    "\n",
    "# in the rating table, each row is given by \"person_id\", \"book_id\", \"rating\" attributes\n",
    "ratings_tocsv = ratings.select([\"person_id\", \"book_id\", \"item_review\"])\\\n",
    "                       .withColumnRenamed(\"item_review\", \"rating\")\n",
    "# ratings_tocsv.show(1)\n",
    "# ratings_tocsv:\n",
    "# +---------+-------+------+\n",
    "# |person_id|book_id|rating|\n",
    "# +---------+-------+------+\n",
    "# |   100489|1981748|     3|\n",
    "# +---------+-------+------+\n",
    "print('Creating CSV files of ratings...')\n",
    "print(\"There are \"+str(ratings_tocsv.count())+\" interactions\")\n",
    "ratings_tocsv.toPandas().to_csv(\"2_explicit_ratings.csv\")\n",
    "ratings_tocsv = ratings_tocsv.drop(\"rating\")\n",
    "print(\"There are \"+str(ratings_tocsv.count())+\" interactions\")\n",
    "ratings_tocsv.toPandas().to_csv(\"2_implicit_ratings.csv\")\n",
    "# in the book table, the metadata about the book are reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954c765-6d94-4df2-ba1e-c84126e5d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATION USERS CSV FILES CELL (+ DESCRIPTIONS HANDLING)\n",
    "\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "# |book_id|            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|    author|               genre|   encrypt_item_id|      isbn|total_count|    average_rating|total_review|book_index|\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "# |1981748|giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|Pulsatilla|Family-Sex&Relati...|014f24ec9629744c88|8845260372|        543|3.1860036832412524|         129|       319|\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "books_tocsv = ratings.dropDuplicates(['book_id'])\\\n",
    "                     .drop(\"person_id\")\\\n",
    "                     #.drop(\"user_index\")\\\n",
    "                     #.drop(\"item_review\")\n",
    "\n",
    "#print(books_tocsv.count())\n",
    "\n",
    "file = \"anobii_genres/content.csv\"\n",
    "DFdescriptions = spark.read.csv(file, header=True)\n",
    "#DFdescriptions.show(1, False)\n",
    "DFdescriptions = DFdescriptions.dropDuplicates([\"item_id\"])\n",
    "#DFdescriptions.filter(F.size(F.split('content', ' ')) <= 5).show(20, False)\n",
    "DFdescriptions = DFdescriptions.filter(F.size(F.split('content', ' ')) >= 50)\n",
    "\n",
    "\n",
    "#DFdescriptions.filter(DFdescriptions.item_id==\"2015441\").show(2, False)\n",
    "print(\"There are \"+str(books_tocsv.count())+\" books\")\n",
    "#books_tocsv = books_tocsv.join(DFdescriptions, DFdescriptions.item_id == books_tocsv.book_id).select(\"book_id\", \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"book_index\", \"content\")\n",
    "books_tocsv = books_tocsv.join(DFdescriptions, DFdescriptions.item_id == books_tocsv.book_id).select(\"book_id\", \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"content\")\n",
    "\n",
    "books_tocsv = books_tocsv.withColumn(\"content2\", books_tocsv[\"content\"])\n",
    "print(books_tocsv.select(\"book_id\").distinct().count())\n",
    "\n",
    "RDDbooks_tocsv = books_tocsv.rdd\n",
    "RDDbooks_tocsv = RDDbooks_tocsv.map(lambda x: (x.book_id, x))\n",
    "RDDreducedbooks = RDDbooks_tocsv.reduceByKey(concatenateContentsDescriptions)\n",
    "RDDreducedbooks = RDDreducedbooks.map(toSingleDescriptions)\n",
    "books_tocsv = RDDreducedbooks.toDF([])\n",
    "#print(books_tocsv.count())\n",
    "\n",
    "#Joiniamo DFreviews a books_tocsv (la cardinalità aumenterà ma con una funzione di riduzione con gli RDD dovremmo riportarla alla normalità)\n",
    "#books_tocsv = books_tocsv.join(DFreviews, books_tocsv.book_id == DFreviews.item_id, \"left\").select(books_tocsv.book_id, \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"book_index\", \"content\", \"comment_content\", \"content2\")\n",
    "\n",
    "books_tocsv = books_tocsv.join(DFreviews, books_tocsv.book_id == DFreviews.item_id, \"left\").select(books_tocsv.book_id, \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"content\", \"comment_content\", \"content2\")\n",
    "\n",
    "#Fatto ciò,  trasformiamo books_tocsv in un rdd per poter applicare la funzione di concatenazione\n",
    "#print(books_tocsv.select(\"book_id\").distinct().count())\n",
    "\n",
    "RDDbooks = books_tocsv.rdd\n",
    "RDDbooks = RDDbooks.map(lambda x: (x.book_id, x))\n",
    "RDDreducedbooks = RDDbooks.reduceByKey(concatenateContentsComments)\n",
    "RDDreducedbooks = RDDreducedbooks.map(toSingleComments)\n",
    "RDDreducedbooks = RDDreducedbooks.map(mergeDescriptionComments)\n",
    "books_tocsv = RDDreducedbooks.toDF([])\n",
    "\n",
    "#print(books_tocsv.count())\n",
    "\n",
    "# in the user table, the person_id is reported for each user (in each row)\n",
    "users_tocsv = ratings.select(\"person_id\").dropDuplicates()\n",
    "\n",
    "# users_tocsv:\n",
    "# +---------+----------+\n",
    "# |person_id|user_index|\n",
    "# +---------+----------+\n",
    "# |  1224803|     10623|\n",
    "# +---------+----------+\n",
    "print(\"There are \"+str(users_tocsv.count())+\" users\")\n",
    "users_tocsv.toPandas().to_csv(\"2_users.csv\")\n",
    "\n",
    "print(\"Csv users files have been written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757b2cbf-80d0-458d-8a6b-5c2715e49cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNUSED: LEXICON LIWC BASED SENTIMENT ANALYSIS (MAYBE IN THE FUTURE..?)\n",
    "\n",
    "#BLOCCO SENTIMENT ANALYSIS --- LIWC \n",
    "#Usando un gestore di file .dic cerco di estrarre tramite una funzione delle etichette per il testo\n",
    "#import liwc\n",
    "\n",
    "books_pandas = books_tocsv.toPandas()\n",
    "books_pandas = books_pandas.dropna(subset=['content2'])\n",
    "\n",
    "content_list = books_pandas['content2'].to_list()   \n",
    "parse, category_names = liwc.load_token_parser('Italian_LIWC2007_Dictionary.dic')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    # you may want to use a smarter tokenizer\n",
    "    tokenizer = word_tokenize(text)\n",
    "    return tokenizer\n",
    "\n",
    "useful_keywords = ['Parolac', 'Sesso', 'Morte', 'Emo_Pos', 'Emo_Neg', 'Ansia', 'Rabbia', 'Tristez', 'Sentim', 'Svago', 'Sen_Pos', 'Sen_Neg']\n",
    "\n",
    "def manage_liwc(counts):\n",
    "    output_labels_sentim = {'ansia': 0, 'rabbia': 0, 'tristezza': 0, 'divertimento': 0}\n",
    "    adult_themes_flag = False\n",
    "    output_labels_mood = {'negativo': 0, 'positivo': 0}\n",
    "    for key in counts:\n",
    "        #BAD VIBES\n",
    "        if key == 'Emo_Neg' or key == 'Sen_Neg':\n",
    "            output_labels_mood['negativo'] += counts[key]\n",
    "            if False:\n",
    "                if 'Ansia' in gettysburg_counts.keys():\n",
    "                    output_labels_sentim['ansia'] += counts[key]\n",
    "                if 'Rabbia' in gettysburg_counts.keys():\n",
    "                    output_labels_sentim['rabbia'] += counts[key]\n",
    "                if 'Tristez' in gettysburg_counts.keys():\n",
    "                    output_labels_sentim['tristezza'] += counts[key]\n",
    "        if key == 'Morte':\n",
    "            output_labels_mood['negativo'] += counts[key]\n",
    "            adult_themes_flag = True\n",
    "            #output_labels_sentim['strong_count'] += gettysburg_counts[key]\n",
    "            if False:\n",
    "                if 'Ansia' in counts.keys():\n",
    "                    output_labels_sentim['ansia'] += counts[key]\n",
    "                if 'Rabbia' in gettysburg_counts.keys():\n",
    "                    output_labels_sentim['rabbia'] += counts[key]\n",
    "                if 'Tristez' in gettysburg_counts.keys():\n",
    "                    output_labels_sentim['tristezza'] += counts[key]\n",
    "\n",
    "        #ADULT THEMES\n",
    "        if key == 'Parolac':\n",
    "            #output_labels_sentim['strong_count'] += gettysburg_counts[key]\n",
    "            adult_themes_flag = True\n",
    "        if key == 'Sesso':\n",
    "            #output_labels_sentim['strong_count'] += gettysburg_counts[key]\n",
    "            adult_themes_flag = True\n",
    "            #output_labels_sentim['love_count'] += gettysburg_counts[key]\n",
    "        if key == 'Ansia':\n",
    "            output_labels_mood['negativo'] += counts[key]\n",
    "            output_labels_sentim['ansia'] += counts[key]\n",
    "        if key == 'Rabbia':\n",
    "            output_labels_mood['negativo'] += counts[key]\n",
    "            output_labels_sentim['rabbia'] += counts[key]\n",
    "        if key == 'Tristez':\n",
    "            output_labels_mood['negativo'] += counts[key]\n",
    "            output_labels_sentim['tristezza'] += counts[key]\n",
    "\n",
    "        #GOOD VIBES#\n",
    "        if key == 'Emo_Pos' or key == 'Sen_Pos':\n",
    "            output_labels_mood['positivo'] += counts[key]\n",
    "            if False:\n",
    "                if 'Svago' in counts.keys():\n",
    "                    output_labels_sentim['divertimento'] += counts[key]\n",
    "                if 'Affett' in counts.keys():\n",
    "                    output_labels_sentim['amore'] += counts[key]\n",
    "                if 'Social' in counts.keys():\n",
    "                    output_labels_sentim['socialità'] += counts[key]\n",
    "        if key == 'Svago':\n",
    "            output_labels_mood['positivo'] += counts[key]\n",
    "            output_labels_sentim['divertimento'] += counts[key]\n",
    "        if key == 'Affett':\n",
    "            output_labels_mood['positivo'] += counts[key]\n",
    "            output_labels_sentim['amore'] += counts[key]\n",
    "        if key == 'Social':\n",
    "            output_labels_mood['positivo'] += counts[key]\n",
    "            output_labels_sentim['socialità'] += counts[key]\n",
    "\n",
    "        #SENTIMENTS\n",
    "        if key == 'Sentim':\n",
    "            if 'Ansia' in counts.keys():\n",
    "                output_labels_sentim['ansia'] += counts[key]\n",
    "            if 'Rabbia' in counts.keys():\n",
    "                output_labels_sentim['rabbia'] += counts[key]\n",
    "            if 'Tristez' in counts.keys():\n",
    "                output_labels_sentim['tristezza'] += counts[key]\n",
    "            if 'Svago' in counts.keys():\n",
    "                output_labels_sentim['divertimento'] += counts[key]\n",
    "            if 'Affett' in counts.keys():\n",
    "                output_labels_sentim['amore'] += counts[key]\n",
    "            if 'Social' in counts.keys():\n",
    "                output_labels_sentim['socialità'] += counts[key]\n",
    "    \n",
    "    max_value_sentim = max(output_labels_sentim.values())\n",
    "    max_value_mood = max(output_labels_mood.values())\n",
    "    if adult_themes_flag == True:\n",
    "        if max_value_sentim != 0 and max_value_mood != 0:\n",
    "            return (max(output_labels_sentim, key=output_labels_sentim.get), max(output_labels_mood, key=output_labels_mood.get), True)\n",
    "        elif max_value_sentim == 0 and max_value_mood != 0:\n",
    "            return (None, max(output_labels_mood, key=output_labels_mood.get), True)\n",
    "        elif max_value_sentim != 0 and max_value_mood == 0:\n",
    "            return (max(output_labels_sentim, key=output_labels_sentim.get), None, True)\n",
    "        else:\n",
    "            return (None, None, True)\n",
    "    if max_value_sentim != 0 and max_value_mood != 0:\n",
    "            return (max(output_labels_sentim, key=output_labels_sentim.get), max(output_labels_mood, key=output_labels_mood.get), False)\n",
    "    elif max_value_sentim == 0 and max_value_mood != 0:\n",
    "        return (None, max(output_labels_mood, key=output_labels_mood.get), False)\n",
    "    elif max_value_sentim != 0 and max_value_mood == 0:\n",
    "        return (max(output_labels_sentim, key=output_labels_sentim.get), None, False)\n",
    "    else:\n",
    "        return (None, None, False)\n",
    "        \n",
    "output_list = []\n",
    "\n",
    "for index, text in enumerate(content_list):\n",
    "    #print(index)\n",
    "    lexicon_dict = Counter(category for token in tokenize(text) for category in parse(token) if category in useful_keywords)\n",
    "    output = manage_liwc(lexicon_dict)\n",
    "    output_list.append(output)\n",
    "\n",
    "#print(len(output_list))\n",
    "books_pandas['liwc_labels'] = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da2baa-8598-4d30-944f-92b3247c9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE BOOKS CSV FILE\n",
    "books_pandas = books_tocsv.toPandas()\n",
    "books_pandas.to_csv(\"drive_books_filtered.csv\")\n",
    "print('CSV books file was created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
