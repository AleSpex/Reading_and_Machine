{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b30ca8-ba51-4a4a-9053-7464602a12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVAL MODEL CELL\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "class UsersBooksModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, embedding_dimension, layers = None):\n",
    "    super().__init__()\n",
    "    self.embedding_dimension = embedding_dimension\n",
    "    self.layers_size = layers\n",
    "    #Embedding per utenti\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      #tf.keras.layers.Input(),\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=users_vocabulary_2, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(users_vocabulary_2) + 1, self.embedding_dimension),\n",
    "      #tf.keras.layers.Dense(32, activation='relu')\n",
    "    ])\n",
    "    \n",
    "    #Embedding per i libri\n",
    "    self.book_embeddings = tf.keras.Sequential([\n",
    "      #tf.keras.layers.Input(),\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=titles_vocabulary_2, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(titles_vocabulary_2) + 1, self.embedding_dimension),\n",
    "      #tf.keras.layers.Dense(32, activation='relu')\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "      metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=\n",
    "            TFdata_books_titles.batch(128).cache().map(self.book_embeddings)\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    if layers != None:\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        for layer_size in layers[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layers[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    if self.layers_size == None:\n",
    "        user_embeddings = self.user_embeddings(features['person_id'])\n",
    "        book_embeddings = self.book_embeddings(features['title'])\n",
    "    else:\n",
    "        user_embeddings = self.dense_layers(self.user_embeddings(features['person_id']))\n",
    "        book_embeddings = self.dense_layers(self.book_embeddings(features['title']))\n",
    "        \n",
    "    return self.task(user_embeddings, book_embeddings, compute_metrics = not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35996a77-bfd1-486b-a30c-80b4dfe3eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UsersBooksModel(128, None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 4:\n",
    "    return 0.1\n",
    "  elif epoch >= 4:\n",
    "    return 0.001\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "history = model.fit(cached_train, validation_data = cached_val, epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47537e-ef0d-4c80-a76b-983f7411c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATION LOSS PLOT\n",
    "\n",
    "#FOR CUSTOM SERVING \n",
    "mapping = ['Comics&GraphicNovels', #0\n",
    "              'Family-Sex&Relationships',#1\n",
    "              'Humor',#2\n",
    "              'History',#3\n",
    "              'ScienceFiction&Fantasy',#4\n",
    "              'Romance',#5\n",
    "              'Travel',#6\n",
    "              'Mystery&Thrillers',#7\n",
    "              'FreeTime',#8\n",
    "              'Non-fiction',#9\n",
    "              'Biography',#10\n",
    "              'SocialScience',#11\n",
    "              'Political',#12\n",
    "              'Crime',#13\n",
    "              'Children&Teens',#14\n",
    "              'Philosophy',#15\n",
    "              'Horror',#16\n",
    "              'Health-Mind&Body',#17\n",
    "              'Professional&Technical',#18\n",
    "              'Science&Nature']#19\n",
    "              #'Fiction&Literature']\n",
    "    \n",
    "sub_df_books = []\n",
    "sub_tensors = []\n",
    "sub_titles = []\n",
    "\n",
    "for genre in mapping:\n",
    "    sub_df_books.append(df_books[df_books['genre_string'].str.contains(genre)])\n",
    "sub_df_books.append(df_books) #ALL GENRES\n",
    "\n",
    "for dataframe in sub_df_books:\n",
    "    sub_tensors.append(tf.data.Dataset.from_tensor_slices(dict(dataframe)))\n",
    "    \n",
    "for tensor in sub_tensors:\n",
    "    sub_titles.append(tensor.map(lambda x: x[\"title\"]))\n",
    "\n",
    "retrieving_layers = []\n",
    "\n",
    "for GENRE in range(0,21):\n",
    "    if GENRE != 20:\n",
    "        retrieving = tfrs.layers.factorized_top_k.BruteForce(model.user_embeddings)\n",
    "        retrieving.index_from_dataset(\n",
    "            sub_titles[GENRE].batch(8192).map(lambda title: (title, model.book_embeddings(title)))\n",
    "        )\n",
    "    else:\n",
    "        retrieving = tfrs.layers.factorized_top_k.BruteForce(model.user_embeddings)\n",
    "        retrieving.index_from_dataset(\n",
    "            TFdata_books_titles.batch(8192).map(lambda title: (title, model.book_embeddings(title)))\n",
    "        )\n",
    "    retrieving_layers.append(retrieving)\n",
    "\n",
    "#EVALUATION LOSS PLOT\n",
    "\n",
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "emb_loss_128 = [69484.21875, 66804.921875, 64446.19921875, 64028.34375, 64608.6640625, 65709.34375, 66901.25, 67988.7109375, 69031.4140625, 69966.8515625]\n",
    "emb_loss_64 = [69572.15625, 67922.671875, 65706.921875, 64586.23046875, 64244.6328125, 64476.9296875, 64981.9765625, 65678.109375, 66410.140625, 67183.578125]\n",
    "emb_loss_32 = [69612.9453125, 68702.1171875, 67113.0703125, 65801.546875, 65081.4375, 64724.9765625, 64697.08984375, 64843.30078125, 65141.2578125, 65502.36328125]\n",
    "emb_loss_16 = [69630.8515625, 69143.359375, 68086.0859375, 67019.71875, 66199.34375, 65673.71875, 65350.4296875, 65205.1484375, 65166.53125, 65222.36328125]\n",
    "emb_loss_8 = [69641.9140625, 69399.5625, 68796.65625, 68078.546875, 67451.28125, 66971.3671875, 66613.1328125, 66364.5625, 66187.71875, 66077.7265625]\n",
    "emb_loss_4 = [69649.796875, 69517.9375, 69161.84375, 68712.828125, 68285.4296875, 67933.5, 67644.59375, 67427.9765625, 67249.625, 67120.34375]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation log loss\")\n",
    "plt.plot(epochs, emb_loss_128, label = \"embedding dim. 128\")\n",
    "plt.plot(epochs, emb_loss_64, label = \"embedding dim. 64\")\n",
    "plt.plot(epochs, emb_loss_32, label = \"embedding dim. 32\")\n",
    "plt.plot(epochs, emb_loss_16, label = \"embedding dim. 16\")\n",
    "plt.plot(epochs, emb_loss_8, label = \"embedding dim. 8\")\n",
    "plt.plot(epochs, emb_loss_4, label = \"embedding dim. 4\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f3be5-e7b3-4c39-a912-a1027d832509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATION OF USER FEATURE (FAVOURITE GENRE OF USER)\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "interactions_train = df_train.to_records(index=False)\n",
    "\n",
    "#Creiamo un dizionario con le interazioni per utente (TRAIN). In questo caso abbiamo bisogno anche dei generi.\n",
    "interactions_per_user_train = {}\n",
    "for index, interaction in enumerate(interactions_train):\n",
    "    if interaction[0] not in interactions_per_user_train.keys():\n",
    "        interactions_per_user_train[interaction[0]] = []\n",
    "        \n",
    "    for genre in eval(interaction[13]).keys():     \n",
    "        interactions_per_user_train[interaction[0]].append(genre)\n",
    "\n",
    "for user in interactions_per_user_train.keys():\n",
    "    interactions_per_user_train[user] = most_common(interactions_per_user_train[user]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149e860-9cff-47ad-b58c-e2fedf9c3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_users = df_train['person_id'].unique().tolist()\n",
    "retrieving = tfrs.layers.factorized_top_k.BruteForce(model.user_embeddings, k=20)\n",
    "retrieving.index_from_dataset(\n",
    "        TFdata_books_titles.batch(8192).map(lambda title: (title, model.book_embeddings(title)))\n",
    "    )\n",
    "users = []\n",
    "recomms = []\n",
    "user_genre_counter = {}\n",
    "\n",
    "mapping = {'Comics&GraphicNovels': 0,\n",
    "              'Family-Sex&Relationships': 1,\n",
    "              'Humor': 2,\n",
    "              'History': 3,\n",
    "              'ScienceFiction&Fantasy': 4,\n",
    "              'Romance': 5,\n",
    "              'Travel': 6,\n",
    "              'Mystery&Thrillers': 7,\n",
    "              'FreeTime': 8,\n",
    "              'Non-fiction': 9,\n",
    "              'Biography': 10,\n",
    "              'SocialScience': 11,\n",
    "              'Political': 12,\n",
    "              'Crime': 13,\n",
    "              'Children&Teens': 14,\n",
    "              'Philosophy': 15,\n",
    "              'Horror': 16,\n",
    "              'Health-Mind&Body': 17,\n",
    "              'Professional&Technical': 18,\n",
    "              'Science&Nature': 19}\n",
    "\n",
    "#RETRIEVAL AVG HIT USERS AND RECOMM. (CUSTOM OR NORMAL SERVING)\n",
    "for index, user in enumerate(list_users):\n",
    "    user_flag = 0\n",
    "    recomms_count = 0\n",
    "    if index % 10000 == 0:\n",
    "        print(index)\n",
    "        \n",
    "    if False:\n",
    "        #Favourite user genre\n",
    "        favourite_genre = interactions_per_user_train[user]\n",
    "\n",
    "        _, titles_1 = retrieving_layers[mapping[favourite_genre]](tf.constant([user]), k=10)\n",
    "        _, titles_2 = retrieving_layers[20](tf.constant([user]), k=20)\n",
    "\n",
    "        titles_decoded = [item.decode() for item in titles_1[0].numpy()]\n",
    "        for title in titles_2[0].numpy():\n",
    "            title = title.decode('utf-8')\n",
    "            #print(title)\n",
    "            if title not in titles_decoded:\n",
    "                titles_decoded.append(title)\n",
    "        titles_decoded = np.asarray(titles_decoded)\n",
    "    #print(titles_decoded)\n",
    "    \n",
    "    _, titles = retrieving(tf.constant([user]), k=20)\n",
    "    titles_decoded = np.asarray([item.decode() for item in titles[0].numpy()])\n",
    "    #print(titles_decoded)\n",
    "    \n",
    "    user_read_books = np.asarray(df_test[df_test['person_id'] == user].title.to_list())\n",
    "    #user_genres = np.asarray(df_test[df_test['person_id'] == user].genre.to_list())\n",
    "    \n",
    "    if user_read_books.size == 0:\n",
    "        continue\n",
    "    #print(user_read_books)\n",
    "    intersection = np.intersect1d(titles_decoded, user_read_books)\n",
    "    #print(intersection.size)\n",
    "    #print(intersection)\n",
    "    if intersection.size != 0:\n",
    "        user_flag = 1\n",
    "        recomms_count += intersection.size\n",
    "        \n",
    "        #Genres\n",
    "        for intersect in intersection:\n",
    "            genre_dict = df_test[df_test['title'] == intersect].genre.to_list()[0]\n",
    "            #print(genre_dict)\n",
    "            for genre in eval(genre_dict).keys():\n",
    "                #print(genre)\n",
    "                if genre in user_genre_counter.keys():\n",
    "                    user_genre_counter[genre] += 1\n",
    "                else:\n",
    "                    user_genre_counter[genre] = 1\n",
    "                #print(user_genre_counter)\n",
    "    users.append(user_flag)\n",
    "    recomms.append(recomms_count)\n",
    "    #print(users)\n",
    "print(np.mean(np.asarray(users)), np.mean(np.asarray(recomms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db473f6-d7d3-442f-9a1f-03b9defe8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVG RANK RETRIEVAL\n",
    "avg_rank = []\n",
    "for index, user in enumerate(list_users):\n",
    "    if index % 10000 == 0:\n",
    "        print(index)\n",
    "        \n",
    "    if False:\n",
    "        #Favourite user genre\n",
    "        favourite_genre = interactions_per_user_train[user]\n",
    "\n",
    "        _, titles_1 = retrieving_layers[mapping[favourite_genre]](tf.constant([user]), k=10)\n",
    "        _, titles_2 = retrieving_layers[20](tf.constant([user]), k=20)\n",
    "\n",
    "        titles_decoded = [item.decode() for item in titles_1[0].numpy()]\n",
    "        for title in titles_2[0].numpy():\n",
    "            title = title.decode('utf-8')\n",
    "            #print(title)\n",
    "            if title not in titles_decoded:\n",
    "                titles_decoded.append(title)\n",
    "        titles_decoded = np.asarray(titles_decoded)\n",
    "    #print(titles_decoded)\n",
    "    \n",
    "    _, titles = retrieving(tf.constant([user]), k=df_books.shape[0])\n",
    "    titles_decoded = np.asarray([item.decode() for item in titles[0].numpy()])\n",
    "    #print(titles_decoded)\n",
    "    \n",
    "    user_read_books = np.asarray(df_test[df_test['person_id'] == user].title.to_list())\n",
    "    #user_genres = np.asarray(df_test[df_test['person_id'] == user].genre.to_list())\n",
    "    \n",
    "    if user_read_books.size != 0:\n",
    "        ranks = np.where(np.in1d(titles_decoded, user_read_books))\n",
    "        #print(ranks)\n",
    "        ranks_min = np.amin(ranks)\n",
    "        avg_rank.append(ranks_min)\n",
    "print(np.mean(np.asarray(avg_rank)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724463bb-f334-4ef4-a976-77cd7fe7ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIT GENRES\n",
    "\n",
    "dict_plot = {'Mystery&Thrillers': 7387, 'Children&Teens': 1831, 'ScienceFiction&Fantasy': 5401, 'Humor': 1868, 'History': 2579, 'Crime': 3218, 'FreeTime': 2402, 'Family-Sex&Relationships': 4751, 'Romance': 3430, 'Non-fiction': 1093, 'Professional&Technical': 750, 'Philosophy': 1001, 'Political': 520, 'Science&Nature': 349, 'Biography': 746, 'Travel': 1703, 'Horror': 1052, 'SocialScience': 419, 'Health-Mind&Body': 777, 'Comics&GraphicNovels': 519}\n",
    "\n",
    "names = dict_plot.keys()\n",
    "values = dict_plot.values()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(names, values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Number of hit books')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
