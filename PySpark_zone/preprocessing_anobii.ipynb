{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE CON I MIEI TENTATIVI DI PREPROCESSING SUL DATABASE DI ANOBii\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "file = \"/data/SMARTDATA/books/anobii/author_item.csv\"\n",
    "DFauthorbooks = spark.read.csv(file,header=True) #MOSTRA I LIBRI RELATIVI AGLI AUTORI\n",
    "#DFauthorbooks.show()\n",
    "\n",
    "#LIBRI DEGLI AUTORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "looking-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/data/SMARTDATA/books/anobii/author_display.csv\"\n",
    "DFdisplay = spark.read.csv(file,header=True) #MOSTRA GLI AUTORI DEL DATABASE\n",
    "#DFdisplay.show()\n",
    "\n",
    "#AUTORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quanto pare author_display è una tabella contenente tutti gli autori del database di anobii mentre author_items\n",
    "#contiene i diversi libri associati ad ogni autore. \n",
    "#DUBBIO: cosa è author original? Cerchiamo una tupla in cui author_original NON è NULL:\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item.csv\"\n",
    "DFitems = spark.read.csv(file,header=True) #MOSTRA I LIBRI DEL DATABASE\n",
    "#DFitems.show()\n",
    "\n",
    "DFitemsauthor = DFitems.join(DFauthorbooks, DFitems.item_id == DFauthorbooks.item_id)\n",
    "#DFitemsauthor.filter(DFitemsauthor.author_id_original != \"null\").show(20, False)\n",
    "\n",
    "#AUTHOR: JOHN FOWLES\n",
    "#DFdisplay.filter(DFdisplay.author_id == \"360704\").show(20, False)\n",
    "#DFdisplay.filter(DFdisplay.author_id_original == \"72565\").show(20, False)\n",
    "\n",
    "#IPOTESI: Sembra che author_id_original sia semplicemente l'id di un vecchio database non a nostra disposizione\n",
    "#dato che non è un autore (author_id) presente in questo DB\n",
    "\n",
    "#Possiamo anche notare come language sia il linguaggio del libro mentre language_correct sia il linguaggio del\n",
    "#libro originale (notare la tupla item_id 1002883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welcome-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/data/SMARTDATA/books/anobii/language_mapping.csv\"\n",
    "DFlanguages = spark.read.csv(file,header=True)\n",
    "#DFlanguages.show()\n",
    "\n",
    "#Dobbiamo tenere solo i libri con language=11 #FILTRO LINGUAGGIO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rural-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/data/SMARTDATA/books/anobii/item_recommend.csv\"\n",
    "DFrecommends = spark.read.csv(file,header=True)\n",
    "#DFrecommends.show(50, False)\n",
    "\n",
    "#Questa tabella contiene gli ISBN riferiti all'item Id (quindi item_id non è unico?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "perfect-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per coerenza, procediamo a un filtraggio equivalente a quello fatto per le biblioteche:\n",
    "#FILTRAGGI BASE\n",
    "\n",
    "#FILTRAGGIO 1: solo libri italiani (filtrare language==11)\n",
    "#FILTRAGGIO 2: solo monografie e manoscritti (questo a dire il vero è fattibile in maniera un po' diversa dal caso\n",
    "#delle biblioteche poiché l'attributo \"binding\" indica la rilegatura del libro). Per iniziare, considererò\n",
    "#\"paperback\" (copertina flessibile) e \"hardcover\" (copertina rigida) NOTA: probabilmente ulteriori scremature\n",
    "#da questo punto di vista saranno possibili\n",
    "#FILTRAGGIO 3: eliminare fumetti e magazine (non sono sicuro della loro presenza, controllo)\n",
    "#UPDATE: non solo ci sono ma sono pure tantissimi! Filtraggio doveroso\n",
    "\n",
    "#DFitems.filter(DFitems.title.contains(\"Topolino\")).show(20, False)\n",
    "\n",
    "#FILTRAGGI AVANZATI\n",
    "\n",
    "#FILTRAGGIO 4: Libri con più di 50 voti (Dove prendere i voti?) In item_comment_vote ci sono i commenti ai libri\n",
    "#fatti da vari utenti. Tuttavia, non vedo i voti. item_comment_feedback contiene i commenti veri e propri.\n",
    "#In item_comment_vote sembrano esserci due campi \"total_yes\" e \"total_no\": che siano loro i voti? (Consigliato\n",
    "#Non consigliato). UPDATE: Noto che in item_comment_vote è presente l'average rating: è già qualcosa, tuttavia\n",
    "#vorrei trovare i voti dei singoli utenti.\n",
    "\n",
    "#FILTRAGGIO 5: Pulizie eventuali, su anobii i titoli sembrano già puliti quindi è necessario semplicemente mappare\n",
    "#l'id dell'autore con il nome dell'autore.\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item_comment_vote.csv\" #MOSTRA INFORMAZIONI SUL VOTO DEGLI UTENTI\n",
    "DFvotes = spark.read.csv(file,header=True)\n",
    "#DFvotes.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item_comment_feedback.csv\" #MOSTRA IL VOTO MEDIO\n",
    "DFfeedback = spark.read.csv(file,header=True)\n",
    "#DFfeedback.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/person_item_recommend.csv\" #MOSTRA I COMMENTI DEGLI UTENTI RELATIVI A UN LIBRO\n",
    "DFcomments = spark.read.csv(file,header=True)\n",
    "#DFcomments.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/person_item_progress.csv\" #MOSTRA INFORMAZIONI SULLE RACCOMANDAZIONI\n",
    "DFprogress = spark.read.csv(file,header=True)\n",
    "#DFprogress.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item_comment.csv\" #MOSTRA INFORMAZIONI VARIE QUALI LA PRESENZA DI\n",
    "#SPOILER IN UN COMMENTO O LA PRESENZA DI PROFANITà\n",
    "DFinfo = spark.read.csv(file,header=True)\n",
    "#DFinfo.show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "appointed-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------+----------+----------------+------------+--------------+-----------+\n",
      "|item_id|title                                   |isbn      |average_rating  |total_review|total_wishlist|total_votes|\n",
      "+-------+----------------------------------------+----------+----------------+------------+--------------+-----------+\n",
      "|1785689|La solitudine dei numeri primi          |8804577029|3.36283911995487|3374        |1723          |19548      |\n",
      "|207699 |Il cacciatore di aquiloni               |8838481725|4.18403634003894|1620        |1331          |15466      |\n",
      "|219852 |L'ombra del vento                       |8804561300|4.16325420039453|2299        |1796          |14759      |\n",
      "|1513019|Harry Potter e i Doni della Morte       |8884518784|4.45385694249649|1401        |339           |14303      |\n",
      "|2328913|L'eleganza del riccio                   |8876417966|3.86156879312773|2915        |1945          |14241      |\n",
      "|622491 |Novecento                               |8807813025|4.24111260909671|1553        |869           |14132      |\n",
      "|2511667|Siddharta                               |A000181195|3.90094813963511|1122        |558           |13961      |\n",
      "|1673758|Uomini che odiano le donne              |8831793322|4.10719718197102|2180        |1096          |12531      |\n",
      "|628992 |Harry Potter e il Principe Mezzosangue  |8884516374|4.40846524432209|551         |243           |11657      |\n",
      "|194749 |1984                                    |8804507454|4.51507648775312|1267        |1209          |11364      |\n",
      "|638663 |Harry Potter e il prigioniero di Azkaban|8877828528|4.37823880331226|482         |146           |11286      |\n",
      "|638684 |Harry Potter e la camera dei segreti    |8877827033|4.16252252252252|398         |157           |11131      |\n",
      "|2720355|Harry Potter e la Pietra Filosofale     |8877827025|4.20501595987232|738         |137           |11001      |\n",
      "|640445 |La casa degli spiriti                   |880781000X|4.35345063360379|942         |735           |10997      |\n",
      "|2503123|Harry Potter e il Calice di Fuoco       |888451049X|4.38326191995624|441         |154           |10993      |\n",
      "|658477 |Il Codice da Vinci                      |8804523417|3.52362931511907|1005        |139           |10902      |\n",
      "|646445 |L'amico ritrovato                       |8807810549|4.08785529715762|820         |597           |10866      |\n",
      "|81817  |Il Piccolo Principe                     |8845205118|4.34799235181644|1034        |323           |10509      |\n",
      "|638679 |Harry Potter e l'Ordine della Fenice    |8884513448|4.35905625386359|423         |143           |9733       |\n",
      "|207696 |Gomorra                                 |8804554509|4.16211762282418|1396        |815           |9731       |\n",
      "+-------+----------------------------------------+----------+----------------+------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#INIZIAMO A FILTRARE USANDO LA ROADMAP DELLA CELLA POCO SOPRA\n",
    "\n",
    "#FILTRAGGIO 1: linguaggio italiano\n",
    "#Mi basterà filtrare da item.csv tutte le tuple con language diverso da 11.\n",
    "\n",
    "DFfilteredlanguageitems = DFitems.filter(DFitems.language == \"11\")\n",
    "#DFfilteredlanguageitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 2: solo \"hardcover\" e \"paperback\"\n",
    "\n",
    "DFfilteredbindingitems = DFfilteredlanguageitems.filter((DFfilteredlanguageitems.binding == \"Paperback\") | (DFfilteredlanguageitems.binding == \"Hardcover\"))\n",
    "#DFfilteredbindingitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 3: eliminare i fumetti (per quanto possibile)\n",
    "#Userò come parole chiave personaggi famosi Disney quali Topolino e Paperino e i fumetti Bonelli (che fra gli italiani\n",
    "#sono probabilmente i più gettonati)\n",
    "\n",
    "DFfilteredmagazineitems = DFfilteredbindingitems.filter(~(DFfilteredbindingitems.title.contains(\"Topolino\")) | (DFfilteredbindingitems.title.contains(\"Paperino\"))|(DFfilteredbindingitems.title.contains(\"Tex\"))|(DFfilteredbindingitems.title.contains(\"Dylan Dog\"))|(DFfilteredbindingitems.title.contains(\"Nathan Never\"))|(DFfilteredbindingitems.title.contains(\"Zagor\")))\n",
    "#DFfilteredmagazineitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 4: libri con più di X votes. Per vedere i voti di ogni libro dovrei usare il dataframe link_person_item.csv.\n",
    "#Come possiamo notare, alcune recensione hanno valore 0: questo non vuol dire che il libro è stato valutato\n",
    "#atrocemente ma che l'utente ha letto il libro senza inserire voti.\n",
    "\n",
    "#Dobbiamo dunque scremare tali voti da questo dataframe.\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item.csv\" #MOSTRA IL VOTO DI UN UTENTE A UN LIBRO\n",
    "DFstars = spark.read.csv(file,header=True)\n",
    "#DFstars.show(50, False)\n",
    "\n",
    "DFstarsfilteredno0 = DFstars.filter(DFstars.item_review > 0)\n",
    "#DFstarsfilteredno0.show(20,False)\n",
    "\n",
    "#Contiamo i libri con più voti e visualizziamoli in ordine discendente\n",
    "\n",
    "DFgrouped = DFstarsfilteredno0.groupby(\"item_id\").count().withColumnRenamed(\"count\",\"total_votes\").sort(\"total_votes\", ascending=False)\n",
    "#I voti dei libri più votati si aggirano intorno ai 10^4 come ordine di grandezza per cui per ora scelgo 300 come\n",
    "#soglia di voti necessaria a rimanere nel dataframe (soggetto a cambiamenti)\n",
    "DFgroupedfiltered = DFgrouped.filter(DFgrouped['total_votes'] > 300)\n",
    "DFjoinbookstars = DFfilteredmagazineitems.join(DFgroupedfiltered, DFfilteredmagazineitems.item_id == DFgroupedfiltered.item_id).drop(DFgroupedfiltered.item_id)\n",
    "\n",
    "#FILTRAGGIO 5: Pulizie varie ed eventuali\n",
    "#DFfilteredlessthan10items.filter(DFfilteredlessthan10items.total_review > 100).show()\n",
    "DFfiltered = DFjoinbookstars.select(\"item_id\", \"title\", \"isbn\", \"average_rating\", \"total_review\", \"total_wishlist\", DFjoinbookstars['total_votes'])\n",
    "DFfiltered.sort(\"total_votes\", ascending=False).show(20, False)\n",
    "#DFfiltered.count() #2516 books (maybe too few? Let's try with 300 WITH 300: 4485, seems fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electronic-screw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+\n",
      "|item_id|person_id|title            |item_review|total_review|average_rating  |total_votes|isbn      |\n",
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+\n",
      "|1981748|273238   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|198729   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|309861   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|165165   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|256302   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|275498   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|333408   |Giulietta squeenz|2          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|406900   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|40869    |Giulietta squeenz|2          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|85637    |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|413585   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|416085   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|258048   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|199579   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|497648   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|147275   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|216178   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|486515   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|499576   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|\n",
      "|1981748|485700   |Giulietta squeenz|1          |128         |3.20037105751391|544        |8845260372|\n",
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's join votes and books to get titles (not considering votes with 0)\n",
    "\n",
    "DFvoteswithtitles = DFstarsfilteredno0.join(DFfiltered, DFfiltered.item_id == DFstarsfilteredno0.item_id).select(DFstarsfilteredno0.item_id, \"person_id\", \"title\", \"item_review\", \"total_review\", \"average_rating\", \"total_votes\",\"isbn\")\n",
    "DFvoteswithtitles.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tutorial-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+----------+----------+\n",
      "|item_id|person_id|title            |item_review|total_review|average_rating  |total_votes|isbn      |user_index|book_index|\n",
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+----------+----------+\n",
      "|1981748|273238   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|56323     |395       |\n",
      "|1981748|198729   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|42795     |395       |\n",
      "|1981748|309861   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|57926     |395       |\n",
      "|1981748|165165   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|37593     |395       |\n",
      "|1981748|256302   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|53426     |395       |\n",
      "|1981748|275498   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|56681     |395       |\n",
      "|1981748|333408   |Giulietta squeenz|2          |128         |3.20037105751391|544        |8845260372|58310     |395       |\n",
      "|1981748|406900   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|59883     |395       |\n",
      "|1981748|40869    |Giulietta squeenz|2          |128         |3.20037105751391|544        |8845260372|60019     |395       |\n",
      "|1981748|85637    |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|121468    |395       |\n",
      "|1981748|413585   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|60605     |395       |\n",
      "|1981748|416085   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|61044     |395       |\n",
      "|1981748|258048   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|53650     |395       |\n",
      "|1981748|199579   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|42940     |395       |\n",
      "|1981748|497648   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|71149     |395       |\n",
      "|1981748|147275   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|30770     |395       |\n",
      "|1981748|216178   |Giulietta squeenz|3          |128         |3.20037105751391|544        |8845260372|45905     |395       |\n",
      "|1981748|486515   |Giulietta squeenz|4          |128         |3.20037105751391|544        |8845260372|69583     |395       |\n",
      "|1981748|499576   |Giulietta squeenz|5          |128         |3.20037105751391|544        |8845260372|71368     |395       |\n",
      "|1981748|485700   |Giulietta squeenz|1          |128         |3.20037105751391|544        |8845260372|69413     |395       |\n",
      "+-------+---------+-----------------+-----------+------------+----------------+-----------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from lightfm import LightFM\n",
    "from pyspark.sql.functions import row_number, lit, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "#Per ora proverò a costruire una CSR (matrice sparsa compressa) dal dataset di anobii (senza join con le biblioteche,\n",
    "#solo per testare). La CSR è costruita in modo tale da avere tre vettori numpy, uno per i dati e due per gli indici\n",
    "#riga-colonna con cui poi ricostruire la matrice originale.\n",
    "\n",
    "#Come posso passare dal dataset a questa matrice? La maniera più efficiente (ed è meglio adottarle dato le grandezze\n",
    "#dei dataset) è quella di creare la matrice direttamente, senza prima crearne una vuota da riempire.\n",
    "\n",
    "#Supposto che le righe di tale matrice siano gli utenti e le colonne siano i libri (e i dati siano per ora solo\n",
    "#i voti, poi potremo aggiungere feature per i metadati) allora posso provare ad aggiungere al mio dataframe delle \n",
    "#colonne indicanti gli indici futuri di riga colonna, usando degli id incrementali.\n",
    "\n",
    "#Proviamo. (Forse con gli RDD è meglio)\n",
    "RDDvoteswithtitles = DFvoteswithtitles.rdd.cache()\n",
    "#RDDpair = RDDvoteswithtitles.map(lambda x: (x.person_id, list(x))).sortByKey()#.collect()\n",
    "\n",
    "def create_user_dictionary(rdd): #Used to assign an integer id to each user of the rdd (to get the rows of the CSR)\n",
    "    rdd = rdd.map(lambda x: (x.person_id, list(x))).sortByKey()\n",
    "    user_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in user_dictionary.keys():\n",
    "        user_dictionary[key] = i\n",
    "        i += 1\n",
    "    return user_dictionary\n",
    "\n",
    "def create_book_dictionary(rdd): #Used to assign an integer id to each book of the rdd (to get the column of the CSR)\n",
    "    rdd = rdd.map(lambda x: (x.item_id, list(x))).sortByKey()\n",
    "    book_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in book_dictionary.keys():\n",
    "        book_dictionary[key] = i\n",
    "        i += 1\n",
    "    return book_dictionary\n",
    "\n",
    "user_dictionary = create_user_dictionary(RDDvoteswithtitles)\n",
    "book_dictionary = create_book_dictionary(RDDvoteswithtitles)\n",
    "\n",
    "def addRowColumnId(line): #Function used to add index to the dataset\n",
    "    book_number = book_dictionary[line.item_id]\n",
    "    user_number = user_dictionary[line.person_id]\n",
    "    \n",
    "    return Row(line.item_id, line.person_id, line.title, line.item_review, line.total_review, line.average_rating, str(line.total_votes), line.isbn, str(user_number), str(book_number))\n",
    "        \n",
    "RDDmapped = RDDvoteswithtitles.map(addRowColumnId)\n",
    "#print(RDDmapped.take(20))\n",
    "DFwithindexes = RDDmapped.toDF([\"item_id\", \"person_id\", \"title\", \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"user_index\", \"book_index\"])\n",
    "DFwithindexes.show(20, False)\n",
    "\n",
    "#DFwithindexes contiene i voti di ogni utente dato il libro, altre info utili e gli indici di riga e di colonna\n",
    "#della eventuale compressed sparse matrix per una facile ed efficiente creazione (per i sistemi di raccomandazione)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
