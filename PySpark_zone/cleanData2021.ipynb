{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7619a7-2674-4c33-a49e-64f5f6b353e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Anobii data\n",
      "+---------------+-------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+-----------+-----------+\n",
      "|item_content_id|item_id|source          |content                                                                                                                                                                                                      |language|preferred|provider_id|last_update|\n",
      "+---------------+-------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+-----------+-----------+\n",
      "|1427528        |2539173|Book Description|Al mercato del villaggio si possono acquistare animali di tutti i tipi. Barbabella, Barbottina e Barbalalla scelgono un maialino, un coniglio, un gallo, una gallina e due oche... Età di lettura: da 1 anno.|it      |f        |null       |null       |\n",
      "+---------------+-------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------+-----------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Raws data have been read\n",
      "Filter Anobii data (select books in italian, drop comics and books with a low number of ratings)\n"
     ]
    }
   ],
   "source": [
    "##Python .py code from .jpynb:\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import row_number, lit, dense_rank\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "#############################################\n",
    "#            read data                      # \n",
    "#############################################\n",
    "print(\"Read Anobii data\")\n",
    "\n",
    "# Read table which contains for each item_id (id of each book), the id of the author (author_id) who wrote that book\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/author_item.csv\"\n",
    "DFauthorbooks = spark.read.csv(file,header=True) #MOSTRA I LIBRI RELATIVI AGLI AUTORI\n",
    "\n",
    "# Read table which contains for each author_id (id of each auhtor), the info of that author\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/author_display.csv\"\n",
    "DFdisplay = spark.read.csv(file,header=True) #MOSTRA GLI AUTORI DEL DATABASE\n",
    "\n",
    "# Read table which contains the mapping of the language (language=11 means italian)\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/language_mapping.csv\"\n",
    "DFlanguages = spark.read.csv(file,header=True)\n",
    "\n",
    "# Read table which contains the info about items, i.e. books\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/item.csv\"\n",
    "DFitems_anobii = spark.read.csv(file,header=True) \n",
    "# DFitems_anobii.show(1, False)\n",
    "\n",
    "# Read table which contains the rate given by a person to a book\n",
    "file = \"/data/SMARTDATA/books/anobii_2021/sql/link_person_item.csv\" #item_review ha il voto dato dall'utente a quel libro\n",
    "DFinfo = spark.read.csv(file,header=True)\n",
    "# DFinfo.show(1, False)\n",
    "\n",
    "# Read table which contains the genre of each book\n",
    "file = \"anobii_genres/genres5.csv\"\n",
    "DFgenres = spark.read.csv(file, header=True)\n",
    "#DFgenres.filter(DFgenres.itemid == \"1981748\").show(10, False)\n",
    "\n",
    "file = \"anobii_genres/content.csv\"\n",
    "DFdescriptions = spark.read.csv(file, header=True)\n",
    "DFdescriptions.show(1, False)\n",
    "#FUNZIONI\n",
    "def title_and_subtitle(line): #Usata per splittare titolo e sottotitolo nel database delle biblioteche e renderli più simili ad anobii\n",
    "    if len(line.title.split(\" : \")) > 1: #Il libro possiede un sottotitolo\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, title, sub_title, line.author, 4, \"None\", 4, \"None\", line.ISBNISSN_new, \"bct\") #NE APPROFITTO ANCHE PER INSERIRE VOTO E CAMPI PER IL MERGE (PER ORA NULL)\n",
    "    else: #Il libro non possiede un sottotitolo\n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, line.title, \"None\", line.author, 4, \"None\", 4, \"None\", line.ISBNISSN_new, \"bct\")\n",
    "\n",
    "def create_user_dictionary(rdd): #Used to assign an integer id to each user of the rdd (to get the rows of the CSR)\n",
    "    rdd = rdd.map(lambda x: (str(x.person_id), list(x))).sortByKey()\n",
    "    user_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in user_dictionary.keys():\n",
    "        user_dictionary[key] = i\n",
    "        i += 1\n",
    "    return user_dictionary\n",
    "\n",
    "def create_book_dictionary(rdd): #Used to assign an integer id to each book of the rdd (to get the column of the CSR)\n",
    "    rdd = rdd.map(lambda x: (x.book_id, list(x))).sortByKey()\n",
    "    book_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in book_dictionary.keys():\n",
    "        book_dictionary[key] = i\n",
    "        i += 1\n",
    "    return book_dictionary\n",
    "\n",
    "def addDataType1(line):\n",
    "    return Row(line.item_id, line.person_id, line.title, str(line.sub_title), line.item_review, line.total_review, line.average_rating, str(line.total_votes), line.isbn, \"anobii\")\n",
    "\n",
    "\n",
    "def addRowColumnId(line): #Funzione usata per aggiungere gli indici per ogni libro e utente\n",
    "    book_number = book_dictionary[line.book_id] \n",
    "    user_number = user_dictionary[line.person_id]\n",
    "    return Row(line.book_id,\n",
    "               line.title,\n",
    "               line.sub_title,\n",
    "               line.total_wishlist,\n",
    "               line.no_of_page,\n",
    "               line.publication_date,\n",
    "               line.publisher,\n",
    "               line.binding,\n",
    "               line.edition,\n",
    "               line.product_type,\n",
    "               line.total_votes,\n",
    "               line.data_type,\n",
    "               line.person_id,\n",
    "               line.item_review,\n",
    "               line.author,\n",
    "               line.genre,\n",
    "               line.encrypt_item_id,\n",
    "               line.isbn,\n",
    "               line.total_count,\n",
    "               line.average_rating,\n",
    "               line.total_review,\n",
    "               str(user_number), \n",
    "               str(book_number))\n",
    "    return Row(line.person_id, line.title, str(line.sub_title), line.item_review, line.data_type, line.book_id, line.author, line.genre, line.encrypt_item_id, line.total_votes_or_loans, line.average_rating, line.total_review, line.isbn, str(user_number), str(book_number))\n",
    "\n",
    "def title_and_subtitle_books(line): #FUNZIONE USATA PER DIVIDERE TITOLO E SOTTOTITOLO NEL DATASET DEI LIBRI DELLE BIBLIOTECHE E PER ELIMINARE EDITION_DATE ED EDITION_LANGUAGE\n",
    "    if len(line.title.split(\" : \")) > 1:\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "    else:\n",
    "        title = line.title\n",
    "        sub_title = \"None\"\n",
    "    #\"title\", \"sub_title\", \"author\", \"publisher\", \"book_id\"\n",
    "    return Row(title, sub_title, line.author, line.publisher, line.manifestation_id_new, line.ISBNISSN_new)\n",
    "\n",
    "print(\"Raws data have been read\")\n",
    "#these are the columns which are needed for our work, for the item table. The others can be dropped\n",
    "DFitems_anobii_cols_to_keep = [\n",
    "                        \"item_id\",\\\n",
    "                        \"isbn\",\\\n",
    "#                         \"family_id\",\\\n",
    "                        \"title\",\\\n",
    "                        \"sub_title\",\\\n",
    "                        # \"barcode\",\\\n",
    "                        # \"image_source\",\\\n",
    "                        # \"image_width\",\\\n",
    "                        # \"image_height\",\\\n",
    "                        \"no_of_page\",\\\n",
    "                        \"publication_date\",\\\n",
    "                        \"publisher\",\\\n",
    "                        \"binding\",\\\n",
    "                        \"edition\",\\\n",
    "                        # \"reading_level\",\\\n",
    "                        # \"height\",\\\n",
    "                        # \"height_unit\",\\\n",
    "                        # \"length\",\\\n",
    "                        # \"length_unit\",\\\n",
    "                        # \"width\",\\\n",
    "                        # \"width_unit\",\\\n",
    "                        # \"weight\",\\\n",
    "                        # \"weight_unit\",\\\n",
    "                        # \"salesrank\",\\\n",
    "                        # \"item_popularity\",\\\n",
    "                        # \"check_same_family\",\\\n",
    "                        # \"check_internal_family\",\\\n",
    "                        # \"last_update\",\\\n",
    "                        \"average_rating\",\\\n",
    "                        \"total_review\",\\\n",
    "                        \"product_type\",\\\n",
    "                        # \"title_foreign\",\\\n",
    "                        # \"image_process\",\\\n",
    "                        # \"amazon\",\\\n",
    "                        # \"google\",\\\n",
    "                        \"encrypt_item_id\",\\\n",
    "                        # \"pid\",\\\n",
    "                        # \"binding_id\",\\\n",
    "                        # \"problem\",\\\n",
    "                        \"language\",\\\n",
    "                        # \"language_correct\",\\\n",
    "                        # \"ean\",\\\n",
    "                        # \"family_head\",\\\n",
    "                        # \"google_time\",\\\n",
    "                        # \"total_world\",\\\n",
    "                        # \"lock\",\\\n",
    "                        # \"volumes\",\\\n",
    "                        # \"publication_country_id\",\\\n",
    "                        # \"added_date\",\\\n",
    "                        # \"publishing_status\",\\\n",
    "                        # \"total_libraries\",\\\n",
    "                        # \"unavailable_date\",\\\n",
    "                        # \"table_of_contents_html\",\\\n",
    "                        # \"product_form_detail\",\\\n",
    "                        # \"total_edition_ratings\",\\\n",
    "                        # \"epub_url\",\\\n",
    "                        # \"imprint_name\",\\\n",
    "                        # \"is_sellable\",\\\n",
    "                        # \"total_topics\",\\\n",
    "                        # \"publisher_id\",\\\n",
    "                        \"total_wishlist\",\\\n",
    "                        # \"embargo_date\",\\\n",
    "                        # \"data_source\",\\\n",
    "                        # \"ebook_type\",\\\n",
    "                        # \"has_ebook\",\\\n",
    "                        # \"fulfillment_book_id\",\\\n",
    "                        # \"ebook_filesize\",\\\n",
    "                        # \"sample_status\",\\\n",
    "                        # \"sample_url\",\\\n",
    "                        # \"sample_filesize\",\\\n",
    "                      ]\n",
    "DFitems_anobii = DFitems_anobii.select(DFitems_anobii_cols_to_keep)\n",
    "print(\"Filter Anobii data (select books in italian, drop comics and books with a low number of ratings)\")\n",
    "#FILTRAGGIO 1: linguaggio italiano\n",
    "#Mi basterà filtrare da item.csv tutte le tuple con language diverso da 11.\n",
    "\n",
    "DFfilteredlanguageitems = DFitems_anobii.filter(DFitems_anobii.language == \"11\")\n",
    "DFitems_anobii = DFitems_anobii.select(DFitems_anobii_cols_to_keep)\n",
    "#DFfilteredlanguageitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 2: solo \"hardcover\" e \"paperback\"\n",
    "\n",
    "DFfilteredbindingitems = DFfilteredlanguageitems.filter((DFfilteredlanguageitems.binding == \"Paperback\") | (DFfilteredlanguageitems.binding == \"Hardcover\"))\n",
    "#DFfilteredbindingitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 3: eliminare i fumetti (per quanto possibile)\n",
    "#Userò come parole chiave personaggi famosi Disney quali Topolino e Paperino e i fumetti Bonelli (che fra gli italiani\n",
    "#sono probabilmente i più gettonati)\n",
    "\n",
    "DFfilteredmagazineitems = DFfilteredbindingitems.filter(~(DFfilteredbindingitems.title.contains(\"Topolino\")) | (DFfilteredbindingitems.title.contains(\"Paperino\"))|(DFfilteredbindingitems.title.contains(\"Tex\"))|(DFfilteredbindingitems.title.contains(\"Dylan Dog\"))|(DFfilteredbindingitems.title.contains(\"Nathan Never\"))|(DFfilteredbindingitems.title.contains(\"Zagor\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0a267d-3ee2-4070-a367-32af25f53489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anobii data have been filtered (select books in italian, drop comics and books with a low number of ratings)\n",
      "Integrete with genre and author attributes Anobii data\n",
      "Anobii data have been integreted with genre and author attributes\n",
      "Read and filter BCT data\n",
      "Togli oggetti inutili: Prima 290125  - Dopo 257054\n",
      "Togli libri in lingua straniera: Prima 290125  - Dopo 228059\n",
      "Togli Fumetti: Prima 290125  - Dopo 227749\n",
      "prefiltrati: 218419 - filtrati: 17947\n",
      "Manifestation prefiltrati: 218419 - filtrati: 18164\n",
      "Item prefiltrati: 998403 - filtrati: 217405\n",
      "Loan prefiltrati: 5484078 - filtrati: 2172971\n",
      "i libri sono: 18164\n",
      "BCT data have been read and filtered\n",
      "Prepare data for merge\n"
     ]
    }
   ],
   "source": [
    "#DFfilteredmagazineitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 4: libri con più di X votes. Per vedere i voti di ogni libro dovrei usare il dataframe link_person_item.csv.\n",
    "#Come possiamo notare, alcune recensione hanno valore 0: questo non vuol dire che il libro è stato valutato\n",
    "#atrocemente ma che l'utente ha letto il libro senza inserire voti.\n",
    "\n",
    "#Dobbiamo dunque scremare tali voti da questo dataframe.\n",
    "\n",
    "# file = \"/data/SMARTDATA/books/anobii/link_person_item.csv\" #MOSTRA IL VOTO DI UN UTENTE A UN LIBRO\n",
    "# DFstars = spark.read.csv(file,header=True)\n",
    "#DFstars.show(50, False)\n",
    "\n",
    "DFstarsfilteredno0 = DFinfo.filter(DFinfo.item_review > 0)\n",
    "#DFstarsfilteredno0.show(20,False)\n",
    "\n",
    "#Contiamo i libri con più voti e visualizziamoli in ordine discendente\n",
    "\n",
    "DFgrouped = DFstarsfilteredno0.groupby(\"item_id\").count().withColumnRenamed(\"count\", \"total_votes\")\\\n",
    "                              .sort(\"total_votes\", ascending=False)\n",
    "#I voti dei libri più votati si aggirano intorno ai 10^4 come ordine di grandezza per cui per ora scelgo 300 come\n",
    "#soglia di voti necessaria a rimanere nel dataframe (soggetto a cambiamenti)\n",
    "DFgroupedfiltered = DFgrouped.filter(DFgrouped['total_votes'] > 300)\n",
    "DFjoinbookstars = DFfilteredmagazineitems.join(DFgroupedfiltered, DFfilteredmagazineitems.item_id == DFgroupedfiltered.item_id).drop(DFgroupedfiltered.item_id)\n",
    "# DFjoinbookstars.show(1, False)\n",
    "# DFjoinbookstars:\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "# |item_id|isbn      |title            |sub_title|no_of_page|publication_date|publisher|binding  |edition|average_rating  |total_review|product_type|encrypt_item_id   |language|total_wishlist|total_votes|\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "# |1981748|8845260372|Giulietta squeenz|null     |209       |2008-05-01      |Bompiani |Paperback|null   |3.18773234200743|129         |1           |014f24ec9629744c88|11      |110           |543        |\n",
    "# +-------+----------+-----------------+---------+----------+----------------+---------+---------+-------+----------------+------------+------------+------------------+--------+--------------+-----------+\n",
    "\n",
    "#FILTRAGGIO 5: Pulizie varie ed eventuali\n",
    "#DFfilteredlessthan10items.filter(DFfilteredlessthan10items.total_review > 100).show()\n",
    "\n",
    "#NOTA: prendo i titoli con le minuscole per facilità di merging con le biblioteche\n",
    "DFmanifestations_definitive_anobii = DFjoinbookstars.select(\"item_id\", \\\n",
    "                                                            lower(DFjoinbookstars.title), \\\n",
    "                                                            lower(DFjoinbookstars.sub_title), \\\n",
    "                                                            \"isbn\",\\\n",
    "                                                            \"average_rating\", \\\n",
    "                                                            \"total_review\", \\\n",
    "                                                            \"total_wishlist\", \\\n",
    "                                                            \"no_of_page\",\n",
    "                                                            \"publication_date\",\n",
    "                                                            \"publisher\",\n",
    "                                                            \"binding\",\n",
    "                                                            \"edition\",\n",
    "                                                            \"product_type\",\n",
    "                                                            \"total_votes\",\n",
    "                                                            \"encrypt_item_id\",)\\\n",
    "                                                    .withColumnRenamed(\"lower(title)\", \"title\")\\\n",
    "                                                    .withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "# DFmanifestations_definitive_anobii.show(1, False)\n",
    "# DFmanifestations_definitive_anobii: (uguale a DFjoinbookstars ma senza language)\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+\n",
    "\n",
    "print(\"Anobii data have been filtered (select books in italian, drop comics and books with a low number of ratings)\")\n",
    "print(\"Integrete with genre and author attributes Anobii data\")\n",
    "#add genres to the item table: this is contained in DFgenres:\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# |id |familyid|itemid |categoryid|slug              |name              |languageid|votes|\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# |1  |32423317|2823074|3         |business-economics|Business&Economics|3         |2.0  |\n",
    "# +---+--------+-------+----------+------------------+------------------+----------+-----+\n",
    "# Notice that if a book has more than 1 genre, DFgenres contained more than one row with that item_id, one for genre.\n",
    "# Aggregation of rows with same itemid is needed \n",
    "DFgenres_aggregated = DFgenres.groupBy('itemid')\\\n",
    "                              .agg(F.concat_ws(\" / \", F.collect_list('name'))\\\n",
    "                                    .alias('genres'))\n",
    "# DFgenres_aggregated:\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "# |itemid |genres                                                                                        |\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "# |1981748|Humor / Fiction&Literature / Romance / Family-Sex&Relationships / Teens / Philosophy / History|\n",
    "# +-------+----------------------------------------------------------------------------------------------+\n",
    "\n",
    "# join between items and DFgenres_aggregated to have, for each item, its genres\n",
    "DFmanifestations_definitive_anobii_genres = DFmanifestations_definitive_anobii.join(DFgenres_aggregated,\\\n",
    "                                                                                    DFgenres_aggregated.itemid == DFmanifestations_definitive_anobii.item_id)\\\n",
    "                                                                              .select(DFmanifestations_definitive_anobii[\"*\"],\\\n",
    "                                                                                      DFgenres_aggregated[\"genres\"]) \n",
    "# DFmanifestations_definitive_anobii_genres.show(1, False)\n",
    "# DFmanifestations_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |genres                                                                                        |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|History / Fiction&Literature / Family-Sex&Relationships / Teens / Humor / Romance / Philosophy|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+\n",
    "# add a column which explain the origin of the data (anobii or BCT)\n",
    "DFmanifestations_definitive_anobii_genres = DFmanifestations_definitive_anobii_genres.withColumn('data_type', lit(\"anobii\"))\n",
    "# DFmanifestations_definitive_anobii_genres.show(1, False)\n",
    "# DFmanifestations_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# |item_id|title            |sub_title|isbn      |average_rating  |total_review|total_wishlist|no_of_page|publication_date|publisher|binding  |edition|product_type|total_votes|encrypt_item_id   |genres                                                                                        |data_type|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# |1981748|giulietta squeenz|null     |8845260372|3.18773234200743|129         |110           |209       |2008-05-01      |Bompiani |Paperback|null   |1           |543        |014f24ec9629744c88|Family-Sex&Relationships / Teens / Humor / Romance / Philosophy / History / Fiction&Literature|anobii   |\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+----------------------------------------------------------------------------------------------+---------+\n",
    "# add author in the DFmanifestations_definitive_anobii_genres table\n",
    "# find author_id for each book\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_definitive_anobii_genres.join(DFauthorbooks, \\\n",
    "                                                                                       DFauthorbooks.item_id == DFmanifestations_definitive_anobii_genres.item_id)\\\n",
    "                                                                                 .select(DFmanifestations_definitive_anobii_genres[\"*\"], \\\n",
    "                                                                                         DFauthorbooks[\"author_id\"])\n",
    "# DFmanifestations_anobii_genres_author.show(1, False)\n",
    "# DFmanifestations_anobii_genres_author:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|author_id|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Romance / Humor /...|   anobii|   354644|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+---------+\n",
    "# find author (name) for each book (and remove books which has same title but different auhtor?)\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_anobii_genres_author.join(DFdisplay,\\\n",
    "                                                                                   DFmanifestations_anobii_genres_author.author_id == DFdisplay.author_id)\\\n",
    "                                                                             .select(DFmanifestations_anobii_genres_author[\"*\"], \\\n",
    "                                                                                     DFdisplay[\"author_name\"])\\\n",
    "                                                                             .drop(\"author_id\")\n",
    "\n",
    "# remove books which has same title but different auhtor\n",
    "DFmanifestations_anobii_genres_author = DFmanifestations_anobii_genres_author.select(\"*\", F.min(DFmanifestations_anobii_genres_author.author_name)\\\n",
    "                                                                                           .over(Window.partitionBy(DFmanifestations_anobii_genres_author.item_id))\\\n",
    "                                                                                           .alias(\"author\"))\\\n",
    "                                                                             .drop(\"author_name\")\\\n",
    "                                                                             .dropDuplicates(['item_id', 'author'])\n",
    "# DFmanifestations_anobii_genres_author.show(1, False)\n",
    "# DFmanifestations_anobii_genres_author:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Philosophy / Hist...|   anobii|Pulsatilla|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+\n",
    "#join of item and rating tables to obtain person_id, item_id, rating and all attributes of the item in the same row\n",
    "#df1.join(df2, df1.id == df2.id).select(df1[\"*\"],df2[\"other\"])\n",
    "DFloans_definitive_anobii_genres = DFstarsfilteredno0.join(DFmanifestations_anobii_genres_author, \\\n",
    "                                                           DFmanifestations_anobii_genres_author.item_id == DFstarsfilteredno0.item_id)\\\n",
    "                                                     .select(DFmanifestations_anobii_genres_author[\"*\"], \\\n",
    "                                                             DFstarsfilteredno0[\"person_id\"], \\\n",
    "                                                             DFstarsfilteredno0[\"item_review\"])\n",
    "# DFloans_definitive_anobii_genres.show(1, False)\n",
    "# DFloans_definitive_anobii_genres:\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|person_id|item_review|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Philosophy / Fict...|   anobii|Pulsatilla|  1244593|          3|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "\n",
    "print(\"Anobii data have been integreted with genre and author attributes\")\n",
    "print(\"Read and filter BCT data\")\n",
    "%run cleanDataBCTwithIBSN.ipynb #Così a quanto pare\n",
    "DFmanifestations_definitive_bct = DFmanifestations_definitive\n",
    "DFloans_definitive_bct = DFloans_definitive\n",
    "# DFmanifestations_definitive_bct.show(1, False)\n",
    "# DFmanifestations_definitive_bct:\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# |edition_language|edition_date|    title|       author|publisher|manifestation_id_new|ISBNISSN_new|\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# |             ita|        1996|Pinocchio|Carlo Collodi|   Nuages|              107930|  8807820714|\n",
    "# +----------------+------------+---------+-------------+---------+--------------------+------------+\n",
    "# DFloans_definitive_bct:\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "# |manifestation_id_new|       patron_id_md5|    loan_date_begin|      loan_date_end|           due_date|from_library|to_library|end_library|\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "# |              220771|fa242f1458100dccc...|2012-09-05 11:27:25|2012-09-27 18:18:00|2012-10-05 11:27:21|          18|        18|         18|\n",
    "# +--------------------+--------------------+-------------------+-------------------+-------------------+------------+----------+-----------+\n",
    "print(\"BCT data have been read and filtered\")\n",
    "print(\"Prepare data for merge\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5a823b-340b-4622-a1d6-800f90852f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data have been prepared for merge\n",
      "Merge data\n"
     ]
    }
   ],
   "source": [
    "# BCT data preparation: prepare the table of loans which contains also metadata of the book\n",
    "DFloans_with_titles = DFloans_definitive_bct.join(DFmanifestations_definitive_bct, \\\n",
    "                                                  DFloans_definitive_bct.manifestation_id_new == DFmanifestations_definitive_bct.manifestation_id_new)\\\n",
    "                                             .select(DFloans_definitive_bct.manifestation_id_new, \\\n",
    "                                                     \"patron_id_md5\", \\\n",
    "                                                     \"author\", \\\n",
    "                                                     \"ISBNISSN_new\", \\\n",
    "                                                     lower(DFmanifestations_definitive_bct.title))\\\n",
    "                                             .withColumnRenamed(\"lower(title)\", \"title\")\n",
    "# DFloans_with_titles:\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "# |manifestation_id_new|       patron_id_md5|       author|ISBNISSN_new|    title|\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "# |              107930|b5c0986c79b1afafd...|Carlo Collodi|  8807820714|pinocchio|\n",
    "# +--------------------+--------------------+-------------+------------+---------+\n",
    "\n",
    "# BCT data preparation: split title and subtitle\n",
    "RDDloans_with_titles = DFloans_with_titles.rdd    \n",
    "RDDloans_for_merge = RDDloans_with_titles.map(title_and_subtitle)  \n",
    "# DFloans_with_titles.show(1, False)\n",
    "DFloans_to_merge = RDDloans_for_merge.toDF([\"item_id\", \\\n",
    "                                            \"person_id\", \\\n",
    "                                            \"title\", \\\n",
    "                                            \"author\", \\\n",
    "                                            \"sub_title\", \\\n",
    "                                            \"item_review\", \\\n",
    "                                            \"total_review\", \\\n",
    "                                            \"average_rating\", \\\n",
    "                                            \"total_votes\", \\\n",
    "                                            \"isbn\", \\\n",
    "                                            \"data_type\"])\n",
    "# BCT data preparation: add missing columns, which are present in DFloans_definitive_anobii_genres\n",
    "columns_to_add = ['total_wishlist',\n",
    "                  'no_of_page',\n",
    "                  'publication_date',\n",
    "                  'publisher',\n",
    "                  'binding',\n",
    "                  'edition',\n",
    "                  'product_type',\n",
    "                  'encrypt_item_id',\n",
    "                  'genre',\n",
    "                 ]\n",
    "values_to_add = {'total_wishlist': None,\n",
    "                  'no_of_page': None,\n",
    "                  'publication_date': None, \n",
    "                  'publisher': None, \n",
    "                  'binding': \"Paperback\",\n",
    "                  'edition': None,\n",
    "                  'product_type': 1,\n",
    "                  'encrypt_item_id': None,\n",
    "                  'genre': None,\n",
    "    \n",
    "}\n",
    "for c in columns_to_add:\n",
    "        DFloans_to_merge = DFloans_to_merge.withColumn(c, lit(values_to_add[c]))\n",
    "\n",
    "# DFloans_to_merge:\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "# |item_id|           person_id|    title|author_name|    sub_title|item_review|total_review|average_rating|total_votes|      isbn|  data_type|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|encrypt_item_id|genre|\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "# | 107930|fcc17388ef20567fe...|pinocchio|       None|Carlo Collodi|          4|        None|          None|       None|8807820714|biblioteche|          null|      null|            null|     null|Paperback|   null|           1|           null| null|\n",
    "# +-------+--------------------+---------+-----------+-------------+-----------+------------+--------------+-----------+----------+-----------+--------------+----------+----------------+---------+---------+-------+------------+---------------+-----+\n",
    "print(\"Data have been prepared for merge\")\n",
    "print(\"Merge data\")\n",
    "# union of the loans of bct data and anobii data\n",
    "DFloans_merged = DFloans_definitive_anobii_genres.union(DFloans_to_merge)\n",
    "# DFloans_merged.show(1)\n",
    "# DFloans_merged\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |item_id|            title|sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|    author|person_id|item_review|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# |1981748|giulietta squeenz|     null|8845260372|3.18773234200743|         129|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|014f24ec9629744c88|Family-Sex&Relati...|   anobii|Pulsatilla|   734393|          5|\n",
    "# +-------+-----------------+---------+----------+----------------+------------+--------------+----------+----------------+---------+---------+-------+------------+-----------+------------------+--------------------+---------+----------+---------+-----------+\n",
    "# Remove books, whose title is one word only, i.e. keep books whose title contains at least a blank space\n",
    "# DFloans_merged.filter(DFloans_merged.title == \"pinocchio\").show()\n",
    "DFloans_merged_nosinglewordtitles = DFloans_merged.filter(DFloans_merged.title.contains(\" \")) \n",
    "# DFloans_merged_nosinglewordtitles.filter(DFloans_merged_nosinglewordtitles.title == \"pinocchio\").show()\n",
    "\n",
    "# Assign to books with the same title, the same book_id\n",
    "DFloans_merged_aggregated = DFloans_merged_nosinglewordtitles.select(\"*\", \\\n",
    "                                                                     F.min(DFloans_merged_nosinglewordtitles.item_id)\\\n",
    "                                                                      .over(Window.partitionBy(DFloans_merged_nosinglewordtitles.title))\\\n",
    "                                                                      .alias(\"book_id\"))\\\n",
    "                                                              .drop(\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd7eefd-3c38-4661-a284-e9e696904a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been merged\n",
      "Write data on csv files\n",
      "There are 3812993 loans\n",
      "There are 3045 books\n",
      "There are 144202 users\n",
      "Csv files have been written\n"
     ]
    }
   ],
   "source": [
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "# |               title|          sub_title|      isbn|  average_rating|total_review|total_wishlist|no_of_page|publication_date|          publisher|  binding|edition|product_type|total_votes|   encrypt_item_id|              genres|data_type|          author|person_id|item_review|book_id|\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "# |come mi batte for...|storia di mio padre|8806198882|4.14122681883024|         206|           270|       302|      2009-11-03|Einaudi (Frontiere)|Hardcover|      1|           1|        705|01500978c278d06718|Crime / Teens / N...|   anobii|Benedetta Tobagi|   767565|          3|2806310|\n",
    "# +--------------------+-------------------+----------+----------------+------------+--------------+----------+----------------+-------------------+---------+-------+------------+-----------+------------------+--------------------+---------+----------------+---------+-----------+-------+\n",
    "\n",
    "# Assign to books with the same title, the same new_author\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.author)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_author\"))\n",
    "\n",
    "# Assign to books with the same title, the same new_genre\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.genre)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_genre\"))\n",
    "\n",
    "# Assign to books with the same title, the same new_encrypt\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.encrypt_item_id)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_encrypt_item_id\"))\n",
    "\n",
    "# Assign to books with the same title, the same new_isbn\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.min(DFloans_merged_aggregated.isbn)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_isbn\"))\n",
    "\n",
    "# Update metrics of loans: new_total_count (to count the number of votes or loans) \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.count(\"*\")\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_total_count\"))\n",
    "\n",
    "# Update metrics of loans: new_average_rating \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.avg(DFloans_merged_aggregated.item_review)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_average_rating\"))\n",
    "\n",
    "# Update metrics of loans: new_total_review, to count the actual number of review for a book (only anobii provides real review!!) \n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.select(\"*\", \\\n",
    "                                                             F.max(DFloans_merged_aggregated.total_review)\\\n",
    "                                                              .over(Window.partitionBy(DFloans_merged_aggregated.book_id))\\\n",
    "                                                              .alias(\"new_total_review\"))\n",
    "\n",
    "# Remove \"old\" attributes\n",
    "columnsToDrop = ['author',\n",
    "                 'genres',\n",
    "                 'encrypt_item_id',\n",
    "                 'isbn',\n",
    "                 'total_count',\n",
    "                 'average_rating',\n",
    "                 'total_review',]\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.drop(*columnsToDrop)\n",
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "# |            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|person_id|item_review|book_id|new_author|           new_genre|new_encrypt_item_id|  new_isbn|new_total_count|new_average_rating|new_total_review|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "# |giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|   959028|          3|1981748|Pulsatilla|Philosophy / Hist...| 014f24ec9629744c88|8845260372|            543|3.1860036832412524|             129|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+-------------------+----------+---------------+------------------+----------------+\n",
    "\n",
    "# Rename \"new\" attributes\n",
    "columnsToRenames = ['new_author',\n",
    "                    'new_genre',\n",
    "                    'new_encrypt_item_id',\n",
    "                    'new_isbn',\n",
    "                    'new_total_count',\n",
    "                    'new_average_rating',\n",
    "                    'new_total_review',]\n",
    "for c in columnsToRenames:\n",
    "    DFloans_merged_aggregated = DFloans_merged_aggregated.withColumnRenamed(c, c.replace(\"new_\", \"\"))\n",
    "# DFloans_merged_aggregated.show(1)\n",
    "# DFloans_merged_aggregated:\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "# |            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|person_id|item_review|book_id|    author|               genre|   encrypt_item_id|      isbn|total_count|    average_rating|total_review|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "# |giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|   273238|          4|1981748|Pulsatilla|Humor / Philosoph...|014f24ec9629744c88|8845260372|        543|3.1860036832412524|         129|\n",
    "# +-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+---------+-----------+-------+----------+--------------------+------------------+----------+-----------+------------------+------------+\n",
    "\n",
    "# Remove ['book_id', 'person_id'] duplicates\n",
    "DFloans_merged_aggregated = DFloans_merged_aggregated.dropDuplicates(['book_id', 'person_id'])\n",
    "print(\"Data has been merged\")\n",
    "# before write data on file, create index for both users and books of the sparce matrix\n",
    "RDDmerged_almost_definitive = DFloans_merged_aggregated.rdd\n",
    "\n",
    "# functions which creates the dictionary where the key is the book_id/person_id and the value is the corresponding index\n",
    "book_dictionary = create_book_dictionary(RDDmerged_almost_definitive)\n",
    "user_dictionary = create_user_dictionary(RDDmerged_almost_definitive)\n",
    "\n",
    "# add the user_index and the book_index in the dataframe\n",
    "RDDdefinitive = RDDmerged_almost_definitive.map(addRowColumnId)\n",
    "DFloans_merged_aggregated = RDDdefinitive.toDF(['book_id',\n",
    "                                                'title',\n",
    "                                                'sub_title',\n",
    "                                                'total_wishlist',\n",
    "                                                'no_of_page',\n",
    "                                                'publication_date',\n",
    "                                                'publisher',\n",
    "                                                'binding',\n",
    "                                                'edition',\n",
    "                                                'product_type',\n",
    "                                                'total_votes',\n",
    "                                                'data_type',\n",
    "                                                'person_id',\n",
    "                                                'item_review',\n",
    "                                                'author',\n",
    "                                                'genre',\n",
    "                                                'encrypt_item_id',\n",
    "                                                'isbn',\n",
    "                                                'total_count',\n",
    "                                                'average_rating',\n",
    "                                                'total_review', \n",
    "                                                'user_index', \n",
    "                                                'book_index'], sampleRatio=0.9)\n",
    "print(\"Write data on csv files\")\n",
    "ratings = DFloans_merged_aggregated.filter((DFloans_merged_aggregated.genre != \"null\"))#DFdefinitive\n",
    "\n",
    "# in the rating table, each row is given by \"person_id\", \"book_id\", \"rating\" attributes\n",
    "ratings_tocsv = ratings.select([\"person_id\", \"book_id\", \"item_review\"])\\\n",
    "                       .withColumnRenamed(\"item_review\", \"rating\")\n",
    "# ratings_tocsv.show(1)\n",
    "# ratings_tocsv:\n",
    "# +---------+-------+------+\n",
    "# |person_id|book_id|rating|\n",
    "# +---------+-------+------+\n",
    "# |   100489|1981748|     3|\n",
    "# +---------+-------+------+\n",
    "print(\"There are \"+str(ratings_tocsv.count())+\" loans\")\n",
    "ratings_tocsv.toPandas().to_csv(\"ratings2021.csv\")\n",
    "\n",
    "# in the book table, the metadata about the book are reported\n",
    "books_tocsv = ratings.dropDuplicates(['book_id'])\\\n",
    "                     .drop(\"person_id\")\\\n",
    "                     .drop(\"user_index\")\\\n",
    "                     .drop(\"item_review\")\n",
    "# books_tocsv.show(1)\n",
    "# books_tocsv:\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "# |book_id|            title|sub_title|total_wishlist|no_of_page|publication_date|publisher|  binding|edition|product_type|total_votes|data_type|    author|               genre|   encrypt_item_id|      isbn|total_count|    average_rating|total_review|book_index|\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "# |1981748|giulietta squeenz|     null|           110|       209|      2008-05-01| Bompiani|Paperback|   null|           1|        543|   anobii|Pulsatilla|Family-Sex&Relati...|014f24ec9629744c88|8845260372|        543|3.1860036832412524|         129|       319|\n",
    "# +-------+-----------------+---------+--------------+----------+----------------+---------+---------+-------+------------+-----------+---------+----------+--------------------+------------------+----------+-----------+------------------+------------+----------+\n",
    "print(\"There are \"+str(books_tocsv.count())+\" books\")\n",
    "\n",
    "books_tocsv = books_tocsv.join(DFdescriptions, DFdescriptions.item_id == books_tocsv.book_id, \"left\").select(\"book_id\", \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"book_index\", \"content\")\n",
    "books_tocsv.toPandas().to_csv(\"books2021.csv\")\n",
    "\n",
    "# in the user table, the person_id is reported for each user (in each row)\n",
    "users_tocsv = ratings.select(\"person_id\", \"user_index\").dropDuplicates()\n",
    "# users_tocsv.show(1)\n",
    "# users_tocsv:\n",
    "# +---------+----------+\n",
    "# |person_id|user_index|\n",
    "# +---------+----------+\n",
    "# |  1224803|     10623|\n",
    "# +---------+----------+\n",
    "print(\"There are \"+str(users_tocsv.count())+\" users\")\n",
    "users_tocsv.toPandas().to_csv(\"users2021.csv\")\n",
    "\n",
    "print(\"Csv files have been written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722d7735-ed85-4ef7-916d-7c0af4288820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###ESTRAZIONE KEYWORD###\n",
    "\n",
    "#Usiamo una versione filtrata di books_tocsv dove non compaiono tuple senza descrizione per attuare la nostra\n",
    "#estrazione.\n",
    "\n",
    "books_with_content = books_tocsv.filter(books_tocsv.content!=\"\")\n",
    "#books_with_content.count() #1387 libri\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95017055-84e1-4ca8-9844-8f628b7f2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per estrarre le keyword in maniera \"TF-IDF\" dobbiamo innanzitutto implementare una funzione che pulisca il testo \n",
    "#dalle stopwords (congiunzioni, rumori, etc.)\n",
    "\n",
    "import re \n",
    "\n",
    "def clean_text(line):\n",
    "    description = line[20]\n",
    "    description = description.replace(\"<b>\", \" \")\n",
    "    description = description.replace(\"</b>\", \" \")\n",
    "    description = description.replace(\"<br>\", \" \")\n",
    "    description = description.replace(\"</br>\", \" \")\n",
    "    description = description.replace(\"<p>\", \" \")\n",
    "    description = description.replace(\"</p>\", \" \")\n",
    "    description = description.replace(\"<P>\", \" \")\n",
    "    description = description.replace(\"</P>\", \" \")\n",
    "    description = description.replace(\"<i>\", \" \")\n",
    "    description = description.replace(\"</i>\", \" \")\n",
    "    description = description.replace(\"&quot\", \" \")\n",
    "    description = description.replace(\"<strong>\", \" \")\n",
    "    description = description.replace(\"</strong>\", \" \")\n",
    "    pattern = re.compile(re.escape(' e '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' o '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' il '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' lo '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' la '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' i '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' gli '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' le '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' di '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' a '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' da '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' in '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' con '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' per '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' su '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' tra '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' fra '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' degli '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' del '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' delle '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' dello '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' della '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' agli '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' al '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' alle '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' alla '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' allo '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' un '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' uno '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' una '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' che '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' ma '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' però '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' perché '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' perchè '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' non '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' ad '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' nella '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' nello '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' nelle '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' negli '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' sulle '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' sugli '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' sulla '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' sullo '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' del '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' sul '), re.IGNORECASE)\n",
    "    description = pattern.sub('', description)\n",
    "    pattern = re.compile(re.escape(' nel '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' al '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(' si '), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\"all'\"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\"nell'\"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\"dell'\"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\"sull'\"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\"l'\"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" mio \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" tuo \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" suo \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" mia \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" tua \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" sua \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" nostro \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" vostro \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" loro \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" nostra \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" vostra \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" io \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" tu \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" lui \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" lei \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" noi \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" voi \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    pattern = re.compile(re.escape(\" essi \"), re.IGNORECASE)\n",
    "    description = pattern.sub(' ', description)\n",
    "    description = description.replace(\",\", \" \")\n",
    "    description = description.replace(\".\", \" \")\n",
    "    description = description.replace('\"', \" \")\n",
    "    description = description.replace(\";\", \" \")\n",
    "    description = description.replace(\":\", \" \")\n",
    "    description = description.replace(\"!\", \" \")\n",
    "    description = description.replace(\"?\", \" \")\n",
    "    description = description.replace(\" è \", \" \")\n",
    "    description = description.replace(\" é \", \" \")\n",
    "    description = description.replace(\" o \", \" \")\n",
    "    description = description.replace(\" ' \", \" \")\n",
    "    description = description.replace(\"  \", \" \")\n",
    "    \n",
    "    return Row(book_id=line[0], title=line[1], sub_title=line[2], \n",
    "               total_wishlist=line[3], no_of_page=line[4], publication_date=line[5], \n",
    "               publisher=line[6], binding=line[7], edition=line[8], product_type=line[9], \n",
    "               total_votes=line[10], data_type=line[11], author=line[12], genre=line[13], \n",
    "               encrypt_item_id=line[14], isbn=line[15], total_count=line[16], average_rating=line[17], \n",
    "               total_review=line[18], book_index=line[19], content=description)\n",
    "RDDcontents = books_with_content.rdd\n",
    "        \n",
    "###SCHEMA###\n",
    "#\"book_id\", \"title\", \"sub_title\", \"total_wishlist\", \"no_of_page\", \"publication_date\", \n",
    "#\"publisher\", \"binding\", \"edition\", \"product_type\", \"total_votes\", \"data_type\", \"author\", \n",
    "#\"genre\", \"encrypt_item_id\", \"isbn\", \"total_count\", \"average_rating\", \"total_review\", \"book_index\", \"content\"\n",
    "#print(RDDcontents.take(1))\n",
    "RDDcleaned = RDDcontents.map(clean_text)\n",
    "#print(RDDcleaned.take(1))\n",
    "\n",
    "DFcleaned = RDDcleaned.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "609a7bbc-f0af-47dc-a5cc-9507986420fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ora che abbiamo il dataframe pulito, convertiamolo in pandas per estrarre i documenti da utilizzare\n",
    "\n",
    "DFcleaned_pandas = DFcleaned.toPandas()\n",
    "#DFcleaned_pandas.dropna(subset=['content'], inplace=True)\n",
    "#DFcleaned_pandas.head()\n",
    "\n",
    "corpus_doc = DFcleaned_pandas['content'].to_list()\n",
    "#print(corpus_doc) #Lista di tutte le descrizioni del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2dbdcbe-6b7e-41bc-9e09-d4f62f6525bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>top_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giulietta bambina intelligente insubordinata a...</td>\n",
       "      <td>[decide, visivo, simpatizzando, sfasciafamigli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allegra sparita Torino c'è più meglio c'è anc...</td>\n",
       "      <td>[iaio, allegra, zombi, ville, troppa, testimon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Togliere mezzo Robert Kelly anziano solitario...</td>\n",
       "      <td>[kelly, cambia, film, zane, village, videoteca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valter burla mondo sempre abituato perdere Pen...</td>\n",
       "      <td>[dolore, valter, scusa, goccia, gioia, sempre,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clay Easton diventato sceneggiatore proprio su...</td>\n",
       "      <td>[clay, turner, rip, julian, molto, diventato, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>Pastorale americana soltanto un'allegoria poli...</td>\n",
       "      <td>[dettagli, zuckerman, pastorale, intollerabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>Che cosa terribile Purtroppo libreria  Il Pap...</td>\n",
       "      <td>[verificato, todorovic, papiro, purtroppo, tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>Anita Blake vorrebbe assistere pace nozze amic...</td>\n",
       "      <td>[anita, vampiri, master, claude, jean, tramand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>Chiunque abbia visto qualche film terrore cent...</td>\n",
       "      <td>[vance, eleanor, scegliere, turno, torrette, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>autore intraprende ricerca ampio raggio mette...</td>\n",
       "      <td>[universali, supposto, specifico, siti, prospe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     Giulietta bambina intelligente insubordinata a...   \n",
       "1      Allegra sparita Torino c'è più meglio c'è anc...   \n",
       "2      Togliere mezzo Robert Kelly anziano solitario...   \n",
       "3     Valter burla mondo sempre abituato perdere Pen...   \n",
       "4     Clay Easton diventato sceneggiatore proprio su...   \n",
       "...                                                 ...   \n",
       "1382  Pastorale americana soltanto un'allegoria poli...   \n",
       "1383   Che cosa terribile Purtroppo libreria  Il Pap...   \n",
       "1384  Anita Blake vorrebbe assistere pace nozze amic...   \n",
       "1385  Chiunque abbia visto qualche film terrore cent...   \n",
       "1386   autore intraprende ricerca ampio raggio mette...   \n",
       "\n",
       "                                           top_keywords  \n",
       "0     [decide, visivo, simpatizzando, sfasciafamigli...  \n",
       "1     [iaio, allegra, zombi, ville, troppa, testimon...  \n",
       "2     [kelly, cambia, film, zane, village, videoteca...  \n",
       "3     [dolore, valter, scusa, goccia, gioia, sempre,...  \n",
       "4     [clay, turner, rip, julian, molto, diventato, ...  \n",
       "...                                                 ...  \n",
       "1382  [dettagli, zuckerman, pastorale, intollerabili...  \n",
       "1383  [verificato, todorovic, papiro, purtroppo, tri...  \n",
       "1384  [anita, vampiri, master, claude, jean, tramand...  \n",
       "1385  [vance, eleanor, scegliere, turno, torrette, p...  \n",
       "1386  [universali, supposto, specifico, siti, prospe...  \n",
       "\n",
       "[1387 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importiamo il TFIDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True)\n",
    "\n",
    "vectorizer.fit_transform(corpus_doc) #CREAZIONE DIZIONARIO CON I VOCABOLI CONTENUTI NELLE DESCRIZIONI\n",
    "\n",
    "feature_names = vectorizer.get_feature_names() #Estrae le feature (i vocaboli) importanti\n",
    "\n",
    "def sort_coo(coo_matrix): #Funzione usata per riordinare il dizionario per score\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data) #COLONNE: FEATURES RIGHE: DESCRIZIONE\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10): #Funzione usata per ottenere le n parole chiave\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    for idx, score in sorted_items:\n",
    "    \n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_keywords(vectorizer, feature_names, doc): #Funzione usata per ritornare le top k parole chiave di una descrizione\n",
    "    tf_idf_vector = vectorizer.transform([doc])\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10) #10 keyword per ora\n",
    "    \n",
    "    return list(keywords.keys())\n",
    "\n",
    "result = []\n",
    "for descrizione in corpus_doc:\n",
    "    df = {}\n",
    "    df['content'] = descrizione\n",
    "    df['top_keywords'] = get_keywords(vectorizer, feature_names, descrizione)\n",
    "    result.append(df)\n",
    "    \n",
    "DFkeywords = pd.DataFrame(result)\n",
    "DFkeywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adf42636-ada3-4d52-9d66-5483453c6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ora che abbiamo il dataframe di pandas con le keywords associate alle descrizioni, non ci resta che joinare\n",
    "#il contenuto di esso con il dataframe dei libri, integrando l'attributo keywords.\n",
    "#Riportiamo il dataframe nella forma PySpark\n",
    "\n",
    "#DFkeywords = spark.createDataFrame(DFkeywords)\n",
    "\n",
    "DF_almost_final = DFcleaned.join(DFkeywords, DFkeywords.content == DFcleaned.content, \"left\").drop(DFkeywords.content).select(\"book_id\", \"top_keywords\")\n",
    "#DF_almost_final.show(1, False)\n",
    "#Adesso joiniamo per book_id al dataframe con più libri (compresi quelli senza descrizione)\n",
    "DF_final = books_tocsv.join(DF_almost_final, DF_almost_final.book_id == books_tocsv.book_id, \"left\").drop(DF_almost_final.book_id)\n",
    "\n",
    "DF_final.toPandas().to_csv('books_and_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ecbb3-e566-420e-9b31-dbbdc30e7e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
