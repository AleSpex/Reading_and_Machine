{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE CON I MIEI TENTATIVI DI PREPROCESSING SUL DATABASE DI ANOBii\n",
    "\n",
    "#IMPORT\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "#from lightfm import LightFM\n",
    "from pyspark.sql.functions import row_number, lit, dense_rank\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "#CARICAMENTO DATAFRAME BASE\n",
    "file = \"/data/SMARTDATA/books/anobii/author_item.csv\"\n",
    "DFauthorbooks = spark.read.csv(file,header=True) #MOSTRA I LIBRI RELATIVI AGLI AUTORI\n",
    "#DFauthorbooks.show(1, False)\n",
    "#LIBRI DEGLI AUTORI\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/author_display.csv\"\n",
    "DFdisplay = spark.read.csv(file,header=True) #MOSTRA GLI AUTORI DEL DATABASE\n",
    "#DFdisplay.show(1, False)\n",
    "#DFauthorbooks_withnames = DFauthorbooks.join(DFdisplay, DFauthorbooks.author_id == DFdisplay.author_id).drop(DFdisplay.author_id)\n",
    "#AUTORI\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/language_mapping.csv\"\n",
    "DFlanguages = spark.read.csv(file,header=True)\n",
    "#DFlanguages.show()\n",
    "\n",
    "#Dobbiamo tenere solo i libri con language=11 #FILTRO LINGUAGGIO\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item_recommend.csv\"\n",
    "DFrecommends = spark.read.csv(file,header=True)\n",
    "#DFrecommends.show(1, False)\n",
    "#Questa tabella contiene gli ISBN riferiti all'item Id (quindi item_id non è unico?)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item.csv\"\n",
    "DFitems_anobii = spark.read.csv(file,header=True) #MOSTRA I LIBRI DEL DATABASE\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item_comment_vote.csv\" #MOSTRA INFORMAZIONI SUL VOTO DEGLI UTENTI\n",
    "DFvotes = spark.read.csv(file,header=True)\n",
    "#DFvotes.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/item_comment_feedback.csv\" #MOSTRA IL VOTO MEDIO\n",
    "DFfeedback = spark.read.csv(file,header=True)\n",
    "#DFfeedback.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/person_item_recommend.csv\" #MOSTRA I COMMENTI DEGLI UTENTI RELATIVI A UN LIBRO\n",
    "DFcomments = spark.read.csv(file,header=True)\n",
    "#DFcomments.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/person_item_progress.csv\" #MOSTRA INFORMAZIONI SULLE RACCOMANDAZIONI\n",
    "DFprogress = spark.read.csv(file,header=True)\n",
    "#DFprogress.show(50, False)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item_comment.csv\" #MOSTRA INFORMAZIONI VARIE QUALI LA PRESENZA DI\n",
    "#SPOILER IN UN COMMENTO O LA PRESENZA DI PROFANITà\n",
    "DFinfo = spark.read.csv(file,header=True)\n",
    "\n",
    "file = \"/data/SMARTDATA/books/anobii/link_person_item.csv\" #MOSTRA IL VOTO DI UN UTENTE A UN LIBRO\n",
    "DFstars = spark.read.csv(file,header=True)\n",
    "\n",
    "#Aggiungiamo encrypt_item_id e genere al dataframe dei libri\n",
    "#DFjoinbookstars_and_authors_nooneword.filter(DFjoinbookstars_and_authors_nooneword.book_id==\"1981748\").show()\n",
    "#Per aggiungere encrypted_item_id, apriamo il dataframe dei dati nuovi di anobii\n",
    "file = file = \"/data/SMARTDATA/books/anobii_2021/sql/item.csv\"\n",
    "DFnew_data = spark.read.csv(file, header=True)\n",
    "DFnew_data = DFnew_data.filter(DFnew_data.language==\"11\")\n",
    "#DFnew_data.show(1, False)\n",
    "#DFnew_data.filter(DFnew_data.item_id == \"1981748\").show()\n",
    "#Lo schema di questo dataset è enorme! Almeno sono riuscito a trovare il path.\n",
    "\n",
    "file = \"anobii_genres/genres5.csv\"\n",
    "DFgenres = spark.read.csv(file, header=True)\n",
    "#DFgenres.filter(DFgenres.itemid == \"1981748\").show(10, False)\n",
    "\n",
    "#DFmanifestations_with_encrypt.filter(DFmanifestations_with_encrypt.book_id == \"672529\").show()\n",
    "#FUNZIONI\n",
    "def title_and_subtitle(line): #Usata per splittare titolo e sottotitolo nel database delle biblioteche e renderli più simili ad anobii\n",
    "    if len(line.title.split(\" : \")) > 1: #Il libro possiede un sottotitolo\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "        \n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, title, sub_title, line.author, 4, \"None\", \"None\", \"None\", line.ISBNISSN_new,\"biblioteche\") #NE APPROFITTO ANCHE PER INSERIRE VOTO E CAMPI PER IL MERGE (PER ORA NULL)\n",
    "    else: #Il libro non possiede un sottotitolo\n",
    "        return Row(line.manifestation_id_new, line.patron_id_md5, line.title, \"None\", line.author, 4, \"None\", \"None\", \"None\", line.ISBNISSN_new, \"biblioteche\")\n",
    "\n",
    "def create_user_dictionary(rdd): #Used to assign an integer id to each user of the rdd (to get the rows of the CSR)\n",
    "    rdd = rdd.map(lambda x: (str(x.person_id), list(x))).sortByKey()\n",
    "    user_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in user_dictionary.keys():\n",
    "        user_dictionary[key] = i\n",
    "        i += 1\n",
    "    return user_dictionary\n",
    "\n",
    "def create_book_dictionary(rdd): #Used to assign an integer id to each book of the rdd (to get the column of the CSR)\n",
    "    rdd = rdd.map(lambda x: (x.book_id, list(x))).sortByKey()\n",
    "    book_dictionary = rdd.countByKey()\n",
    "    i = 0\n",
    "    for key in book_dictionary.keys():\n",
    "        book_dictionary[key] = i\n",
    "        i += 1\n",
    "    return book_dictionary\n",
    "\n",
    "def addDataType1(line):\n",
    "    return Row(line.item_id, line.person_id, line.title, str(line.sub_title), line.item_review, line.total_review, line.average_rating, str(line.total_votes), line.isbn, \"anobii\")\n",
    "\n",
    "\n",
    "def addRowColumnId(line): #Funzione usata per aggiungere gli indici per ogni libro e utente\n",
    "    book_number = book_dictionary[line.book_id] \n",
    "    user_number = user_dictionary[line.person_id]\n",
    "    \n",
    "    return Row(line.person_id, line.title, str(line.sub_title), line.item_review, line.data_type, line.book_id, line.author, line.genre, line.encrypt_item_id, line.total_votes_or_loans, line.average_rating, line.total_review, line.isbn, str(user_number), str(book_number))\n",
    "\n",
    "def title_and_subtitle_books(line): #FUNZIONE USATA PER DIVIDERE TITOLO E SOTTOTITOLO NEL DATASET DEI LIBRI DELLE BIBLIOTECHE E PER ELIMINARE EDITION_DATE ED EDITION_LANGUAGE\n",
    "    if len(line.title.split(\" : \")) > 1:\n",
    "        title = line.title.split(\" : \")[0]\n",
    "        sub_title = line.title.split(\" : \")[1]\n",
    "    else:\n",
    "        title = line.title\n",
    "        sub_title = \"None\"\n",
    "    #\"title\", \"sub_title\", \"author\", \"publisher\", \"book_id\"\n",
    "    return Row(title, sub_title, line.author, line.publisher, line.manifestation_id_new, line.ISBNISSN_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRAGGIO 1: linguaggio italiano\n",
    "#Mi basterà filtrare da item.csv tutte le tuple con language diverso da 11.\n",
    "\n",
    "DFfilteredlanguageitems = DFitems_anobii.filter(DFitems_anobii.language == \"11\")\n",
    "#DFfilteredlanguageitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 2: solo \"hardcover\" e \"paperback\"\n",
    "\n",
    "DFfilteredbindingitems = DFfilteredlanguageitems.filter((DFfilteredlanguageitems.binding == \"Paperback\") | (DFfilteredlanguageitems.binding == \"Hardcover\"))\n",
    "#DFfilteredbindingitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 3: eliminare i fumetti (per quanto possibile)\n",
    "#Userò come parole chiave personaggi famosi Disney quali Topolino e Paperino e i fumetti Bonelli (che fra gli italiani\n",
    "#sono probabilmente i più gettonati)\n",
    "\n",
    "DFfilteredmagazineitems = DFfilteredbindingitems.filter(~(DFfilteredbindingitems.title.contains(\"Topolino\")) | (DFfilteredbindingitems.title.contains(\"Paperino\"))|(DFfilteredbindingitems.title.contains(\"Tex\"))|(DFfilteredbindingitems.title.contains(\"Dylan Dog\"))|(DFfilteredbindingitems.title.contains(\"Nathan Never\"))|(DFfilteredbindingitems.title.contains(\"Zagor\")))\n",
    "#DFfilteredmagazineitems.show(20, False)\n",
    "\n",
    "#FILTRAGGIO 4: libri con più di X votes. Per vedere i voti di ogni libro dovrei usare il dataframe link_person_item.csv.\n",
    "#Come possiamo notare, alcune recensione hanno valore 0: questo non vuol dire che il libro è stato valutato\n",
    "#atrocemente ma che l'utente ha letto il libro senza inserire voti.\n",
    "\n",
    "#Dobbiamo dunque scremare tali voti da questo dataframe.\n",
    "\n",
    "# file = \"/data/SMARTDATA/books/anobii/link_person_item.csv\" #MOSTRA IL VOTO DI UN UTENTE A UN LIBRO\n",
    "# DFstars = spark.read.csv(file,header=True)\n",
    "#DFstars.show(50, False)\n",
    "\n",
    "DFstarsfilteredno0 = DFstars.filter(DFstars.item_review > 0)\n",
    "#DFstarsfilteredno0.show(20,False)\n",
    "\n",
    "#Contiamo i libri con più voti e visualizziamoli in ordine discendente\n",
    "\n",
    "DFgrouped = DFstarsfilteredno0.groupby(\"item_id\").count().withColumnRenamed(\"count\", \"total_votes\").sort(\"total_votes\", ascending=False)\n",
    "#I voti dei libri più votati si aggirano intorno ai 10^4 come ordine di grandezza per cui per ora scelgo 300 come\n",
    "#soglia di voti necessaria a rimanere nel dataframe (soggetto a cambiamenti)\n",
    "DFgroupedfiltered = DFgrouped.filter(DFgrouped['total_votes'] > 300)\n",
    "DFjoinbookstars = DFfilteredmagazineitems.join(DFgroupedfiltered, DFfilteredmagazineitems.item_id == DFgroupedfiltered.item_id).drop(DFgroupedfiltered.item_id)\n",
    "\n",
    "#FILTRAGGIO 5: Pulizie varie ed eventuali\n",
    "#DFfilteredlessthan10items.filter(DFfilteredlessthan10items.total_review > 100).show()\n",
    "\n",
    "#NOTA: prendo i titoli con le minuscole per facilità di merging con le biblioteche\n",
    "DFmanifestations_definitive_anobii = DFjoinbookstars.select(\"item_id\", lower(DFjoinbookstars.title), lower(DFjoinbookstars.sub_title), \\\n",
    "                                                            \"isbn\", \"average_rating\", \"total_review\", \"total_wishlist\", \\\n",
    "                                                            DFjoinbookstars['total_votes']).withColumnRenamed(\"lower(title)\", \"title\").withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "#remove rows with null in ibsn\n",
    "# DFmanifestations_definitive_anobii.select([count(when(isnan(c) | isnull(c), c)).alias(c) for c in [\"isbn\"]]).show() #--> sono 47: togliamoli !!!\n",
    "DFmanifestations_definitive_anobii = DFmanifestations_definitive_anobii.na.drop(subset=[\"isbn\"])\n",
    "# DFmanifestations_definitive_anobii.select([count(when(isnan(c) | isnull(c), c)).alias(c) for c in [\"isbn\"]]).show() #--> sono zero!\n",
    "# DFitems_anobii.select([count(when(isnan(c) | isnull(c), c)).alias(c) for c in [\"isbn\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c4d950-0208-4074-9f11-32a07d587264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFmanifestations_definitive_anobii.show(1, False)\n",
    "DFfiltered = DFjoinbookstars.select(\"item_id\", lower(DFjoinbookstars.title), \\\n",
    "                                    lower(DFjoinbookstars.sub_title), \"isbn\", \"average_rating\", \"total_review\", \"total_wishlist\", \\\n",
    "                                    DFjoinbookstars['total_votes']).withColumnRenamed(\"lower(title)\", \"title\").withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "DFauthorsandbooks = DFdisplay.join(DFauthorbooks, DFdisplay.author_id == DFauthorbooks.author_id).drop(DFdisplay.author_id).filter(DFdisplay.language==\"11\")\n",
    "DFvoteswithtitles = DFstarsfilteredno0.join(DFfiltered, DFfiltered.item_id == DFstarsfilteredno0.item_id).select(DFstarsfilteredno0.item_id, \"person_id\", \"title\", str(\"sub_title\"), \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\")\n",
    "#DFvoteswithtitles.filter((DFvoteswithtitles.title == \"il fuggiasco\") & (DFvoteswithtitles.person_id == \"262165\")).show()\n",
    "#DFvoteswithtitles.filter(DFvoteswithtitles.title == \"la custode di libri\").show()\n",
    "#Per ora proverò a costruire una CSR (matrice sparsa compressa) dal dataset di anobii (senza join con le biblioteche,\n",
    "#solo per testare). La CSR è costruita in modo tale da avere tre vettori numpy, uno per i dati e due per gli indici\n",
    "#riga-colonna con cui poi ricostruire la matrice originale.\n",
    "\n",
    "#Come posso passare dal dataset a questa matrice? La maniera più efficiente (ed è meglio adottarle dato le grandezze\n",
    "#dei dataset) è quella di creare la matrice direttamente, senza prima crearne una vuota da riempire.\n",
    "\n",
    "#Supposto che le righe di tale matrice siano gli utenti e le colonne siano i libri (e i dati siano per ora solo\n",
    "#i voti, poi potremo aggiungere feature per i metadati) allora posso provare ad aggiungere al mio dataframe delle \n",
    "#colonne indicanti gli indici futuri di riga colonna, usando degli id incrementali.\n",
    "DFvoteswithtitles = DFstarsfilteredno0.join(DFfiltered, DFfiltered.item_id == DFstarsfilteredno0.item_id).select(DFstarsfilteredno0.item_id, \"person_id\", \"title\", \\\n",
    "                                                                                                                 str(\"sub_title\"), \"item_review\", \"total_review\", \\\n",
    "                                                                                                                 \"average_rating\", \"total_votes\", \"isbn\")\n",
    "#Proviamo. (Forse con gli RDD è meglio)\n",
    "RDDvoteswithtitles = DFvoteswithtitles.rdd.cache()\n",
    "#RDDpair = RDDvoteswithtitles.map(lambda x: (x.person_id, list(x))).sortByKey()#.collect()\n",
    "RDDmapped = RDDvoteswithtitles.map(addDataType1)\n",
    "#user_dictionary = create_user_dictionary(RDDvoteswithtitles)\n",
    "#book_dictionary = create_book_dictionary(RDDvoteswithtitles)\n",
    "#print(RDDmapped.take(20))\n",
    "\n",
    "DFwithindexes = RDDmapped.toDF([\"item_id\", \"person_id\", \"title\", \"sub_title\",  \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"data_type\"], sampleRatio = 0.9) \n",
    "#Per evitare il problema del sampling in sub_title\n",
    "#DFvoteswithtitles.filter((DFvoteswithtitles.title == \"il fuggiasco\") & (DFvoteswithtitles.person_id == \"262165\")).show()\n",
    "#DFwithindexes contiene i voti di ogni utente dato il libro, altre info utili e gli indici di riga e di colonna\n",
    "#della eventuale compressed sparse matrix per una facile ed efficiente creazione (per i sistemi di raccomandazione)\n",
    "#Fatto ciò, riprendiamo il database delle biblioteche filtrato (come si importa un altro file .ipynb?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea752c0-2b06-4969-85ff-c0802530c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##INSERIAMO I NUOVI ATTRIBUTI (ENCRYPTED_ITEM_ID E GENRE DAI DATASET NUOVI)\n",
    "DFwithindexes_encrypted  = DFwithindexes.join(DFnew_data, DFnew_data.item_id == DFwithindexes.item_id).drop(DFnew_data.item_id).drop(DFnew_data.sub_title).drop(DFnew_data.title).drop(DFnew_data.total_review).drop(DFnew_data.average_rating).drop(DFnew_data.isbn).select(\"item_id\", \"person_id\", \"title\", \"sub_title\",  \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"data_type\", \"encrypt_item_id\")\n",
    "\n",
    "DFwithindexes_genres = DFwithindexes_encrypted.join(DFgenres, DFgenres.itemid == DFwithindexes_encrypted.item_id).select(\"item_id\", \"person_id\", \"title\", \"sub_title\",  \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"data_type\", \"encrypt_item_id\", \"name\")\n",
    "\n",
    "#DFwithindexes_genres.show(20, False)\n",
    "\n",
    "DFwithindexes_genres = DFwithindexes_genres.withColumnRenamed(\"name\", \"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excessive-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Togli oggetti inutili: Prima 290125  - Dopo 257054\n",
      "Togli libri in lingua straniera: Prima 290125  - Dopo 228059\n",
      "Togli Fumetti: Prima 290125  - Dopo 227749\n",
      "prefiltrati: 218419 - filtrati: 17947\n",
      "Manifestation prefiltrati: 218419 - filtrati: 18164\n",
      "Item prefiltrati: 998403 - filtrati: 217405\n",
      "Loan prefiltrati: 5484078 - filtrati: 2172971\n",
      "i libri sono: 18164\n"
     ]
    }
   ],
   "source": [
    "%run cleanDataBCTwithIBSN.ipynb #Così a quanto pare\n",
    "DFmanifestations_definitive_bct = DFmanifestations_definitive\n",
    "# DFmanifestations_definitive_bct.show(1, False)\n",
    "# DFmanifestations_definitive_bct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ready-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+---------+-----------+------------+----------------+-----------+----------+---------+\n",
      "|item_id|person_id|            title|sub_title|item_review|total_review|  average_rating|total_votes|      isbn|data_type|\n",
      "+-------+---------+-----------------+---------+-----------+------------+----------------+-----------+----------+---------+\n",
      "|1981748|    68170|giulietta squeenz|     None|          3|         128|3.20037105751391|        544|8845260372|   anobii|\n",
      "+-------+---------+-----------------+---------+-----------+------------+----------------+-----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DFwithindexes.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per adesso, concentriamoci su DFloans_definitive (i prestiti scremati).\n",
    "\n",
    "#DFauthorsandbooks.filter(DFauthorsandbooks.item_id == \"1254828\").show()\n",
    "#DFauthorsandbooks.filter(DFauthorsandbooks.item_id==\"651589\").show(20, False)\n",
    "DFwithindexes_and_authors = DFwithindexes_genres.join(DFauthorsandbooks, DFwithindexes.item_id == DFauthorsandbooks.item_id).\\\n",
    "                                          select(DFwithindexes.item_id, \"person_id\", \"title\", \"sub_title\", \"author_name\", \\\n",
    "                                                 \"item_review\", \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"data_type\", \"encrypt_item_id\", \"genre\")\n",
    "#Prendo i prestiti (che alla fine, è ciò che mi interessa) con i titoli che, per una formattazione più agevole, rendo minuscoli.\n",
    "DFloans_with_titles = DFloans_definitive.join(DFmanifestations_definitive, DFloans_definitive.manifestation_id_new == DFmanifestations_definitive.manifestation_id_new)\\\n",
    "                                        .select(DFloans_definitive.manifestation_id_new, \"patron_id_md5\", \"author\", \"ISBNISSN_new\", \\\n",
    "                                                lower(DFmanifestations_definitive.title)).\\\n",
    "                                        withColumnRenamed(\"lower(title)\", \"title\")\n",
    "#DFwithindexes_and_authors.filter((DFwithindexes_and_authors.title == \"il fuggiasco\") & (DFwithindexes_and_authors.person_id == \"262165\")).show()\n",
    "#Di cosa ho bisogno in loans_definitive per renderlo \"simile\" alle tuple di anobii? Certamente avrò bisogno del titolo, poi del manifestation_id (item_id), del cliente della biblioteca\n",
    "#(orrispettivo di person_id), di assegnare una item_review provvisoria (abbiamo stabilito, almeno per ora, 4 NOTA: l'average rating lo setto a NULL nelle tuple o lo ricalcolo considerando le \n",
    "#biblioteche? Da vedere), di settare le total_review (per ora a NULL?), i total_votes, l'isbn e lo user e book index (a NULL?)\n",
    "\n",
    "#Il problema di molti campi che lascerei a NULL è che in alcuni casi i titoli non sono esattamente gli stessi a causa della formattazione dei database delle biblioteche. Per stemperare il problema,\n",
    "#proverò a scindere titolo e sottotitoli in due campi differenti (alla maniera di anobii) e a pulire eventuali simboli strani (ad esempio, i numeri all'inizio di alcuni titoli).\n",
    "\n",
    "RDDloans_with_titles = DFloans_with_titles.rdd\n",
    "    \n",
    "RDDloans_for_merge = RDDloans_with_titles.map(title_and_subtitle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressed-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------------+-------------+------------+---------+\n",
      "|manifestation_id_new|patron_id_md5                   |author       |ISBNISSN_new|title    |\n",
      "+--------------------+--------------------------------+-------------+------------+---------+\n",
      "|107930              |5bd489802c61305cc115ad942fa60908|Carlo Collodi|8807820714  |pinocchio|\n",
      "+--------------------+--------------------------------+-------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DFloans_with_titles.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3c6e57-9dee-4ffd-9583-4d94e9301dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5266964\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "DFloans_to_merge = RDDloans_for_merge.toDF([\"item_id\", \"person_id\", \"title\", \"author_name\", \"sub_title\", \"item_review\", \\\n",
    "                                            \"total_review\", \"average_rating\", \"total_votes\", \"isbn\", \"data_type\"])\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "DFloans_to_merge = DFloans_to_merge.withColumn(\"encrypt_item_id\", lit(None))\n",
    "DFloans_to_merge = DFloans_to_merge.withColumn(\"genre\", lit(None))\n",
    "\n",
    "DFmerged = DFwithindexes_and_authors.union(DFloans_to_merge)\n",
    "### MERGE AVVENUTO (sperando di averlo implementato bene...)\n",
    "\n",
    "#Adesso vorrei cercare di sostituire i book_id delle biblioteche con quelli del corrispettivo titolo di anobii. Ciò aiuterà quando creerò la \n",
    "#colonna degli indici per la compressed sparse matrix.\n",
    "#Inoltre, vorrei che la funzione aggiornasse le metriche delle tuple delle biblioteche, per ora cosparse di \"None\".\n",
    "\n",
    "#Come discusso nel meeting, vorrei inoltre eliminare dal mio dataframe mergiato tutti quei titoli con una sola parola (che di solito si riferiscono a guide turistiche).\n",
    "\n",
    "#Infine, vorrei inserire gli indici di colonna e di riga della compressed sparse matrix in modo da iniziare a preparare l'input per la libreria di raccomandazione \n",
    "#(ho già implementato le funzioni\n",
    "#per farlo, a patto che le chiavi usate per il dizionario non siano erronee).\n",
    "\n",
    "#FASE 1: i libri con lo stesso titolo dovrebbero avere lo stesso book_id (e le metriche dovrebbero essere aggiornate di conseguenza).\n",
    "#Ciò è fattibile con la window di SQL e una partitionby. Controlliamo, con un sampling casuale, se ci sono due libri provenienti dai due diversi database (controllare data_type).\n",
    "\n",
    "#DFmerged.filter(DFmerged.title == \"la custode di libri\").show() #TROVATO ERRORE DI RIPETIZIONE TUPLE A CAUSA DELLA MANCATA SCREMATURA DEL LINGUAGGIO DURANTE IL JOIN PER LE INFO SULL'AUTORE (SISTEMATO)\n",
    "\n",
    "#ERRORE 2: alcuni libri di anobii sono ripetuti due volte con un autore diverso (ma perché?), da sistemare con un'aggregazione\n",
    "#Prima, però. filtriamo via i titoli con una parola (dovrebbero essere pochi rispetto alla cardinalità totale e ci semplifica la vita con i libri omonimi)\n",
    "#print(DFmerged.count()) #CARDINALITà DATABASE MERGIATO COUNT = 10331428\n",
    "DFmerged_no_onewordtitles = DFmerged.filter(DFmerged.title.contains(\" \")) #Se contiene uno spazio allora non è una sola parola (sperando di aver formattato bene)\n",
    "#DFmerged_no_onewordtitles.filter(DFmerged_no_onewordtitles.title == \"barcellona\").show()\n",
    "#DFmerged.filter(DFmerged.title == \"barcellona\").show()\n",
    "\n",
    "#Procediamo adesso con la sostituzione dei book_id delle biblioteche con quelli di anobii\n",
    "DFmerged_aggregated = DFmerged_no_onewordtitles.select(\"*\", F.min(DFmerged_no_onewordtitles.item_id).over(Window.partitionBy(DFmerged_no_onewordtitles.title)).alias(\"book_id\"))\n",
    "### MERGE AVVENUTO (sperando di averlo implementato bene...)\n",
    "\n",
    "#Adesso vorrei cercare di sostituire i book_id delle biblioteche con quelli del corrispettivo titolo di anobii. Ciò aiuterà quando creerò la colonna degli indici per la compressed sparse matrix.\n",
    "#Inoltre, vorrei che la funzione aggiornasse le metriche delle tuple delle biblioteche, per ora cosparse di \"None\".\n",
    "\n",
    "#Come discusso nel meeting, vorrei inoltre eliminare dal mio dataframe mergiato tutti quei titoli con una sola parola (che di solito si riferiscono a guide turistiche).\n",
    "\n",
    "#Infine, vorrei inserire gli indici di colonna e di riga della compressed sparse matrix in modo da iniziare a preparare l'input per la libreria di raccomandazione (ho già implementato le funzioni\n",
    "#per farlo, a patto che le chiavi usate per il dizionario non siano erronee).\n",
    "\n",
    "#FASE 1: i libri con lo stesso titolo dovrebbero avere lo stesso book_id (e le metriche dovrebbero essere aggiornate di conseguenza).\n",
    "#Ciò è fattibile con la window di SQL e una partitionby. Controlliamo, con un sampling casuale, se ci sono due libri provenienti dai due diversi database (controllare data_type).\n",
    "\n",
    "#DFmerged.filter(DFmerged.title == \"la custode di libri\").show() #TROVATO ERRORE DI RIPETIZIONE TUPLE A CAUSA DELLA MANCATA SCREMATURA DEL LINGUAGGIO DURANTE IL JOIN PER LE INFO SULL'AUTORE (SISTEMATO)\n",
    "\n",
    "#ERRORE 2: alcuni libri di anobii sono ripetuti due volte con un autore diverso (ma perché?), da sistemare con un'aggregazione\n",
    "#Prima, però. filtriamo via i titoli con una parola (dovrebbero essere pochi rispetto alla cardinalità totale e ci semplifica la vita con i libri omonimi)\n",
    "#print(DFmerged.count()) #CARDINALITà DATABASE MERGIATO COUNT = 10331428\n",
    "DFmerged_no_onewordtitles = DFmerged.filter(DFmerged.title.contains(\" \")) #Se contiene uno spazio allora non è una sola parola (sperando di aver formattato bene)\n",
    "#DFmerged_no_onewordtitles.filter(DFmerged_no_onewordtitles.title == \"barcellona\").show()\n",
    "#DFmerged.filter(DFmerged.title == \"barcellona\").show()\n",
    "\n",
    "#Procediamo adesso con la sostituzione dei book_id delle biblioteche con quelli di anobii\n",
    "DFmerged_aggregated = DFmerged_no_onewordtitles.select(\"*\", F.min(DFmerged_no_onewordtitles.item_id).over(Window.partitionBy(DFmerged_no_onewordtitles.title)).alias(\"book_id\"))\n",
    "#print(DFmerged_no_onewordtitles.count()) #DOPO L'ELIMINAZIONE DEI LIBRI CON UNA SOLA PAROLA COUNT = 8895429\n",
    "\n",
    "#Aggreghiamo adesso ripetizioni di uno stessa coppia (item_id, user_id) (PER ELIMINARE LE TUPLE RIPETUTE, VEDESI ERRORE 2 DOVUTO ALLA FORMATTAZIONE DI ANOBII)\n",
    "#DFmerged_aggregated.filter(DFmerged_aggregated.title == \"la custode di libri\").show()\n",
    "\n",
    "#Troviamo \"new_author\" formattato in maniera coerente fra i database mergiati\n",
    "DFmerged_aggregated_norepetition = DFmerged_aggregated.select(\"*\", F.min(DFmerged_aggregated.author_name).over(Window.partitionBy(DFmerged_aggregated.book_id)).alias(\"new_author\"))\n",
    "#DFmerged_aggregated_norepetition.filter(DFmerged_aggregated_norepetition.title == \"la custode di libri\").show()\n",
    "\n",
    "#Aggreghiamo anche i generi e l'encrypt_item_id\n",
    "\n",
    "\n",
    "#Infine, eliminiamo le ridondanze con dropDuplicates.\n",
    "DFmerged_aggregated_genres = DFmerged_aggregated_norepetition.select(\"*\", F.min(DFmerged_aggregated.genre).over(Window.partitionBy(DFmerged_aggregated.book_id)).alias(\"new_genre\"))\n",
    "DFmerged_aggregated_encrypt = DFmerged_aggregated_genres.select(\"*\", F.min(DFmerged_aggregated.encrypt_item_id).over(Window.partitionBy(DFmerged_aggregated.book_id)).alias(\"new_encrypt\"))            \n",
    "                                                        \n",
    "                                                              \n",
    "DFmerged_aggregated_norepetition_unique = DFmerged_aggregated_encrypt.dropDuplicates(['book_id', 'person_id'])\n",
    "#DFmerged_aggregated_norepetition_unique.filter(DFmerged_aggregated_norepetition_unique.title == \"la custode di libri\").show()\n",
    "\n",
    "#Infine, droppiamo gli attributi che non servono più e rinominiamo quelli nuovi e più utili\n",
    "DFmerged_final = DFmerged_aggregated_norepetition_unique.drop(\"item_id\").drop(\"author_name\").drop(\"encrypt_item_id\").drop(\"genre\")\n",
    "#ERRORE 2 SISTEMATO\n",
    "#DFmerged_final.filter(DFmerged_final.book_id == \"1254828\").show()\n",
    "#DFmerged_final.orderBy(rand()).show(50, False)\n",
    "#Adesso che il merge e gli attributi sono un po' più solidi possiamo provare a calcolare qualche metrica anche per le tuple della biblioteca\n",
    "#Prima però vorrei controllare una cosa\n",
    "\n",
    "#DFmerged_final.filter(DFmerged_final.title == \"1 ora\").show()\n",
    "#DFmerged_final.filter(DFmerged_final.title == \"un'ora\").show()\n",
    "\n",
    "#Ho provato superficialmente a considerare libri con un numero nel titolo per controllare se fossero formattati diversamente, continuerò il controllo più tardi\n",
    "#Una metrica da considerare per le tuple \"biblioteche\" potrebbe essere il numero di prestiti per un certo libro (sapere che un prestito è avvenuto 20 o 2000 volte è certamente un'info notevole)\n",
    "\n",
    "#Nota: sarebbe consono anche aggiornare le metriche di anobii post raggruppamento\n",
    "DFmerged_count = DFmerged_final.select(\"*\", F.count(\"*\").over(Window.partitionBy(DFmerged_final.book_id, DFmerged_final.data_type)).alias(\"total_count\"))\n",
    "#DFmerged_count.orderBy(rand()).show(50, False)\n",
    "DFmerged_average = DFmerged_count.select(\"*\", F.avg(DFmerged_final.item_review).over(Window.partitionBy(DFmerged_final.book_id, DFmerged_final.data_type)).alias(\"new_average_rating\"))\n",
    "DFmerged_maxreviews = DFmerged_average.select(\"*\", F.max(DFmerged_final.total_review).over(Window.partitionBy(DFmerged_final.book_id, DFmerged_final.data_type)).alias(\"new_total_review\"))\n",
    "\n",
    "#NOTA: l'average rating per le tuple delle biblioteche sarà, almeno per ora, ovviamente 4.0 per via dei voti fissi. new_number_reviews rappresenta il numero massimo di recensioni in caso di incongruenze.\n",
    "#DFmerged_sumreviews.orderBy(rand()).show(50, False)\n",
    "\n",
    "#Infine, inseriamo l'isbn anche per le tuple delle biblioteche  che abbiano una corrispondenza in anobii(potrebbe servire ed è anche utile per ricercare eventuali libri dalla formattazione errata)\n",
    "DFmerged_isbn = DFmerged_maxreviews.select(\"*\", F.min(DFmerged_maxreviews.isbn).over(Window.partitionBy(DFmerged_final.book_id)).alias(\"new_isbn\"))\n",
    "#DFmerged_isbn.orderBy(rand()).show(20, False)  \n",
    "\n",
    "#DFmerged_isbn.orderBy(rand()).filter(DFmerged_isbn.title == \"i giorni dell'arcobaleno\").show(50) #LIBRO PRESENTE SOLO NELLE BIBLIOTECHE TROVATO CON ISBN == None\n",
    "\n",
    "#Adesso droppiamo gli attributi inutili e rinominiamo quelli utili\n",
    "\n",
    "DFmerged_almost_definitive = DFmerged_isbn.drop(\"total_review\").drop(\"total_votes\").drop(\"average_rating\").drop(\"isbn\")\\\n",
    "                                          .withColumnRenamed(\"total_count\", \"total_votes_or_loans\")\\\n",
    "                                          .withColumnRenamed(\"new_average_rating\", \"average_rating\")\\\n",
    "                                          .withColumnRenamed(\"new_isbn\", \"isbn\")\\\n",
    "                                          .withColumnRenamed(\"new_total_review\", \"total_review\")\\\n",
    "                                          .withColumnRenamed(\"new_author\", \"author\")\\\n",
    "                                          .withColumnRenamed(\"new_genre\", \"genre\")\\\n",
    "                                          .withColumnRenamed(\"new_encrypt\", \"encrypt_item_id\")\n",
    "                                            \n",
    "\n",
    "#DFmerged_almost_definitive.show(1, False)\n",
    "#Adesso è il momento di attaccare gli indici di riga e colonna per la compressed sparse matrix tramite le funzioni che ho creato qualche cella fa.\n",
    "\n",
    "#DFmerged_almost_definitive.filter(typeof(DFmerged_almost_definitive.person_id) != str).show()\n",
    "RDDmerged_almost_definitive = DFmerged_almost_definitive.rdd\n",
    "#from itertools import islice\n",
    "\n",
    "#def take(n, iterable):\n",
    "#    \"Return first n items of the iterable as a list\"\n",
    "#    return list(islice(iterable, n))\n",
    "book_dictionary = create_book_dictionary(RDDmerged_almost_definitive)\n",
    "user_dictionary = create_user_dictionary(RDDmerged_almost_definitive)\n",
    "#n_items = take(20, user_dictionary.items())\n",
    "RDDdefinitive = RDDmerged_almost_definitive.map(addRowColumnId)\n",
    "#print(n_items)\n",
    "#print(RDDdefinitive.take(1))\n",
    "DFdefinitive = RDDdefinitive.toDF([\"person_id\", \"title\", \"sub_title\", \"item_review\", \"data_type\", \"book_id\", \"author\", \"genre\", \"encrypt_item_id\", \"total_votes_or_loans\",\\\n",
    "                                   \"average_rating\", \"total_review\", \"isbn\", \"user_index\", \"book_index\"], sampleRatio=0.9)\n",
    "#DFdefinitive.show(1, False) ###COLLABORATIVE FILTERING###\n",
    "#Merge per raccomandazione content based\n",
    "print(DFdefinitive.count()) #COUNT 5266964\n",
    "print(DFdefinitive.filter(DFdefinitive.genre!=\"null\").count()) #COUNT \n",
    "#Ho bisogno di un dataframe che contenga tutti i libri (dei dataset anobii e biblioteche) presenti post-filtraggio.\n",
    "#Per prima cosa, carichiamo DFmanifestations_definitive da cleanedData. (per eseguire cleanedData, vedere qualche cella sopra).\n",
    "\n",
    "#Come è fatto DFmanifestations_definitive?\n",
    "\n",
    "#DFmanifestations_definitive.show(10, False)\n",
    "# DFmanifestations_definitive.filter(DFmanifestations_definitive.manifestation_id_new == \"107930\").show()\n",
    "\n",
    "#Come possiamo vedere, il dataframe contiene i libri, presi una singola volta, secondo lo schema:\n",
    "#edition_language, edition_date, title, author, publisher, manifestation_id_new (che è il book_id).\n",
    "\n",
    "#E invece anobii? Per vedere i libri di anobii dobbiamo controllare DFitems_anobii.\n",
    "\n",
    "#DFitems_anobii.show(1, False)\n",
    "\n",
    "#NOTA: edition_date e edition_language di DFmanifestations_definitive sono eliminabili poiché non utili ai fini della raccomandazione\n",
    "#NOTA2: devo dividere titolo e sottotitolo come ho fatto per l'altro merge, oltre a rendere minuscoli tutti i caratteri\n",
    "#NOTA 3: il publisher deve rimanere per entrambi i dataset (e magari renderli coerenti)\n",
    "\n",
    "#Usiamo il dataset filtrato di DFitems_anobii: DFjoinbookstars (ha senso mantenere il filtraggio fatto rispetto ai numeri di voti in un content based? Da vedere)\n",
    "\n",
    "#DFjoinbookstars.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93c50e8-910b-423a-8983-d1eaf2b81339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------------------------------+---------+-----------+-----------+-------+-------------+--------+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "|person_id                       |title                               |sub_title|item_review|data_type  |book_id|author       |genre   |encrypt_item_id   |total_votes_or_loans|average_rating|total_review|isbn      |user_index|book_index|\n",
      "+--------------------------------+------------------------------------+---------+-----------+-----------+-------+-------------+--------+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "|0057b060eea06ee994b98c422b97f473|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|159       |176       |\n",
      "|0059a7e6d21805f9ebc6d58b5aa6042f|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|163       |176       |\n",
      "|01e6b77295a03c6bbf346400e2f07080|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|852       |176       |\n",
      "|01ec7118bdcdc09ada1647e6bd215f31|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|867       |176       |\n",
      "|022ffa50f53804ca2b82e2e9bd921d65|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|985       |176       |\n",
      "|02343094c8d5f0038c51421a48ae1a09|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|994       |176       |\n",
      "|023534288df4d266a9aa4ba3ef6b43ef|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|995       |176       |\n",
      "|027038febd8346ab8f88226cebddc5f4|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|1091      |176       |\n",
      "|02b52c188f745c7119b6da593dccaccb|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|1208      |176       |\n",
      "|02d22ac7fda06f74261e1206c1147a87|harry potter e la camera dei segreti|None     |4          |biblioteche|105503 |J. K. Rowling|Children|010990eaa2a97d8b83|793                 |4.0           |None        |0828877157|1261      |176       |\n",
      "+--------------------------------+------------------------------------+---------+-----------+-----------+-------+-------------+--------+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DFdefinitive.filter((DFdefinitive.title.contains(\"harry potter\")) & (DFdefinitive.data_type ==\"biblioteche\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accompanied-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDDmanifestations_definitive = DFmanifestations_definitive.rdd\n",
    "\n",
    "RDDmanifestations_trimmed = RDDmanifestations_definitive.map(title_and_subtitle_books)\n",
    "\n",
    "DFmanifestations_trimmed = RDDmanifestations_trimmed.toDF([\"title\", \"sub_title\", \"author\", \"publisher\", \"book_id\", \"isbn\"])\n",
    "DFmanifestations_lowercase = DFmanifestations_trimmed.select(lower(DFmanifestations_trimmed.title), lower(DFmanifestations_trimmed.sub_title), \"author\", \"publisher\", \"book_id\", \"isbn\")\\\n",
    "                                                     .withColumnRenamed(\"lower(title)\", \"title\")\\\n",
    "                                                     .withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "\n",
    "#DFmanifestations_lowercase.show(1, False)\n",
    "\n",
    "#NOTA: eliminiamo i libri con una sola parola nel titolo per ragioni analoghe a quelle del merge collaborativo\n",
    "DFmanifestations_nooneword = DFmanifestations_lowercase.filter(DFmanifestations_lowercase.title.contains(\" \"))\n",
    "# DFmanifestations_nooneword.show(1, False)\n",
    "\n",
    "#PER I NUOVI ATTRIBUTI\n",
    "DFmanifestations_nooneword = DFmanifestations_nooneword.withColumn(\"encrypt_item_id\", lit(None))\n",
    "DFmanifestations_nooneword = DFmanifestations_nooneword.withColumn(\"genre\", lit(None))\n",
    "DFmanifestations_nooneword = DFmanifestations_nooneword.select(\"title\", \"sub_title\", \"author\", \"publisher\", \"encrypt_item_id\", \"book_id\", \"isbn\", \"genre\")\n",
    "#print(DFmanifestations_lowercase.count()) #COUNT 18164\n",
    "#print(DFmanifestations_nooneword.count()) #COUNT 16143\n",
    "\n",
    "#Adesso, trimmiamo DFjoinbookstars.\n",
    "#NOTA: abbiamo bisogno dell'autore quindi dobbiamo fare un join con DFauthorsandbooks (vedere celle sopra)\n",
    "\n",
    "DFjoinbookstars_and_authors = DFjoinbookstars.join(DFauthorsandbooks, DFjoinbookstars.item_id == DFauthorsandbooks.item_id)\\\n",
    "                                             .select(lower(DFjoinbookstars.title), lower(DFjoinbookstars.sub_title), \"author_name\", \"publisher\", \"isbn\", DFjoinbookstars.item_id, )\\\n",
    "                                             .withColumnRenamed(\"author_name\", \"author\")\\\n",
    "                                             .withColumnRenamed(\"item_id\", \"book_id\")\\\n",
    "                                             .withColumnRenamed(\"lower(title)\", \"title\")\\\n",
    "                                             .withColumnRenamed(\"lower(sub_title)\", \"sub_title\")\n",
    "DFjoinbookstars_and_authors_nooneword = DFjoinbookstars_and_authors.filter(DFjoinbookstars_and_authors.title.contains(\" \"))\n",
    "# DFjoinbookstars_and_authors_nooneword.show(1, False)\n",
    "\n",
    "#print(DFjoinbookstars_and_authors.count()) #COUNT 8524\n",
    "#print(DFjoinbookstars_and_authors_nooneword.count()) #COUNT 7273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14382ca0-2f18-4422-9d2a-3d13b556c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fatto ciò, joiniamo questo dataset con quello dei libri finali (non DFbooks_final ma DFjoinbookstars_and_authors_nooneword\n",
    "#che è il dataset prima del merge). Dobbiamo quindi posticipare il merge con le biblioteche.\n",
    "\n",
    "DFmanifestations_with_encrypt = DFjoinbookstars_and_authors_nooneword.join(DFnew_data, DFnew_data.item_id == DFjoinbookstars_and_authors_nooneword.book_id).drop(DFnew_data.title).drop(DFnew_data.sub_title).drop(DFnew_data.publisher).drop(DFnew_data.isbn).select(\"title\", \"sub_title\", \"author\", \"publisher\", \"encrypt_item_id\", \"book_id\", \"isbn\")\n",
    "#DFmanifestations_with_encrypt.filter(DFmanifestations_with_encrypt.book_id == \"1981748\").show(10, False)\n",
    "\n",
    "#Fatto ciò, inseriamo anche il genere usando il file csv da me creato dal file item_category.sql \n",
    "#NOTA: avendolo dovuto rifare da zero per via di corruzioni del file originale è possibile ci siano delle righe\n",
    "#di rumore, eliminarle.\n",
    "#NOTA2: aggiungere new_genres.csv ad Hadoop. (FATTO)\n",
    "\n",
    "#Adesso, joiniamo usando item_id per ottenere il genere nelle tuple dei libri (più informazioni per il sistema di\n",
    "#raccomandazione).\n",
    "\n",
    "#NOTA:l'item_id nel DFgenres compare più volte. Questo immagina sia dovuto alla presenza di più generi su un solo libro.\n",
    "#Cercherò adesso di combinarli in un genere solo tramite una funzione RDD.\n",
    "\n",
    "RDDgenres = DFgenres.rdd\n",
    "RDDgenres.sortBy(lambda x: x.name) #Per avere i generi ordinati alfabeticamente\n",
    "RDDgenres_keyvalue = RDDgenres.map(lambda x: (x.itemid, list(x)))\n",
    "#print(RDDgenres_keyvalue.take(1))\n",
    "\n",
    "def reduceGenres(x, y): #Ritorna il libro con i generi accorpati\n",
    "    return [x[0], x[1], x[2], x[3], x[4] + \" / \" + y[4], x[5] + \" / \" + y[5], x[6], x[7]]\n",
    "\n",
    "RDDreduced = RDDgenres_keyvalue.reduceByKey(reduceGenres)\n",
    "#print(RDDreduced.take(1))\n",
    "\n",
    "#La funzione di reduce sembra funzionare. Riportiamolo in forma di RDD singolo e poi di dataframe.\n",
    "def toSingle(line):\n",
    "    return Row(str(line[1][0]), str(line[1][1]), str(line[1][2]), str(line[1][3]), str(line[1][4]), str(line[1][5]), str(line[1][6]), str(line[1][7]))\n",
    "RDDsingle = RDDreduced.map(toSingle)\n",
    "#print(RDDsingle.take(20))\n",
    "DFgenres_agg = RDDsingle.toDF(['id', 'familyid', 'book_id', 'categoryid', 'slug', 'genre', 'language', 'votes'])\n",
    "#DFgenres_agg.show(1, False)\n",
    "#NOTA2: bisogna anche raggruppare le ripetizioni dei libri dovute ai diversi autori\n",
    "#Questo tipo di aggregazione si può fare (per ora) con una aggregazione partitionBy\n",
    "#NOTA PER IL FUTURO: implementare funzione per aggregare gli autori in maniera simile alla funzione\n",
    "#reduceGenres per evitare l'aggregazione per ordine alfabetico (ciò vale anche per l'altra aggregazione per autore)\n",
    "#DFmanifestations_with_encrypt.filter(DFmanifestations_with_encrypt.book_id==\"2421303\").show()\n",
    "DFmanifestations_with_encrypt_agg_author = DFmanifestations_with_encrypt.select(\"*\", F.min(DFmanifestations_with_encrypt.author).over(Window.partitionBy(DFmanifestations_with_encrypt.book_id)).alias(\"new_author\")).drop(\"author\").withColumnRenamed(\"new_author\", \"author\").dropDuplicates(['book_id', 'author'])\n",
    "DFbooks_with_genres = DFmanifestations_with_encrypt_agg_author.join(DFgenres_agg, DFgenres_agg.book_id == DFmanifestations_with_encrypt_agg_author.book_id).drop(DFmanifestations_with_encrypt_agg_author.book_id).select(\"title\", \"sub_title\", \"author\", \"publisher\", \"encrypt_item_id\", \"book_id\", \"isbn\", \"genre\")\n",
    "#DFbooks_with_genres.show(20, False)\n",
    "#DFbooks_with_genres.filter(DFbooks_with_genres.title==\"il mercante di quadri scomparsi\").show()\n",
    "#Possiamo adesso procedere con il merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e5f17b-ce96-415e-8689-bdfa3d8ddcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gli attributi sono gli stessi: procediamo al merge\n",
    "\n",
    "DFcontentbased_merge = DFmanifestations_nooneword.union(DFbooks_with_genres)\n",
    "\n",
    "#Adesso dobbiamo raggruppare sotto lo stesso id i libri uguali ma provenienti da due dataset diversi\n",
    "\n",
    "DFbooks_sameisbn = DFcontentbased_merge.select(\"*\", F.min(DFcontentbased_merge.isbn).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_isbn\"))\n",
    "DFbooks_sameid = DFbooks_sameisbn.select(\"*\", F.min(DFcontentbased_merge.book_id).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_book_id\"))\n",
    "#Approfittiamone per raggruppare anche autori e publisher (per rendere le tuple più coerenti) (serve?)\n",
    "DFbooks_samepublisher = DFbooks_sameid.select(\"*\", F.min(DFcontentbased_merge.publisher).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_publisher\"))\n",
    "DFbooks_sameauthor = DFbooks_samepublisher.select(\"*\", F.min(DFcontentbased_merge.author).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_author\"))\n",
    "#E raggruppiamo anche il genere e l'encrypted_item_id\n",
    "DFbooks_samegenre = DFbooks_sameauthor.select(\"*\", F.min(DFcontentbased_merge.genre).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_genre\"))\n",
    "DFbooks_sameencrypted = DFbooks_samegenre.select(\"*\", F.min(DFcontentbased_merge.encrypt_item_id).over(Window.partitionBy(DFcontentbased_merge.title)).alias(\"new_encrypted\"))\n",
    "#Droppiamo i vecchi attributi e lasciamo i nuovi\n",
    "\n",
    "DFbooks_dropid = DFbooks_sameencrypted.drop(\"book_id\").drop(\"publisher\").drop(\"author\").drop(\"encrypt_item_id\").drop(\"genre\").drop(\"isbn\")\\\n",
    "                                   .withColumnRenamed(\"new_book_id\", \"book_id\")\\\n",
    "                                   .withColumnRenamed(\"new_author\", \"author\")\\\n",
    "                                   .withColumnRenamed(\"new_publisher\", \"publisher\")\\\n",
    "                                   .withColumnRenamed(\"new_isbn\", \"isbn\")\\\n",
    "                                   .withColumnRenamed(\"new_genre\", \"genre\")\\\n",
    "                                   .withColumnRenamed(\"new_encrypted\", \"encrypt_item_id\")\n",
    "#Adesso droppiamo i duplicati\n",
    "\n",
    "DFbooks_final = DFbooks_dropid.dropDuplicates([\"book_id\", \"author\", \"publisher\"])\n",
    "\n",
    "#DFbooks_final.orderBy(rand()).show(100, False)\n",
    "#DFbooks_final.filter(DFbooks_final.title==\"l'eleganza del riccio\").show()\n",
    "#print(DFbooks_final.count()) #COUNT 16329\n",
    "#print(DFbooks_final.filter(DFbooks_final.genre!=None).count()) #COUNT 2782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a7575f20-37f9-4822-8972-e713f7ce3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salviamo DFbooks_final con i nuovi attributi in un file csv\n",
    "#DFbooks_final.toPandas().to_csv(\"books_with_new_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "million-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------------+----------+-------+---------+-------------------+-----+---------------+-----------+--------------------+--------------+------------+----------+\n",
      "|title               |sub_title                   |isbn      |book_id|publisher|author             |genre|encrypt_item_id|data_type  |total_votes_or_loans|average_rating|total_review|book_index|\n",
      "+--------------------+----------------------------+----------+-------+---------+-------------------+-----+---------------+-----------+--------------------+--------------+------------+----------+\n",
      "|il fiore di vincenzo|storia di un pittore in erba|8882032450|125592 |Nord-Sud |Valerij H. Horbačov|null |null           |biblioteche|68                  |4.0           |None        |803       |\n",
      "+--------------------+----------------------------+----------+-------+---------+-------------------+-----+---------------+-----------+--------------------+--------------+------------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "there are 16316 books\n",
      "+--------------------------------+-----------+-------+\n",
      "|person_id                       |item_review|book_id|\n",
      "+--------------------------------+-----------+-------+\n",
      "|0044c777bfead9d4d026906f07d02bae|4          |125592 |\n",
      "+--------------------------------+-----------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "there are 5261501 rates\n",
      "+---------+----------+\n",
      "|person_id|user_index|\n",
      "+---------+----------+\n",
      "|1236832  |20704     |\n",
      "+---------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "there are 254847 users\n"
     ]
    }
   ],
   "source": [
    "books = DFbooks_final\n",
    "# books.filter(books.title == \"il fiore di vincenzo\").show(1, False)\n",
    "ratings = DFdefinitive\n",
    "# ratings.filter(ratings.title == \"il fiore di vincenzo\").show(1, False)\n",
    "\n",
    "#take data in ratings that must be placed in books table\n",
    "isnbnForbook_id = ratings.dropDuplicates([\"book_id\"])\n",
    "# isnbnForbook_id.show(1, False)\n",
    "books_tocsv = books.join(isnbnForbook_id, books.book_id == isnbnForbook_id.book_id).select(books[\"*\"],\\\n",
    "                                                                             isnbnForbook_id[\"data_type\"], \n",
    "                                                                             isnbnForbook_id[\"total_votes_or_loans\"],\n",
    "                                                                             isnbnForbook_id[\"average_rating\"],\n",
    "                                                                             isnbnForbook_id[\"total_review\"],\n",
    "                                                                             isnbnForbook_id[\"book_index\"])\n",
    "#drop books which has null isbn\n",
    "books_tocsv = books_tocsv.filter(books_tocsv.isbn.isNotNull()).na.drop(subset=[\"isbn\"])\n",
    "books_tocsv.show(1, False)\n",
    "books_tocsv.toPandas().to_csv(\"books.csv\")\n",
    "print(\"there are \"+str(books_tocsv.count())+\" books\")\n",
    "\n",
    "toDrop = [#\"person_id\",\n",
    "          \"title\",\n",
    "          \"sub_title\",\n",
    "          \"data_type\",\n",
    "          \"author\",\n",
    "          \"total_votes_or_loans\",\n",
    "          \"average_rating\",\n",
    "          \"total_review\",\n",
    "          \"isbn\",\n",
    "          \"genre\", \n",
    "          \"encrypt_item_id\",\n",
    "          \"user_index\",\n",
    "          \"book_index\",\n",
    "          ]\n",
    "ratings_tocsv = ratings.drop(*toDrop)\n",
    "# ratings_tocsv.show(1, False)\n",
    "ratings_tocsv = ratings_tocsv.join(books_tocsv, books_tocsv.book_id == ratings.book_id, \"leftsemi\")\n",
    "ratings_tocsv.show(1, False)\n",
    "ratings_tocsv.toPandas().to_csv(\"ratings.csv\")\n",
    "print(\"there are \"+str(ratings_tocsv.count())+\" rates\")\n",
    "\n",
    "users_tocsv = ratings.select(\"person_id\", \"user_index\").dropDuplicates()\n",
    "users_tocsv.show(1, False)\n",
    "users_tocsv.toPandas().to_csv(\"users.csv\")\n",
    "print(\"there are \"+str(users_tocsv.count())+\" users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brazilian-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#  write file for doing API  #\n",
    "#google book requests (local)#\n",
    "##############################\n",
    "id2isbn = books_tocsv.select(['book_id', 'isbn']).rdd.map(lambda row : (row[0],row[1])).collectAsMap()\n",
    "with open('id2isbn.csv', 'w') as f:\n",
    "    for key in id2isbn.keys():\n",
    "        f.write(\"%s, %s\\n\" % (key, id2isbn[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4e5c5e-be14-445a-b796-a6b64931b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16329\n",
      "2782\n"
     ]
    }
   ],
   "source": [
    "print(books.count()) #16329\n",
    "print(books.filter(books.genre!= \"null\").count()) #2782\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad9a1a78-d876-4cdb-b523-c5dbedeef2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-----------------------+---------+-----------+-----------+-------+---------------+-----+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "|person_id                       |title                  |sub_title|item_review|data_type  |book_id|author         |genre|encrypt_item_id   |total_votes_or_loans|average_rating|total_review|isbn      |user_index|book_index|\n",
      "+--------------------------------+-----------------------+---------+-----------+-----------+-------+---------------+-----+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "|0035874fe0c316bce3db526c79840c0b|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|89        |2705      |\n",
      "|069c8bd97ef5e01185405e2a1740a300|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|2966      |2705      |\n",
      "|074765c1797de2a792be2111f2366edd|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|3277      |2705      |\n",
      "|0969564c18cf69fb6b4182f0f56e83bf|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|4259      |2705      |\n",
      "|09d4b2fe7059a1d520ee9ef4d9c81611|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|4474      |2705      |\n",
      "|0aff79643e0e8ce75a892aa9a9e736f4|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|5036      |2705      |\n",
      "|0b042def78a422e6eaa1af56349a917a|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|5045      |2705      |\n",
      "|0d5ed7d7170dec64f64f2086fdae7d71|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|6182      |2705      |\n",
      "|0d82aecd38517116e7ebfcf77d6b3be3|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|6244      |2705      |\n",
      "|0e5b57c72476fef56501d76ad38d7001|la variante di lüneburg|None     |4          |biblioteche|18726  |Paolo Maurensig|Crime|016eecb4d5426b7dcb|137                 |4.0           |None        |8845909840|6647      |2705      |\n",
      "+--------------------------------+-----------------------+---------+-----------+-----------+-------+---------------+-----+------------------+--------------------+--------------+------------+----------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#books_tocsv.filter((books_tocsv.genre!=\"null\") & (books_tocsv.data_type == \"biblioteche\")).show(10, False)\n",
    "\n",
    "#NOTA: forse è meglio droppare i duplicati che contengono \"anobii\" e non quelli delle biblioteche, per avere\n",
    "#un'idea di quanti libri delle biblioteche abbiano il genere\n",
    "\n",
    "ratings.filter((ratings.genre!=\"null\") & (ratings.data_type == \"biblioteche\")).show(10, False)\n",
    "\n",
    "#Infatti in ratings questo tipo di caso è presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48194831-9a22-4f09-8c62-190216c05cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
