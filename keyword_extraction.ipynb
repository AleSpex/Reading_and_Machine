{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e95ff-be19-44cc-bed4-d1a6ef4964b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###KEYWORD EXTRACTION###\n",
    "\n",
    "#Each book must have a non empty description of at least 50 characters.\n",
    "\n",
    "#SPACY PIPELINE FUNCTIONS\n",
    "#Keyword extraction with TF-IDF\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "def scores_ordering(coo_matrix): #Function to order the matrix by score\n",
    "        tuples = zip(coo_matrix.col, coo_matrix.data) #COLUMNS: FEATURES ROWS: DESCRIPTIONS\n",
    "        return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def top_extraction(feature_names, sorted_items, topn=5): #Function to obtain N keywords\n",
    "    #print(feature_names)\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    return results\n",
    "\n",
    "def get_keywords(vectorizer, feature_names, doc, k): #Funzione usata per ritornare le top k parole chiave di una descrizione\n",
    "    tf_idf_vector = vectorizer.transform([doc])\n",
    "    sorted_items=scores_ordering(tf_idf_vector.tocoo())\n",
    "    keywords=top_extraction(feature_names,sorted_items, k) #20 keyword per ora\n",
    "\n",
    "    return list(keywords.keys())\n",
    "\n",
    "def keywordCoverage(dictionary, dataframe): #To calculate the coverage of a keyword in the dataset\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    temp_dictionary = dictionary.copy()\n",
    "    temp_subset = dataframe['top_keywords'].to_list()\n",
    "    while True:\n",
    "        \n",
    "        max_coverage_count = 0\n",
    "        chosen_keyword = \"\"\n",
    "        \n",
    "        for keyword in temp_dictionary:\n",
    "        \n",
    "            coverage_count = len([item for item in temp_subset if keyword in item])\n",
    "            if coverage_count > max_coverage_count:\n",
    "                max_coverage_count = coverage_count\n",
    "                chosen_keyword = keyword\n",
    "            \n",
    "        try:\n",
    "            choice = input(f\"La parola scelta è {chosen_keyword}. Ha una coverage di {max_coverage_count}. La lunghezza rimanente del dataset è {len(temp_subset)}. (y/n)\")\n",
    "\n",
    "            if choice == \"y\":\n",
    "                temp_dictionary.pop(chosen_keyword)\n",
    "                output_list.append(chosen_keyword)\n",
    "                temp_subset = [item for item in temp_subset if chosen_keyword not in item]\n",
    "                print(\"KEYWORD SCELTA\")\n",
    "                if len(temp_subset) == 0:\n",
    "                    break\n",
    "                if len(output_list) == 20:\n",
    "                    print(\"Limite di 20 keywords raggiunto. Ritorno la lista di keywords del genere.\")\n",
    "                    return output_list \n",
    "            elif choice == \"n\":\n",
    "                temp_dictionary.pop(chosen_keyword)\n",
    "                print(\"KEYWORD SCARTATA\")\n",
    "                if len(temp_subset) == 0:\n",
    "                    break\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Scegliere una scelta possibile (y/n).\")\n",
    "        \n",
    "    return output_list\n",
    "\n",
    "def countOccurrencies(dictionary, reference_list): #Count occurrences in keyword list\n",
    "        for keyword in reference_list:\n",
    "            if keyword in dictionary:\n",
    "                dictionary[keyword] += 1\n",
    "            elif keyword not in dictionary:\n",
    "                dictionary[keyword] = 1\n",
    "        return dictionary\n",
    "\n",
    "def clean_text_light(doc_collection): #FILTERING NOTABLE MEANINGLESS WORDS\n",
    "    new_corpus_doc = []\n",
    "    for description in doc_collection:\n",
    "        description = description.replace(\"agrave\", \" \")\n",
    "        description = description.replace(\"egrave\", \" \")\n",
    "        description = description.replace(\"igrave\", \" \")\n",
    "        description = description.replace(\"ograve\", \" \")\n",
    "        description = description.replace(\"ograve\", \" \")\n",
    "        description = description.replace(\"<b>\", \" \")\n",
    "        description = description.replace(\",\", \" \")\n",
    "        description = description.replace(\"'\", \" \")\n",
    "        description = description.replace('\"', \" \")\n",
    "        description = description.replace(\"<b>\", \" \")\n",
    "        description = description.replace(\"<br />\", \" \")\n",
    "        description = description.replace(\"</b>\", \" \")\n",
    "        description = description.replace(\"<br>\", \" \")\n",
    "        description = description.replace(\"</br>\", \" \")\n",
    "        description = description.replace(\"<p>\", \" \")\n",
    "        description = description.replace(\"</p>\", \" \")\n",
    "        description = description.replace(\"<P>\", \" \")\n",
    "        description = description.replace(\"</P>\", \" \")\n",
    "        description = description.replace(\"<i>\", \" \")\n",
    "        description = description.replace(\"</i>\", \" \")\n",
    "        description = description.replace(\"&quot\", \" \")\n",
    "        description = description.replace(\"<strong>\", \" \")\n",
    "        description = description.replace(\"</strong>\", \" \")\n",
    "        description = description.replace(\"&\", \" \")  \n",
    "        #KEYWORD PRESENTI MA NON MOLTO UTILI\n",
    "        pattern = re.compile(re.escape(\"leggere\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"lettrice\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"lettore\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"lettori\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"lettura\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"libro\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"libri\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mese \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mesi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"tempo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"tempi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"parte \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"parti \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" cosa \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" cose \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" personaggio \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" personaggi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" volume \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" volumi\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" protagonista\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" protagonisti\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" testo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" testi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" pagina \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" pagine \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" secolo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" secoli \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" persona \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" persone \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"scrittore \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" scrittrice \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" scrittrici \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" scrittori \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        #pattern = re.compile(re.escape(\" vic\"), re.IGNORECASE)\n",
    "        #description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" fine \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"nome \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"nomi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"inizio \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" parola \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" parole \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        #pattern = re.compile(re.escape(\" ista\"), re.IGNORECASE)\n",
    "        #description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"modo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" numero \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" punto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" centro \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        #pattern = re.compile(re.escape(\"ora \"), re.IGNORECASE)\n",
    "        #description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" frattempo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mezzo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mezzi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" corso \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" situazione \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" piano \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" via \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" vie \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" forma \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" forme \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" posto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" posti \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" fronte \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" luogo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"autore \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" autori \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" autrici \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"autrice \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" grazie \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" fatto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" fatti \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"edizione \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" edizioni \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" opere \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" serie \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" tema \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" temi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" grado \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" gradi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" genere \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" generi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" titolo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" titoli \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"oggetto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" oggetti \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" tempo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" tempi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" sfondo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" sfondi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" conto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" conti \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" volta \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" volte \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        #pattern = re.compile(re.escape(\" race\"), re.IGNORECASE)\n",
    "        #description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" scena \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" scene \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"età \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" figura \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" figure \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"epoca \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" epoche\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"none\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"libreria\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"librerie\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"biblioteca\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"biblioteche\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"generazione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"generazioni\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mano \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" mani \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"aspetto \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"titolo\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"produzione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" senso \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" trama \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" trame \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"racconto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"racconti\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"capitolo\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"capitoli\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" fondo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"domanda\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"risposta\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"domande\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"risposte\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"versione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"argomento\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"argomenti\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" tesi \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"italiano\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"effetto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" carta \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"bisogno\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"bisogni\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"analisi\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"momento\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"milione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"disegno\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" dono \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"successo\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"traduzione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" penna \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"regola\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"regole\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"progetto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"esempio\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"narrazione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" data \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"pratica\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"frase\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"ultimo\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"base\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"effetto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"attenzione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"motivo\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"essere\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"linguaggio\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" lingua \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"lavoro\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"critica\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"aspetto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"introduzione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"episodio\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"livello\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"pubblicazione\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\" pezzo \"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"interesse\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"consiglio\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        pattern = re.compile(re.escape(\"effetto\"), re.IGNORECASE)\n",
    "        description = pattern.sub(' ', description)\n",
    "        #pattern = re.compile(re.escape(\"ore\"), re.IGNORECASE)\n",
    "        #description = pattern.sub(' ', description)\n",
    "       \n",
    "        new_corpus_doc.append(description)\n",
    "    return new_corpus_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42dd0c-57c9-46a6-a6b9-68e3d8676b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: BOOKS_TOCSV IS THE OUTPUT OF THE MERGED DATASET.\n",
    "\n",
    "#FEATURES CREATION: KEYWORDS PER EACH BOOK CONSIDERING COMMENTS\n",
    "\n",
    "#WITH COMMENTS 80 LENGTH\n",
    "\n",
    "DFcontent_pandas = books_tocsv.toPandas()\n",
    "corpus_doc = DFcontent_pandas['content'].to_list() #Descriptions collection\n",
    "cleaned_corpus = clean_text_light(corpus_doc) #Filtering meaningless and notable words\n",
    "id_list = DFcontent_pandas['book_id'].to_list()\n",
    "new_corpus_doc = []\n",
    "nlp = spacy.load(\"it_core_news_lg\") #Load spacy dictionary file to keeep just nouns \n",
    "\n",
    "for document in cleaned_corpus:\n",
    "    noun_tokens = []\n",
    "    doc = nlp(document)\n",
    "    for token in doc:\n",
    "        if (token.pos_ == \"NOUN\") and token.is_oov==False: #Only vocabulary names\n",
    "            noun_tokens.append(token.lemma_)\n",
    "    new_document = (\" \").join(noun_tokens)\n",
    "    new_corpus_doc.append(new_document)\n",
    "vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True) \n",
    "vectorizer.fit_transform(new_corpus_doc) #Dictionary creation\n",
    "feature_names = vectorizer.get_feature_names_out() #Terms list\n",
    "\n",
    "result = []\n",
    "for descrizione, identifier in zip(new_corpus_doc, id_list): #keywprds features (variable k)\n",
    "    df = {}\n",
    "    df['book_id'] = identifier\n",
    "    df['top_keywords_5_with_comment'] = get_keywords(vectorizer, feature_names, descrizione, 5)\n",
    "    df['top_keywords_10_with_comment'] = get_keywords(vectorizer, feature_names, descrizione, 10)\n",
    "    df['top_keywords_15_with_comment'] = get_keywords(vectorizer, feature_names, descrizione, 15)\n",
    "    df['top_keywords_20_with_comment'] = get_keywords(vectorizer, feature_names, descrizione, 20)\n",
    "    result.append(df)\n",
    "\n",
    "DFkeywords = pd.DataFrame(result)\n",
    "\n",
    "DFbooks_integrated = DFcontent_pandas.merge(DFkeywords, on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55880460-cc4e-41d5-a5c7-d1eb8f780941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT COMMENTS\n",
    "\n",
    "DFcontent_pandas = books_tocsv.toPandas()\n",
    "corpus_doc = DFcontent_pandas['content2'].to_list()\n",
    "cleaned_corpus = clean_text_light(corpus_doc)\n",
    "id_list = DFcontent_pandas['book_id'].to_list()\n",
    "new_corpus_doc = []\n",
    "\n",
    "for document in cleaned_corpus:\n",
    "    noun_tokens = []\n",
    "    doc = nlp(document)\n",
    "    for token in doc:\n",
    "        if (token.pos_ == \"NOUN\") and token.is_oov==False: #Only vocabulary names\n",
    "            noun_tokens.append(token.lemma_)\n",
    "    new_document = (\" \").join(noun_tokens)\n",
    "    new_corpus_doc.append(new_document)\n",
    "vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True) \n",
    "vectorizer.fit_transform(new_corpus_doc) #Dictionary creation\n",
    "feature_names = vectorizer.get_feature_names_out() #Terms list\n",
    "\n",
    "result = []\n",
    "for descrizione, identifier in zip(new_corpus_doc, id_list):\n",
    "    df = {}\n",
    "    df['book_id'] = identifier\n",
    "    df['top_keywords_5_without_comm'] = get_keywords(vectorizer, feature_names, descrizione, 5)\n",
    "    df['top_keywords_10_without_comm'] = get_keywords(vectorizer, feature_names, descrizione, 10)\n",
    "    df['top_keywords_15_without_comm'] = get_keywords(vectorizer, feature_names, descrizione, 15)\n",
    "    df['top_keywords_20_without_comm'] = get_keywords(vectorizer, feature_names, descrizione, 20)\n",
    "    result.append(df)\n",
    "\n",
    "DFkeywords = pd.DataFrame(result)\n",
    "\n",
    "DFbooks_integrated_without = DFbooks_integrated.merge(DFkeywords, on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd705ed8-d17b-47fc-9581-ecc3ecc51d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFbooks_integrated_without.to_csv('2_keywords_and_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e4f4c-c6e2-4a4c-a31b-bc522b391812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENRE KEYWORDS\n",
    "import numpy as np\n",
    "\n",
    "mapping = {'Comics&GraphicNovels': 0,\n",
    "              'Family-Sex&Relationships': 1,\n",
    "              'Humor': 2,\n",
    "              'History': 3,\n",
    "              'ScienceFiction&Fantasy': 4,\n",
    "              'Romance': 5,\n",
    "              'Travel': 6,\n",
    "              'Mystery&Thrillers': 7,\n",
    "              'FreeTime': 8,\n",
    "              'Non-fiction': 9,\n",
    "              'Biography': 10,\n",
    "              'SocialScience': 11,\n",
    "              'Political': 12,\n",
    "              'Crime': 13,\n",
    "              'Children&Teens': 14,\n",
    "              'Philosophy': 15,\n",
    "              'Horror': 16,\n",
    "              'Health-Mind&Body': 17,\n",
    "              'Professional&Technical': 18,\n",
    "              'Science&Nature': 19}\n",
    "              #'Fiction&Literature': 20}\n",
    "\n",
    "DFchosen_keywords = pd.DataFrame()\n",
    "DFcontent_pandas = books_tocsv.toPandas()\n",
    "possible_keywords = [50]\n",
    "average_percentages = average_percentages = [49.086402663093516, 65.79894419074137, 75.69834836556531, 82.83928946909826, 91.31414622247611]\n",
    "for number_keywords in possible_keywords:\n",
    "    percentages = []\n",
    "    for key in mapping:\n",
    "        chosen_genre_keywords = []\n",
    "        current_coverage = 0\n",
    "        print(f'Total number of books is {DFcontent_pandas.shape[0]}') \n",
    "        masking = DFcontent_pandas.genre.apply(lambda x: key in x.keys())\n",
    "        print(f'The current genre is {key}')\n",
    "        DFcontent_pandas_masked = DFcontent_pandas[masking]\n",
    "        print(f'Number of books of that genre is {DFcontent_pandas_masked.shape[0]}')\n",
    "        corpus_doc = DFcontent_pandas_masked['content'].to_list()\n",
    "        cleaned_corpus_doc = clean_text_light(corpus_doc) #Pulizia rumori\n",
    "\n",
    "        max_coverage = DFcontent_pandas_masked.shape[0]\n",
    "\n",
    "        new_corpus_doc = []\n",
    "        for document in cleaned_corpus_doc:\n",
    "            noun_tokens = []\n",
    "            doc = nlp(document)\n",
    "            for token in doc:\n",
    "                if (token.pos_ == \"NOUN\") and token.is_oov==False: #Solo nomi presenti nel vocabolario italiano\n",
    "                    noun_tokens.append(token.lemma_)\n",
    "            new_document = (\" \").join(noun_tokens)\n",
    "            new_corpus_doc.append(new_document)\n",
    "        vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True) #Di solito 0.60, 40\n",
    "        vectorizer.fit_transform(new_corpus_doc) #CREAZIONE DIZIONARIO CON I VOCABOLI CONTENUTI NELLE DESCRIZIONI\n",
    "        feature_names = vectorizer.get_feature_names_out() #Estrae le feature (i vocaboli) importanti\n",
    "\n",
    "        id_list = DFcontent_pandas_masked['book_id'].to_list()\n",
    "        result = []\n",
    "        for descrizione, identifier in zip(new_corpus_doc, id_list):\n",
    "            df = {}\n",
    "            df['book_id'] = identifier\n",
    "            df['top_keywords_20'] = get_keywords(vectorizer, feature_names, descrizione, 50)\n",
    "            result.append(df)\n",
    "\n",
    "        DFkeywords = pd.DataFrame(result)\n",
    "        DFkeywords_copy = DFkeywords.copy()\n",
    "        #Take the first 20 keywords\n",
    "        #print(DFkeywords.shape)\n",
    "        for i in range(0,20):\n",
    "            if DFkeywords_copy.shape[0] == 0:\n",
    "                break\n",
    "            keywords_list = DFkeywords_copy['top_keywords_20'].to_list()\n",
    "            flat_list = [keyword for keywords_sublist in keywords_list for keyword in keywords_sublist]\n",
    "\n",
    "            #Counting occurrences of keywords\n",
    "            dict_occurrences = {}\n",
    "            for keyword in flat_list:\n",
    "                if keyword in dict_occurrences.keys():\n",
    "                    dict_occurrences[keyword] += 1\n",
    "                else:\n",
    "                    dict_occurrences[keyword] = 1\n",
    "            dict_occurrences = dict(sorted(dict_occurrences.items(), key=lambda item: item[1], reverse=True))\n",
    "            chosen_keyword = list(dict_occurrences.keys())[0:1]\n",
    "            chosen_genre_keywords.append(chosen_keyword[0])\n",
    "            current_coverage += int(list(dict_occurrences.values())[0])\n",
    "            coverage_percentage = (current_coverage/max_coverage) * 100\n",
    "            DFkeywords_mask = DFkeywords_copy.top_keywords_20.apply(lambda x: chosen_keyword[0] not in x)\n",
    "            DFkeywords_copy = DFkeywords_copy[DFkeywords_mask]\n",
    "        print(f'You have covered {coverage_percentage}% of the {key} books')  \n",
    "        print(f'Chosen keywords for genre {key} are:')\n",
    "        print(chosen_genre_keywords)\n",
    "        DFchosen_keywords = DFchosen_keywords.append(pd.DataFrame({'genre': key, 'keywords': [chosen_genre_keywords], 'coverage': coverage_percentage}))\n",
    "        DFchosen_keywords.to_csv(f'50_prova_keywords.csv', index=False)\n",
    "        print(DFchosen_keywords)\n",
    "        percentages.append(coverage_percentage)\n",
    "    percentages_np = np.asarray(percentages)\n",
    "    percentage_mean = np.mean(percentages_np)\n",
    "    average_percentages.append(percentage_mean)\n",
    "    print(average_percentages)\n",
    "    \n",
    "if False:\n",
    "    #Keywords graph coverage\n",
    "    possible_keywords = [5, 10, 15, 20, 30, 50]\n",
    "    average_percentages = [49.086402663093516, 65.79894419074137, 75.69834836556531, 82.83928946909826, 91.31414622247611, 98.63530510583139]\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(possible_keywords, average_percentages)\n",
    "    plt.xlabel('Number of keywords per book')\n",
    "    plt.ylabel('Coverage percentage')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0788e63-f0d9-48a3-ba64-ac012d2d2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEYWORD MANUAL TUNING\n",
    "while True:\n",
    "    print('Welcome to the manual tuning interface. Choose a genre.')\n",
    "    print('Write exit to close the interface.')\n",
    "    DFkeywords_50 = pd.read_csv('50_prova_keywords.csv')\n",
    "    display(DFkeywords_50)\n",
    "    genre = input()\n",
    "    if genre == 'exit':\n",
    "        break\n",
    "    elif genre not in list(mapping.keys()):\n",
    "        print('Error, not existing genre')\n",
    "    else:\n",
    "        print('These are the chosen keywords for that genre.')\n",
    "        list_keywords = DFkeywords_50['keywords'].to_list()\n",
    "        coverage = DFkeywords_50['coverage'].to_list()[mapping[genre]]\n",
    "        coverage_start = 0\n",
    "        print(list_keywords[mapping[genre]])\n",
    "        print('Choose a keyword to substitute or write exit to exit.')\n",
    "        substitute = input()\n",
    "        list_words = eval(list_keywords[mapping[genre]])\n",
    "        \n",
    "        if substitute == 'exit':\n",
    "            break\n",
    "        elif substitute not in list_words:\n",
    "            print()\n",
    "            print('Error, keyword not present.')\n",
    "        else:\n",
    "            print('Calculating possible keywords..')\n",
    "            chosen_genre_keywords = []\n",
    "            masking = DFcontent_pandas.genre.apply(lambda x: genre in x.keys())\n",
    "            DFcontent_pandas_masked = DFcontent_pandas[masking]\n",
    "            corpus_doc = DFcontent_pandas_masked['content'].to_list()\n",
    "            cleaned_corpus_doc = clean_text_light(corpus_doc) #Pulizia rumori\n",
    "\n",
    "            max_coverage = DFcontent_pandas_masked.shape[0]\n",
    "\n",
    "            new_corpus_doc = []\n",
    "            for document in cleaned_corpus_doc:\n",
    "                noun_tokens = []\n",
    "                doc = nlp(document)\n",
    "                for token in doc:\n",
    "                    if (token.pos_ == \"NOUN\") and token.is_oov==False: #Solo nomi presenti nel vocabolario italiano\n",
    "                        noun_tokens.append(token.lemma_)\n",
    "                new_document = (\" \").join(noun_tokens)\n",
    "                new_corpus_doc.append(new_document)\n",
    "            vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True) #Di solito 0.60, 40\n",
    "            vectorizer.fit_transform(new_corpus_doc) #CREAZIONE DIZIONARIO CON I VOCABOLI CONTENUTI NELLE DESCRIZIONI\n",
    "            feature_names = vectorizer.get_feature_names_out() #Estrae le feature (i vocaboli) importanti\n",
    "\n",
    "            id_list = DFcontent_pandas_masked['book_id'].to_list()\n",
    "            result = []\n",
    "            for descrizione, identifier in zip(new_corpus_doc, id_list):\n",
    "                df = {}\n",
    "                df['book_id'] = identifier\n",
    "                df['top_keywords_20'] = get_keywords(vectorizer, feature_names, descrizione, 50)\n",
    "                result.append(df)\n",
    "\n",
    "            DFkeywords = pd.DataFrame(result)\n",
    "            DFkeywords_copy = DFkeywords.copy()\n",
    "            keywords_list = DFkeywords_copy['top_keywords_20'].to_list()\n",
    "            flat_list = [keyword for keywords_sublist in keywords_list for keyword in keywords_sublist]\n",
    "               \n",
    "            #Counting occurrences of keywords\n",
    "            dict_occurrences = {}\n",
    "            for keyword in flat_list:\n",
    "                if keyword in dict_occurrences.keys():\n",
    "                    dict_occurrences[keyword] += 1\n",
    "                else:\n",
    "                    dict_occurrences[keyword] = 1\n",
    "            dict_occurrences = dict(sorted(dict_occurrences.items(), key=lambda item: item[1], reverse=True))\n",
    "            print(dict_occurrences)\n",
    "            print('Choose a word from this dictionary or write exit to exit.')\n",
    "            word_input = input()\n",
    "            if word_input=='exit':\n",
    "                break\n",
    "            elif word_input not in list(dict_occurrences.keys()):\n",
    "                print('Word not existing in the dictionary')\n",
    "            else:         \n",
    "                chosen_keyword = word_input\n",
    "                list_words.remove(substitute)\n",
    "                chosen_genre_keywords = list_words + [chosen_keyword]\n",
    "                \n",
    "                print(chosen_genre_keywords)\n",
    "                for key in chosen_genre_keywords:\n",
    "                    coverage_start += dict_occurrences[key]\n",
    "                if coverage_start > max_coverage:\n",
    "                    coverage_start = max_coverage\n",
    "                coverage_percentage = (coverage_start/max_coverage) * 100\n",
    "            print(f'Coverage goes from {coverage} to {coverage_percentage}. Proceed? (y/n)')  \n",
    "            final_choice = input()\n",
    "            if final_choice != 'y' and final_choice != 'n':\n",
    "                print('Impossible choice.')\n",
    "            elif final_choice == 'n':\n",
    "                print('Returning...')\n",
    "                break\n",
    "            elif final_choice == 'y':\n",
    "                DFkeywords_50.loc[mapping[genre]] = genre, chosen_genre_keywords, coverage_percentage\n",
    "            display(DFkeywords_50)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
